{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the GitHub Repository."
      ],
      "metadata": {
        "id": "ux8aP0GzdCQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FciA9FUhquM7",
        "outputId": "70d5d495-f45e-4ca2-813d-8e43762963d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction'...\n",
            "remote: Enumerating objects: 2911, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 2911 (delta 42), reused 64 (delta 25), pack-reused 2807\u001b[K\n",
            "Receiving objects: 100% (2911/2911), 84.14 MiB | 17.08 MiB/s, done.\n",
            "Resolving deltas: 100% (2031/2031), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b dev https://github.com/EfranH25/CS-674-Final-Project-3dInAction.git '/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the Google Drive"
      ],
      "metadata": {
        "id": "_3wmUzKQxq5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "help(drive)\n",
        "\n",
        "from os import chdir as change_directory\n",
        "from os import listdir as list_directory\n",
        "\n",
        "# Mount my Google Drive at My Drive.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3g4au_cq5T2",
        "outputId": "02356b9b-8b8e-4341-c71e-6d56eb9628d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on module google.colab.drive in google.colab:\n",
            "\n",
            "NAME\n",
            "    google.colab.drive - Colab-specific Google Drive integration.\n",
            "\n",
            "FUNCTIONS\n",
            "    flush_and_unmount(timeout_ms=86400000)\n",
            "        Unmount Google Drive and flush any outstanding writes to it.\n",
            "    \n",
            "    mount(mountpoint, force_remount=False, timeout_ms=120000, readonly=False)\n",
            "        Mount your Google Drive at the specified mountpoint path.\n",
            "\n",
            "DATA\n",
            "    __all__ = ['flush_and_unmount', 'mount']\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/google/colab/drive.py\n",
            "\n",
            "\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# datasets/MSRAction3DDataset.py"
      ],
      "metadata": {
        "id": "ENJw1rvncqnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move in the cloned repository.\n",
        "change_directory('/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/datasets')\n",
        "list_directory('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeVS0WUGvZPL",
        "outputId": "19d700a2-02f7-4948-dfd9-be0de8d501cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DfaustDataset.py',\n",
              " 'IKEAActionDatasetClips.py',\n",
              " 'IKEAEgoDatasetClips.py',\n",
              " '__init__.py',\n",
              " 'MSRAction3DDataset.py']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSRAction3DDataset_py_content = \"import torch\\n\\\n",
        "import pickle\\n\\\n",
        "import numpy as NumPy\\n\\\n",
        "import torch.cuda as tcuda\\n\\\n",
        "\\n\\\n",
        "# If CUDA is available, run code on GPU. Else, run code on CPU.\\n\\\n",
        "if tcuda.is_available():\\n\\\n",
        "  this_device = torch.device('cuda:0')\\n\\\n",
        "else:\\n\\\n",
        "  this_device = torch.device('cpu')\\n\\\n",
        "\\n\\\n",
        "class MSRAction3DDataset(torch.utils.data.Dataset):\\n\\\n",
        "  def __init__(self, dataset_path, set, cfg_data):\\n\\\n",
        "    # Call the __init__ function of the Dataset superclass.\\n\\\n",
        "    super(MSRAction3DDataset, self).__init__()\\n\\\n",
        "\\n\\\n",
        "    with open(dataset_path + 'MSRAction3D_FPS_Videos.pickle' , mode = 'rb') as msr_action3d_pickle_file:\\n\\\n",
        "      msr_action3d_depth_map_sequences = pickle.load(msr_action3d_pickle_file)\\n\\\n",
        "    msr_action3d_depth_map_sequence_labels = NumPy.load(dataset_path + 'MSRAction3D_FPS_Video_Labels.npz')['labels']\\n\\\n",
        "\\n\\\n",
        "    # Store the number of depth maps per clip in a variable.\\n\\\n",
        "    clip_size = 8\\n\\\n",
        "\\n\\\n",
        "    # Initialize a dictionary to hold the MSRAction3D clips and their labels.\\n\\\n",
        "    MSRAction3D_dataset = {'labels': [], 'clips': []}\\n\\\n",
        "\\n\\\n",
        "    # Loop through the depth map sequences of the MSRAction3D Dataset.\\n\\\n",
        "    for index, depth_map_sequence in enumerate(msr_action3d_depth_map_sequences):\\n\\\n",
        "      label = msr_action3d_depth_map_sequence_labels[index]\\n\\\n",
        "      num_depth_maps = depth_map_sequence.shape[1]\\n\\\n",
        "      clips = list(torch.Tensor(depth_map_sequence[0]).split(clip_size))\\n\\\n",
        "      if num_depth_maps % clip_size != 0:\\n\\\n",
        "        clips = clips[:-1]\\n\\\n",
        "      MSRAction3D_dataset['labels'].append(label + torch.zeros((num_depth_maps // clip_size, )))\\n\\\n",
        "      [MSRAction3D_dataset['clips'].append(clip[None]) for clip in clips]\\n\\\n",
        "\\n\\\n",
        "    # Concatenate all the label Tensors in the dataset together to form a single Tensor. Similarly, \\n\\\n",
        "    # concatenate all the clip Tensors into a single Tensor.\\n\\\n",
        "    labels = torch.concatenate(MSRAction3D_dataset['labels'])\\n\\\n",
        "    subsequences = torch.concatenate(MSRAction3D_dataset['clips'])\\n\\\n",
        "\\n\\\n",
        "    # Calculate the portion of the dataset to use depending on whether\\n\\\n",
        "    # the current phase is a training, validation or test phase.\\n\\\n",
        "    if set == \\\"train\\\":\\n\\\n",
        "      start_index = 0\\n\\\n",
        "      end_index = int(0.6 * labels.shape[0])\\n\\\n",
        "    elif set == \\\"test\\\":\\n\\\n",
        "      start_index = int(0.6 * labels.shape[0])\\n\\\n",
        "      end_index = labels.shape[0]\\n\\\n",
        "\\n\\\n",
        "    # Store the labels and subsequences in class variables.\\n\\\n",
        "    self.labels = labels[start_index: end_index].to(device = this_device)\\n\\\n",
        "    self.subsequences = subsequences[start_index: end_index].to(device = this_device)\\n\\\n",
        "\\n\\\n",
        "    # Store the clips in the dataset in a variable.\\n\\\n",
        "    self.clip_set = MSRAction3D_dataset['clips']\\n\\\n",
        "  def __getitem__(self, integral_key):\\n\\\n",
        "    # Implemented the __getitem__ method of this dataset.\\n\\\n",
        "    return (self.labels[integral_key], self.subsequences[integral_key])\\n\\\n",
        "  def __len__(self):\\n\\\n",
        "    # Implemented the __len__ method of this dataset.\\n\\\n",
        "    return len(self.labels)\\n\\\n",
        "  def __getitems__(self, batch_indices):\\n\\\n",
        "    # Implemented the __getitems__ method of this dataset.\\n\\\n",
        "    return (self.labels[batch_indices], self.subsequences[batch_indices])\\n\\\n",
        "  def make_weights_for_balanced_classes(self):\\n\\\n",
        "    label_counts = self.labels.unique(return_counts = True)[1]\\n\\\n",
        "    self.num_classes = label_counts.shape[0]\\n\\\n",
        "    return list(label_counts / label_counts.sum())\"\n",
        "\n",
        "with open('MSRAction3DDataset.py', 'w') as python_file:\n",
        "  python_file.writelines(MSRAction3DDataset_py_content)"
      ],
      "metadata": {
        "id": "QJo_B8LBDgYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# datasets/__init__.py"
      ],
      "metadata": {
        "id": "biWL9Y_icu8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_init_file = \"\"\"\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# from .IKEAEgoDatasetClips import IKEAEgoDatasetClips\n",
        "# from .DfaustDataset import DfaustActionClipsDataset\n",
        "# from .IKEAActionDatasetClips import IKEAActionDatasetClips\n",
        "from .MSRAction3DDataset import MSRAction3DDataset\n",
        "\n",
        "import i3d_utils as utils\n",
        "\n",
        "def build_dataset(cfg, training=True):\n",
        "    split = 'train' if training else 'test'\n",
        "    cfg_data = cfg['DATA']\n",
        "    if cfg_data.get('name') == 'DFAUST':\n",
        "        data_augmentation = cfg['TRAINING'].get('aug') if split == 'train' else cfg['TESTING'].get('aug')\n",
        "        dataset = DfaustActionClipsDataset(\n",
        "            action_dataset_path=cfg_data['dataset_path'], frames_per_clip=cfg_data['frames_per_clip'], set=split,\n",
        "            n_points=cfg_data['n_points'], shuffle_points=cfg_data['shuffle_points'], gender=cfg_data['gender'],\n",
        "            data_augmentation=data_augmentation, noisy_data=cfg_data['noisy_data'],\n",
        "        )\n",
        "    elif cfg_data.get('name') == 'IKEA_ASM':\n",
        "        dataset = IKEAActionDatasetClips(dataset_path=cfg_data['dataset_path'], set=split)\n",
        "    elif cfg_data.get('name') == 'IKEA_EGO':\n",
        "        dataset = IKEAEgoDatasetClips(dataset_path=cfg_data['dataset_path'], set=split, cfg_data=cfg_data)\n",
        "    elif cfg_data.get('name') == 'MSR-Action3D':\n",
        "        dataset = MSRAction3DDataset(dataset_path=cfg_data['dataset_path'], set=split, cfg_data=cfg_data)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def build_dataloader(config, training=True, shuffle=False):\n",
        "    dataset = build_dataset(config, training)\n",
        "\n",
        "    num_workers = config['num_workers']\n",
        "    batch_size = config['TRAINING'].get('batch_size') if training else config['TESTING'].get('batch_size')\n",
        "    data_sampler = config['DATA'].get('data_sampler')\n",
        "\n",
        "    split = 'train' if training else 'test'\n",
        "    print(\"Number of clips in the {} set:{}\".format(split, len(dataset)))\n",
        "\n",
        "    if training and data_sampler == 'weighted':\n",
        "        if config['DATA'].get('name') == 'DFAUST':\n",
        "            weights = dataset.make_weights_for_balanced_classes()\n",
        "        elif config['DATA'].get('name') == 'IKEA_ASM' or config['DATA'].get('name') == 'IKEA_EGO':\n",
        "            weights = utils.make_weights_for_balanced_classes(dataset.clip_set, dataset.clip_label_count)\n",
        "        elif config['DATA'].get('name') == 'MSR-Action3D':\n",
        "            weights = dataset.make_weights_for_balanced_classes()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
        "    else:\n",
        "        sampler = None\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        shuffle=shuffle,\n",
        "        num_workers = num_workers,\n",
        "        sampler = sampler,\n",
        "        collate_fn = lambda x: x,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return dataloader, dataset\n",
        "\"\"\"\n",
        "\n",
        "with open('__init__.py', 'w') as python_file:\n",
        "  python_file.writelines(dataset_init_file)"
      ],
      "metadata": {
        "id": "nYmpzfnkI72J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# config/msr-action3d/config_msr_action3d.yaml"
      ],
      "metadata": {
        "id": "hhPW-HAycyX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from os import getcwd as pwd\n",
        "from os import makedirs as newdir\n",
        "from os.path import exists as file_existing\n",
        "\n",
        "#help(yaml)\n",
        "\n",
        "yaml_document = None\n",
        "\n",
        "newdir('../configs/msr-action3d', exist_ok = True)\n",
        "\n",
        "if file_existing('/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/configs/msr-action3d/config_msr_action3d.yaml'):\n",
        "  with open('/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/configs/msr-action3d/config_msr_action3d.yaml', 'r') as yaml_file:\n",
        "    yaml_document = yaml.safe_load( yaml_file)\n",
        "else:\n",
        "  with open('../configs/dfaust/config_dfaust.yaml', 'r') as yaml_file:\n",
        "    yaml_document = yaml.safe_load(yaml_file)\n",
        "    yaml_document['DATA']['name'] = 'MSR-Action3D'\n",
        "    yaml_document['DATA']['dataset_path'] = '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/MSRAction3D_fps/'\n",
        "    yaml_document['MODEL']['pc_model'] = 'set_transformer'\n",
        "    yaml_document['TRAINING']['batch_size'] = 32\n",
        "    yaml_document['TRAINING']['n_epochs'] = 1800\n",
        "    yaml_document['TRAINING']['refine'] = True\n",
        "    yaml_document['TRAINING']['refine_epoch'] = 1500\n",
        "    yaml_document['TRAINING']['lr'] = 1e-3\n",
        "\n",
        "with open('../configs/msr-action3d/config_msr_action3d.yaml', 'w') as yaml_file:\n",
        "  yaml.safe_dump(yaml_document, yaml_file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uidMAJ3tAg2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Wandb files."
      ],
      "metadata": {
        "id": "Yr8mG-otxjp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copy as copy_file\n",
        "\n",
        "file_1 = \"/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/log/debug/{:06d}.pt\".format(yaml_document['TRAINING']['refine_epoch'])\n",
        "file_2 = \"/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/log/debug/{:06d}.pt\".format(yaml_document['TRAINING']['refine_epoch'])\n",
        "\n",
        "newdir('/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/log/debug/', exist_ok = True)\n",
        "copy_file(file_1, file_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "g70tvSl_xbHv",
        "outputId": "ef10ff01-b13d-440b-c6de-0d0473d4d426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/log/debug/002700.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# models/pointnet2_utils.py"
      ],
      "metadata": {
        "id": "4SPQR2hUc2Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pointnet2_utils_py = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from time import time\n",
        "import numpy as np\n",
        "from torch.autograd import Function\n",
        "import warnings\n",
        "\n",
        "# try:\n",
        "#     import models._ext as _ext\n",
        "# except ImportError:\n",
        "#     from torch.utils.cpp_extension import load\n",
        "#     import glob\n",
        "#     import os.path as osp\n",
        "#     import os\n",
        "\n",
        "#     warnings.warn(\"Unable to load pointnet2_ops cpp extension. JIT Compiling.\")\n",
        "\n",
        "#     _ext_src_root = osp.join(osp.dirname(__file__), \"_ext-src\")\n",
        "#     _ext_sources = glob.glob(osp.join(_ext_src_root, \"src\", \"*.cpp\")) + glob.glob(\n",
        "#         osp.join(_ext_src_root, \"src\", \"*.cu\")\n",
        "#     )\n",
        "#     _ext_headers = glob.glob(osp.join(_ext_src_root, \"include\", \"*\"))\n",
        "\n",
        "#     os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"3.7+PTX;5.0;6.0;6.1;6.2;7.0;7.5\"\n",
        "#     _ext = load(\n",
        "#         \"_ext\",\n",
        "#         sources=_ext_sources,\n",
        "#         extra_include_paths=[osp.join(_ext_src_root, \"include\")],\n",
        "#         extra_cflags=[\"-O3\"],\n",
        "#         extra_cuda_cflags=[\"-O3\", \"-Xfatbin\", \"-compress-all\"],\n",
        "#         with_cuda=True,\n",
        "#     )\n",
        "\n",
        "def timeit(tag, t):\n",
        "    print(\"{}: {}s\".format(tag, time() - t))\n",
        "    return time()\n",
        "\n",
        "def pc_normalize(pc):\n",
        "    l = pc.shape[0]\n",
        "    centroid = np.mean(pc, axis=0)\n",
        "    pc = pc - centroid\n",
        "    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n",
        "    pc = pc / m\n",
        "    return pc\n",
        "\n",
        "def square_distance(src, dst):\n",
        "    \\\"\\\"\\\"\n",
        "    Calculate Euclid distance between each two points.\n",
        "\n",
        "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
        "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
        "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
        "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
        "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
        "\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: per-point square distance, [B, N, M]\n",
        "    \\\"\\\"\\\"\n",
        "    B, N, _ = src.shape\n",
        "    _, M, _ = dst.shape\n",
        "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
        "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
        "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
        "    return dist\n",
        "\n",
        "\n",
        "def index_points(points, idx):\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \\\"\\\"\\\"\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    idx = idx.long()\n",
        "    new_points = points[batch_indices, idx, :]\n",
        "    return new_points\n",
        "\n",
        "\n",
        "# This implementation is very slow and should not be used unless you can't get the CUDA version to compile\n",
        "# def farthest_point_sample(xyz, npoint):\n",
        "#     \\\"\\\"\\\"\n",
        "#     Input:\n",
        "#         xyz: pointcloud data, [B, N, 3]\n",
        "#         npoint: number of samples\n",
        "#     Return:\n",
        "#         centroids: sampled pointcloud index, [B, npoint]\n",
        "#     \\\"\\\"\\\"\n",
        "#     device = xyz.device\n",
        "#     B, N, C = xyz.shape\n",
        "#     centroids = torch.zeros(B, npoint, dtype=torch.long, device=device)\n",
        "#     distance = torch.ones(B, N, device=device)* 1e10\n",
        "#     farthest = torch.randint(0, N, (B,), dtype=torch.long, device=device)\n",
        "#     batch_indices = torch.arange(B, dtype=torch.long, device=device)\n",
        "#     for i in range(npoint):\n",
        "#         centroids[:, i] = farthest\n",
        "#         centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
        "#         dist = torch.sum((xyz - centroid) ** 2, -1)\n",
        "#         mask = dist < distance\n",
        "#         distance[mask] = dist[mask]\n",
        "#         farthest = torch.max(distance, -1)[1]\n",
        "#     return centroids\n",
        "\n",
        "\n",
        "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
        "    \\\"\\\"\\\"\n",
        "    Input:\n",
        "        radius: local region radius\n",
        "        nsample: max sample number in local region\n",
        "        xyz: all points, [B, N, 3]\n",
        "        new_xyz: query points, [B, S, 3]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, nsample]\n",
        "    \\\"\\\"\\\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    _, S, _ = new_xyz.shape\n",
        "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "    group_idx[sqrdists > radius ** 2] = N\n",
        "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
        "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
        "    mask = group_idx == N\n",
        "    group_idx[mask] = group_first[mask]\n",
        "    return group_idx\n",
        "\n",
        "\n",
        "def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Input:\n",
        "        npoint:\n",
        "        radius:\n",
        "        nsample:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, npoint, nsample, 3]\n",
        "        new_points: sampled points data, [B, npoint, nsample, 3+D]\n",
        "    \\\"\\\"\\\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = npoint\n",
        "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]\n",
        "    new_xyz = index_points(xyz, fps_idx.to(torch.int64))\n",
        "\n",
        "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
        "    # dists = square_distance(new_xyz, xyz)  # B x npoint x N\n",
        "    # idx = dists.argsort()[:, :, :nsample]\n",
        "\n",
        "    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]\n",
        "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
        "\n",
        "    if points is not None:\n",
        "        grouped_points = index_points(points, idx)\n",
        "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, C+D]\n",
        "    else:\n",
        "        new_points = grouped_xyz_norm\n",
        "    if returnfps:\n",
        "        return new_xyz, new_points, grouped_xyz, fps_idx\n",
        "    else:\n",
        "        return new_xyz, new_points\n",
        "\n",
        "\n",
        "def sample_and_group_all(xyz, points):\n",
        "    \\\"\\\"\\\"\n",
        "    Input:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, 1, 3]\n",
        "        new_points: sampled points data, [B, 1, N, 3+D]\n",
        "    \\\"\\\"\\\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    new_xyz = torch.zeros(B, 1, C).to(device)\n",
        "    grouped_xyz = xyz.view(B, 1, N, C)\n",
        "    if points is not None:\n",
        "        new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
        "    else:\n",
        "        new_points = grouped_xyz\n",
        "    return new_xyz, new_points\n",
        "\n",
        "\n",
        "def sample_and_group_4d(npoint, radius, nsample, xyz, points, returnfps=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Input:\n",
        "        npoint:\n",
        "        radius:\n",
        "        nsample:\n",
        "        xyz: input points position data, [B, t, N, 3]\n",
        "        points: input points data, [B, t, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, t, npoint, nsample, 3]\n",
        "        new_points: sampled points data, [B, t, npoint, nsample, 3+D]\n",
        "    \\\"\\\"\\\"\n",
        "    B, t, N, C = xyz.shape\n",
        "    S = npoint\n",
        "    D = points.shape[-1]\n",
        "    fps_idx = farthest_point_sample(xyz[:, 0], npoint)  # [B, npoint, C], use frist drame for fps\n",
        "    xyz = xyz.reshape(-1, N, C)\n",
        "    new_xyz = index_points(xyz, fps_idx.unsqueeze(1).repeat([1, t, 1]).reshape(-1, npoint))\n",
        "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
        "    grouped_xyz = index_points(xyz, idx)  # [B, npoint, nsample, C]\n",
        "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B*t, S, 1, C)  # shouldnt this also be scaled to unit sphere?\n",
        "\n",
        "    if points is not None:\n",
        "        grouped_points = index_points(points.reshape(-1, N, D), idx)\n",
        "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1)  # [B, npoint, nsample, C+D]\n",
        "    else:\n",
        "        new_points = grouped_xyz_norm\n",
        "\n",
        "    new_xyz = new_xyz.reshape(B, t, npoint, C)\n",
        "    new_points = new_points.reshape(B, t, npoint, nsample, -1)\n",
        "\n",
        "    if returnfps:\n",
        "        return new_xyz, new_points, grouped_xyz, fps_idx\n",
        "    else:\n",
        "        return new_xyz, new_points\n",
        "\n",
        "def sample_and_group_all_4d(xyz, points):\n",
        "    \\\"\\\"\\\"\n",
        "    Input:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, 1, 3]\n",
        "        new_points: sampled points data, [B, 1, N, 3+D]\n",
        "    \\\"\\\"\\\"\n",
        "    device = xyz.device\n",
        "    B, t, N, C = xyz.shape\n",
        "    new_xyz = torch.zeros(B, t, 1, C).to(device)\n",
        "    grouped_xyz = xyz.view(B, t, 1, N, C)\n",
        "    if points is not None:\n",
        "        new_points = torch.cat([grouped_xyz, points.view(B, t, 1, N, -1)], dim=-1)\n",
        "    else:\n",
        "        new_points = grouped_xyz\n",
        "    return new_xyz, new_points\n",
        "\n",
        "\n",
        "class PointNetSetAbstraction(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
        "        super(PointNetSetAbstraction, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv3d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm3d(out_channel))\n",
        "            last_channel = out_channel\n",
        "        self.group_all = group_all\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \\\"\\\"\\\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \\\"\\\"\\\"\n",
        "        b, t, k, n = xyz.shape\n",
        "        xyz = xyz.reshape(-1, k, n)\n",
        "        xyz = xyz.permute(0, 2, 1).contiguous()\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 1, 3, 2)\n",
        "            points = points.reshape(-1, points.shape[-2], points.shape[-1])\n",
        "\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
        "        else:\n",
        "            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
        "        # new_xyz: sampled points position data, [b*t, npoint, k]\n",
        "        # new_points: sampled points data, [b*t, npoint, nsample, d+k]\n",
        "        new_points = new_points.reshape(b, t, new_points.shape[-3], new_points.shape[-2], new_points.shape[-1])\n",
        "        new_points = new_points.permute(0, 4, 2, 1, 3)  # [b, d+k, npoint, t, nsample]\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points = F.relu(bn(conv(new_points)))\n",
        "\n",
        "        new_points = torch.max(new_points, -1)[0]\n",
        "        new_points = new_points.permute(0, 3, 1, 2)\n",
        "        new_xyz = new_xyz.reshape(b, t, new_xyz.shape[-2], new_xyz.shape[-1]).permute(0, 1, 3, 2)\n",
        "        return new_xyz, new_points\n",
        "\n",
        "class PointNetPP4DSetAbstraction(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all, temporal_conv=4):\n",
        "        super(PointNetPP4DSetAbstraction, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv3d(last_channel, out_channel, [1, temporal_conv, 1], 1, padding='same'))\n",
        "            self.mlp_bns.append(nn.BatchNorm3d(out_channel))\n",
        "            last_channel = out_channel\n",
        "        self.group_all = group_all\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \\\"\\\"\\\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \\\"\\\"\\\"\n",
        "        b, t, k, n = xyz.shape\n",
        "        xyz = xyz.reshape(-1, k, n)\n",
        "        xyz = xyz.permute(0, 2, 1)\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 1, 3, 2)\n",
        "            # points = points.reshape(-1, points.shape[-2], points.shape[-1])\n",
        "\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points = sample_and_group_all_4d(xyz.reshape(b, t, n, k), points)\n",
        "        else:\n",
        "            new_xyz, new_points = sample_and_group_4d(self.npoint, self.radius, self.nsample,\n",
        "                                                      xyz.reshape(b, t, n, k), points)\n",
        "\n",
        "        # new_xyz: sampled points position data, [b*t, npoint, k]\n",
        "        # new_points: sampled points data, [b*t, npoint, nsample, d+k]\n",
        "        new_points = new_points.reshape(b, t, new_points.shape[-3], new_points.shape[-2], new_points.shape[-1])\n",
        "        new_points = new_points.permute(0, 4, 2, 1, 3)  # [b, d+k, npoint, t, nsample]\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points = F.relu(bn(conv(new_points)))\n",
        "\n",
        "        new_points = torch.max(new_points, -1)[0]\n",
        "        new_points = new_points.permute(0, 3, 1, 2)\n",
        "        new_xyz = new_xyz.reshape(b, t, new_xyz.shape[-2], new_xyz.shape[-1]).permute(0, 1, 3, 2)\n",
        "        return new_xyz, new_points\n",
        "\n",
        "class PointNetSetAbstractionMsg(nn.Module):\n",
        "    def __init__(self, npoint, radius_list, nsample_list, in_channel, mlp_list):\n",
        "        super(PointNetSetAbstractionMsg, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius_list = radius_list\n",
        "        self.nsample_list = nsample_list\n",
        "        self.conv_blocks = nn.ModuleList()\n",
        "        self.bn_blocks = nn.ModuleList()\n",
        "        for i in range(len(mlp_list)):\n",
        "            convs = nn.ModuleList()\n",
        "            bns = nn.ModuleList()\n",
        "            last_channel = in_channel # + 3\n",
        "            for out_channel in mlp_list[i]:\n",
        "                convs.append(nn.Conv3d(last_channel, out_channel, 1))\n",
        "                bns.append(nn.BatchNorm3d(out_channel))\n",
        "                last_channel = out_channel\n",
        "            self.conv_blocks.append(convs)\n",
        "            self.bn_blocks.append(bns)\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \\\"\\\"\\\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \\\"\\\"\\\"\n",
        "        b, t, k, n = xyz.shape\n",
        "        xyz = xyz.reshape(-1, k, n)\n",
        "        xyz = xyz.permute(0, 2, 1).contiguous()\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 1, 3, 2)\n",
        "            points = points.reshape(-1, points.shape[-2], points.shape[-1])\n",
        "\n",
        "        B, N, C = xyz.shape\n",
        "        S = self.npoint\n",
        "        new_xyz = index_points(xyz, farthest_point_sample(xyz, S))\n",
        "        new_points_list = []\n",
        "        for i, radius in enumerate(self.radius_list):\n",
        "            K = self.nsample_list[i]\n",
        "            group_idx = query_ball_point(radius, K, xyz, new_xyz)\n",
        "            grouped_xyz = index_points(xyz, group_idx)\n",
        "            grouped_xyz -= new_xyz.view(B, S, 1, C)\n",
        "            if points is not None:\n",
        "                grouped_points = index_points(points, group_idx)\n",
        "                grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)\n",
        "            else:\n",
        "                grouped_points = grouped_xyz\n",
        "\n",
        "            grouped_points = grouped_points.reshape(b, t, grouped_points.shape[-3], grouped_points.shape[-2], grouped_points.shape[-1])\n",
        "            grouped_points = grouped_points.permute(0, 4, 2, 1, 3)  # [b, d+k, npoint, t, nsample]\n",
        "\n",
        "            for j in range(len(self.conv_blocks[i])):\n",
        "                conv = self.conv_blocks[i][j]\n",
        "                bn = self.bn_blocks[i][j]\n",
        "                grouped_points = F.relu(bn(conv(grouped_points)))\n",
        "            new_points = torch.max(grouped_points, -1)[0]\n",
        "            new_points_list.append(new_points)\n",
        "\n",
        "        new_xyz = new_xyz.reshape(b, t, new_xyz.shape[-2], new_xyz.shape[-1]).permute(0, 1, 3, 2)\n",
        "        new_points_concat = torch.cat(new_points_list, dim=1)\n",
        "        new_points_concat = new_points_concat.permute(0, 3, 1, 2)\n",
        "        return new_xyz, new_points_concat\n",
        "\n",
        "\n",
        "class PointNetFeaturePropagation(nn.Module):\n",
        "    def __init__(self, in_channel, mlp):\n",
        "        super(PointNetFeaturePropagation, self).__init__()\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
        "            last_channel = out_channel\n",
        "\n",
        "    def forward(self, xyz1, xyz2, points1, points2):\n",
        "        \\\"\\\"\\\"\n",
        "        Input:\n",
        "            xyz1: input points position data, [B, C, N]\n",
        "            xyz2: sampled input points position data, [B, C, S]\n",
        "            points1: input points data, [B, D, N]\n",
        "            points2: input points data, [B, D, S]\n",
        "        Return:\n",
        "            new_points: upsampled points data, [B, D', N]\n",
        "        \\\"\\\"\\\"\n",
        "        xyz1 = xyz1.permute(0, 2, 1)\n",
        "        xyz2 = xyz2.permute(0, 2, 1)\n",
        "\n",
        "        points2 = points2.permute(0, 2, 1)\n",
        "        B, N, C = xyz1.shape\n",
        "        _, S, _ = xyz2.shape\n",
        "\n",
        "        if S == 1:\n",
        "            interpolated_points = points2.repeat(1, N, 1)\n",
        "        else:\n",
        "            dists = square_distance(xyz1, xyz2)\n",
        "            dists, idx = dists.sort(dim=-1)\n",
        "            dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
        "\n",
        "            dist_recip = 1.0 / (dists + 1e-8)\n",
        "            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
        "            weight = dist_recip / norm\n",
        "            interpolated_points = torch.sum(index_points(points2, idx) * weight.view(B, N, 3, 1), dim=2)\n",
        "\n",
        "        if points1 is not None:\n",
        "            points1 = points1.permute(0, 2, 1)\n",
        "            new_points = torch.cat([points1, interpolated_points], dim=-1)\n",
        "        else:\n",
        "            new_points = interpolated_points\n",
        "\n",
        "        new_points = new_points.permute(0, 2, 1)\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points = F.relu(bn(conv(new_points)))\n",
        "        return new_points\n",
        "\n",
        "\n",
        "class PointNetSetAbstractionOriginal(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all, knn=False):\n",
        "        super(PointNetSetAbstractionOriginal, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.knn = knn\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
        "            last_channel = out_channel\n",
        "        self.group_all = group_all\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \\\"\\\"\\\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, N, C]\n",
        "            points: input points data, [B, N, C]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, S, C]\n",
        "            new_points_concat: sample points feature data, [B, S, D']\n",
        "        \\\"\\\"\\\"\n",
        "        xyz = xyz.permute(0, 2, 1)\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
        "        else:\n",
        "            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
        "        # new_xyz: sampled points position data, [B, npoint, C]\n",
        "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
        "        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points =  F.relu(bn(conv(new_points)))\n",
        "\n",
        "        new_points = torch.max(new_points, 2)[0].transpose(1, 2)\n",
        "        return new_xyz, new_points\n",
        "\n",
        "\n",
        "class FurthestPointSampling(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, xyz, npoint):\n",
        "        # type: (Any, torch.Tensor, int) -> torch.Tensor\n",
        "        r\\\"\\\"\\\"\n",
        "        Uses iterative furthest point sampling to select a set of npoint features that have the largest\n",
        "        minimum distance\n",
        "        Parameters\n",
        "        ----------\n",
        "        xyz : torch.Tensor\n",
        "            (B, N, 3) tensor where N > npoint\n",
        "        npoint : int32\n",
        "            number of features in the sampled set\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            (B, npoint) tensor containing the set\n",
        "        \\\"\\\"\\\"\n",
        "        fps_inds = _ext.furthest_point_sampling(xyz, npoint)\n",
        "        ctx.mark_non_differentiable(fps_inds)\n",
        "        return fps_inds\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(xyz, a=None):\n",
        "        return None, None\n",
        "\n",
        "\n",
        "farthest_point_sample = FurthestPointSampling.apply\n",
        "\"\"\"\n",
        "\n",
        "with open('../models/pointnet2_utils.py', 'w') as python_file:\n",
        "  python_file.writelines(pointnet2_utils_py)"
      ],
      "metadata": {
        "id": "rD5J-7UPONyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# models/__init__.py"
      ],
      "metadata": {
        "id": "62fJ640jj6bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "change_directory('/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/datasets')"
      ],
      "metadata": {
        "id": "MJ_EYELfekoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_init_py = \"\"\"\n",
        "import os\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "print(\"DEBUG\")\n",
        "\n",
        "from .pointnet import PointNet1, PointNet1Basic\n",
        "\n",
        "print(\"DEBUG\")\n",
        "\n",
        "# from .pointnet2_cls_ssg import PointNet2, PointNet2Basic\n",
        "\n",
        "print(\"DEBUG\")\n",
        "\n",
        "from .pytorch_3dmfv import FourDmFVNet\n",
        "\n",
        "print(\"DEBUG\")\n",
        "\n",
        "#from .tpatches import TPatchesInAction\n",
        "from .set_transformer import SetTransformerTemporal\n",
        "\n",
        "print(\"DEBUG-22\")\n",
        "\n",
        "#from .tpatch_trajectory import tPatchTraj\n",
        "from .DGCNN import DGCNN\n",
        "\n",
        "print(\"DEBUG-27\")\n",
        "\n",
        "#from .pstnet import PSTnet\n",
        "\n",
        "print(\"DEBUG-31\")\n",
        "\n",
        "# from .PST_Transformer import PSTTransformer\n",
        "# from .P4Transformer import P4Transformer\n",
        "\n",
        "print(\"DEBUG\")\n",
        "\n",
        "__all__ = {\n",
        "    'pn1': PointNet1,\n",
        "    'pn1_4d_basic': PointNet1Basic,\n",
        "    #'pn2': PointNet2,\n",
        "    #'pn2_4d_basic': PointNet2Basic,\n",
        "    #'tpatches': TPatchesInAction,\n",
        "    '3dmfv': FourDmFVNet,\n",
        "    'set_transformer': SetTransformerTemporal,\n",
        "    #'tpatch_trajectory': tPatchTraj,\n",
        "    'dgcnn': DGCNN,\n",
        "#    'pst_transformer': PSTTransformer,\n",
        "#    'pstnet': PSTnet,\n",
        "#    'p4transformer': P4Transformer,\n",
        "}\n",
        "\n",
        "def build_model(model_cfg, num_class, frames_per_clip):\n",
        "    model = __all__[model_cfg['pc_model']](\n",
        "        model_cfg=model_cfg, num_class=num_class, n_frames=frames_per_clip\n",
        "    )\n",
        "    return model\n",
        "\n",
        "file_name_dict = {\n",
        "    'pn1': \"pointnet.py\",\n",
        "    'pn1_4d_basic': \"pointnet.py\",\n",
        "    'pn2': \"pointnet2_cls_ssg.py\",\n",
        "    'pn2_4d_basic': \"pointnet2_cls_ssg.py\",\n",
        "    'tpatches': \"tpatches.py\",\n",
        "    '3dmfv': \"pytorch_3dmfv.py\",\n",
        "    'set_transformer': 'set_transformer.py',\n",
        "    'tpatch_trajectory': 'tpatch_trajectory.py',\n",
        "    'dgcnn': 'DGCNN.py',\n",
        "    'pstnet': 'pstnet.py',\n",
        "    'pst_transformer': 'PST_Transformer.py',\n",
        "    'p4transformer': 'P4Transformer.py',\n",
        "}\n",
        "\n",
        "\n",
        "class build_model_from_logdir(object):\n",
        "    def __init__(self, logdir, model_cfg, num_classes, frames_per_clip):\n",
        "        pc_model = model_cfg.get('pc_model')\n",
        "        model_instance = __all__[pc_model]\n",
        "        model_name = model_instance.__name__\n",
        "        file_name = file_name_dict.get(pc_model)\n",
        "\n",
        "        spec = importlib.util.spec_from_file_location(model_name, os.path.join(logdir, 'models', file_name))\n",
        "        import_model = importlib.util.module_from_spec(spec)\n",
        "        sys.modules[model_name] = import_model\n",
        "        spec.loader.exec_module(import_model)\n",
        "        self.model = model_instance(model_cfg=model_cfg, num_class=num_classes, n_frames=frames_per_clip)\n",
        "    def get(self):\n",
        "        return self.model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open('../models/__init__.py', 'w') as python_file:\n",
        "  python_file.writelines(models_init_py)"
      ],
      "metadata": {
        "id": "-Va0uO1Vj8I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# models/extractors.py"
      ],
      "metadata": {
        "id": "F5ZjUlvhQKXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractors_py = \"\"\"\n",
        "import faiss\n",
        "from faiss.contrib.torch_utils import torch_replacement_knn_gpu as faiss_torch_knn_gpu\n",
        "from pykeops.torch import Vi, Vj\n",
        "from scipy.spatial import cKDTree\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import models.pointnet2_utils as utils\n",
        "\n",
        "\n",
        "def get_tpatches(x1, x2, feat_seq, flip=False, k=16, radius=0.2, res=None,\n",
        "                 sample_mode='nn', add_centroid_jitter=None, downsample_method='fps', npoints=None):\n",
        "    b, t, n, d = x1.shape\n",
        "    n_out = n\n",
        "\n",
        "    if feat_seq is None:\n",
        "        feat_seq = x1\n",
        "        d_feat = d\n",
        "    else:\n",
        "        d_feat = feat_seq.shape[-1]\n",
        "\n",
        "    out_x = torch.empty(b, t, n_out, d)\n",
        "    patchlets = torch.empty(b, t, n, k, device=x1.device, dtype=torch.long)\n",
        "    distances_i = torch.empty(b, t, n, k, device=x1.device)\n",
        "    idxs_i = torch.empty(b, t, n, k, device=x1.device, dtype=torch.long)\n",
        "    patchlet_points = torch.empty(b, t, n, k, d, device=x1.device)\n",
        "    patchlet_feats = torch.empty(b, t, n, k, d_feat, device=x1.device)\n",
        "\n",
        "    # loop over the data to reorder the indices to form the patchlets\n",
        "    x_current = x2[:, 0]\n",
        "    feat_seq_2 = torch.cat([feat_seq[:, [0]], feat_seq], dim=1)[:, :-1]\n",
        "    for i in range(0, t):\n",
        "        x_next = x1[:, i]\n",
        "        distances, idxs = get_knn(x_current[..., 0:3], x_next[..., 0:3], k=k, res=res, method='keops',\n",
        "                                  radius=radius)\n",
        "        if sample_mode == 'nn':\n",
        "            x_current = utils.index_points(x_next, idxs)[:, :, 0, :]\n",
        "        elif sample_mode == 'randn':\n",
        "            rand_idx = torch.randint(k, (b, n, 1), device=x_next.device, dtype=torch.int64).repeat(\n",
        "                [1, 1, 3]).unsqueeze(2)\n",
        "            x_current = torch.gather(utils.index_points(x_next, idxs).squeeze(), dim=2, index=rand_idx).squeeze()\n",
        "        elif sample_mode == 'gt':\n",
        "            # only works when point correspondence is known and points are already aligned\n",
        "            x_current = x_next\n",
        "        else:\n",
        "            raise ValueError(\"sample mode not supported\")\n",
        "\n",
        "        out_x[:, i] = x_current\n",
        "        if add_centroid_jitter is not None and not sample_mode == 'gt':\n",
        "            x_current = x_current + add_centroid_jitter * torch.randn_like(x_current)\n",
        "\n",
        "        distances_i[:, i], idxs_i[:, i] = distances, idxs\n",
        "        patchlets[:, i] = idxs_i[:, i]\n",
        "        patchlet_points[:, i] = utils.index_points(x_next, idxs).squeeze()\n",
        "        patchlet_feats[:, i] = utils.index_points(feat_seq_2[:, i], idxs).squeeze()\n",
        "\n",
        "    distances = distances_i\n",
        "    idxs = idxs_i\n",
        "    if flip:  # reverse temporal order\n",
        "        patchlet_feats = torch.flip(patchlet_feats, [1])\n",
        "        patchlet_points = torch.flip(patchlet_points, [1])\n",
        "        idxs = torch.flip(idxs, [1])\n",
        "        distances = torch.flip(distances, [1])\n",
        "        patchlets = torch.flip(patchlets, [1])\n",
        "\n",
        "    patchlet_feats = patchlet_feats.reshape(b * t, n, k, d_feat)\n",
        "    patchlet_points = patchlet_points.reshape(b * t, n, k, d)\n",
        "    idxs = idxs.reshape(b * t, n, k)\n",
        "    distances = distances.reshape(b * t, n, k)\n",
        "    patchlets = patchlets.reshape(b * t, n, k)\n",
        "\n",
        "    fps_idx = None\n",
        "    if downsample_method == 'fps':\n",
        "        # select a subset of the points using fps for maximum coverage\n",
        "        selected_idxs = utils.farthest_point_sample(x1[:, 0].contiguous(), npoints).to(torch.int64)\n",
        "        selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, npoints)\n",
        "        patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "        patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "        distances = utils.index_points(distances, selected_idxs)\n",
        "        idxs = utils.index_points(idxs, selected_idxs)\n",
        "        patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "        n = npoints\n",
        "    elif downsample_method == 'var' or downsample_method == 'mean_var_t':\n",
        "        # select a subset of the points with the largest point variance for maximum temporal movement\n",
        "        if downsample_method == 'var':\n",
        "            temporal_patchlet_points = patchlet_points.reshape(b, t, n, k, d). \\\n",
        "                permute(0, 2, 1, 3, 4).reshape(b, n, -1, d)\n",
        "            patchlet_variance = torch.linalg.norm(torch.var(temporal_patchlet_points, -2), dim=-1)\n",
        "        elif downsample_method == 'mean_var_t':\n",
        "            patchlet_variance = torch.linalg.norm(\n",
        "                torch.var(torch.mean(patchlet_points.reshape(b, t, n, k, d), -2), 1), dim=-1)\n",
        "        else:\n",
        "            raise ValueError(\"downsample method not supported \")\n",
        "        _, selected_idxs = torch.topk(patchlet_variance, npoints)\n",
        "        selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, npoints)\n",
        "        patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "        patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "        distances = utils.index_points(distances, selected_idxs)\n",
        "        idxs = utils.index_points(idxs, selected_idxs)\n",
        "        patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "        n = npoints\n",
        "\n",
        "    return patchlet_points, patchlet_feats, distances, idxs, patchlets, n, d_feat, fps_idx, out_x\n",
        "\n",
        "\n",
        "def get_knn(x1, x2, k=16, res=None, method='faiss_gpu', radius=None):\n",
        "\n",
        "    if method == 'faiss_gpu':\n",
        "        distances, idxs = faiss_torch_knn_gpu(res, x1, x2, k=k)\n",
        "    if method == 'faiss_cpu':\n",
        "        distances, idxs = faiss.knn(np.ascontiguousarray(x1.detach().cpu().numpy(), dtype=np.float32),\n",
        "                                    np.ascontiguousarray(x2.detach().cpu().numpy(), dtype=np.float32), k=k)\n",
        "        distances, idxs = torch.tensor(distances, device=x1.device).cuda(), torch.tensor(idxs, device=x1.device).cuda()\n",
        "    if method == 'spatial':\n",
        "        tree = cKDTree(x2.detach().cpu().numpy())\n",
        "        distances, idxs = tree.query(x1.detach().cpu().numpy(), k, workers=-1)\n",
        "        distances, idxs = torch.tensor(distances).cuda(), torch.tensor(idxs).cuda()\n",
        "    if method == 'keops': #supports batch operaations\n",
        "        X_i = Vi(0, x1.shape[-1])\n",
        "        X_j = Vj(1, x2.shape[-1])\n",
        "        D_ij = ((X_i - X_j) ** 2).sum(-1)\n",
        "        KNN_fun = D_ij.Kmin_argKmin(k, dim=1)\n",
        "        distances, idxs = KNN_fun(x1.contiguous(), x2.contiguous())\n",
        "\n",
        "    if radius is not None:\n",
        "        # clip samples outside a radius, replace with origin to keep k constant\n",
        "        clipped_idxs = idxs[..., [0]].repeat(1, 1, k)\n",
        "        mask = distances > radius**2\n",
        "        idxs[mask] = clipped_idxs[mask]\n",
        "        distances[mask] = 0\n",
        "    return distances, idxs\n",
        "\n",
        "\n",
        "class TPatchExtractor(nn.Module):\n",
        "    def __init__(self, k=16, sample_mode='nn', npoints=None, add_centroid_jitter=None, downsample_method=None,\n",
        "                 radius=None, temporal_stride=8):\n",
        "        super(TPatchExtractor, self).__init__()\n",
        "        self.k = k\n",
        "        self.radius = radius\n",
        "        self.sample_mode = sample_mode\n",
        "        self.downsample_method = downsample_method\n",
        "        self.npoints = npoints\n",
        "        self.add_centroid_jitter = add_centroid_jitter\n",
        "        self.res = faiss.StandardGpuResources()\n",
        "        self.res.setDefaultNullStreamAllDevices()\n",
        "\n",
        "\n",
        "    def forward(self, point_seq, feat_seq=None):\n",
        "        b, t, n, d = point_seq.shape\n",
        "        n_original = n\n",
        "        n_out = n\n",
        "        if feat_seq is None:\n",
        "            feat_seq = point_seq\n",
        "            d_feat = d\n",
        "        else:\n",
        "            d_feat = feat_seq.shape[-1]\n",
        "\n",
        "        x1 = point_seq\n",
        "        x2 = torch.cat([point_seq[:, [0]], point_seq], dim=1)[:, :-1]\n",
        "\n",
        "        out_x = torch.empty(b, t, n_out, d)\n",
        "        patchlets = torch.empty(b, t, n, self.k, device=point_seq.device, dtype=torch.long)\n",
        "        distances_i = torch.empty(b,  t, n, self.k, device=point_seq.device)\n",
        "        idxs_i = torch.empty(b, t, n, self.k, device=point_seq.device, dtype=torch.long)\n",
        "        patchlet_points = torch.empty(b, t, n, self.k, d, device=point_seq.device)\n",
        "        patchlet_feats = torch.empty(b, t, n, self.k, d_feat, device=point_seq.device)\n",
        "\n",
        "        # loop over the data to reorder the indices to form the patchlets\n",
        "        x_current = x2[:, 0]\n",
        "        feat_seq_2 = torch.cat([feat_seq[:, [0]], feat_seq], dim=1)[:, :-1]\n",
        "        for i in range(0, t):\n",
        "            x_next = x1[:, i]\n",
        "            distances, idxs = get_knn(x_current[..., 0:3], x_next[..., 0:3], k=self.k, res=self.res, method='keops', radius=self.radius)\n",
        "            if self.sample_mode == 'nn':\n",
        "                x_current = utils.index_points(x_next, idxs)[:, :, 0, :]\n",
        "            elif self.sample_mode == 'randn':\n",
        "                rand_idx = torch.randint(self.k, (b, n, 1), device=x_next.device, dtype=torch.int64).repeat([1, 1, 3]).unsqueeze(2)\n",
        "                x_current = torch.gather(utils.index_points(x_next, idxs).squeeze(), dim=2, index=rand_idx).squeeze()\n",
        "            elif self.sample_mode == 'gt':\n",
        "                # only works when point correspondence is known and points are already aligned\n",
        "                x_current = x_next\n",
        "            else:\n",
        "                raise ValueError(\"sample mode not supported\")\n",
        "\n",
        "            out_x[:, i] = x_current\n",
        "            if self.add_centroid_jitter is not None and not self.sample_mode == 'gt':\n",
        "                x_current = x_current + self.add_centroid_jitter*torch.randn_like(x_current)\n",
        "\n",
        "            distances_i[:, i], idxs_i[:, i] = distances, idxs\n",
        "            patchlets[:, i] = idxs_i[:, i]\n",
        "            patchlet_points[:, i] = utils.index_points(x_next, idxs).squeeze()\n",
        "            patchlet_feats[:, i] = utils.index_points(feat_seq_2[:, i], idxs).squeeze()\n",
        "\n",
        "        distances = distances_i\n",
        "        idxs = idxs_i\n",
        "\n",
        "        patchlet_feats = patchlet_feats.reshape(b*t, n, self.k, d_feat)\n",
        "        patchlet_points = patchlet_points.reshape(b * t, n, self.k, d)\n",
        "        idxs = idxs.reshape(b*t, n, self.k)\n",
        "        distances = distances.reshape(b*t, n, self.k)\n",
        "        patchlets = patchlets.reshape(b*t, n, self.k)\n",
        "\n",
        "        fps_idx = None\n",
        "        if self.downsample_method == 'fps':\n",
        "            #select a subset of the points using fps for maximum coverage\n",
        "            selected_idxs = utils.farthest_point_sample(point_seq[:, 0].contiguous(), self.npoints).to(torch.int64)\n",
        "            selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, self.npoints)\n",
        "            patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "            patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "            distances = utils.index_points(distances, selected_idxs)\n",
        "            idxs = utils.index_points(idxs, selected_idxs)\n",
        "            patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "            n = self.npoints\n",
        "        elif self.downsample_method == 'var' or self.downsample_method == 'mean_var_t':\n",
        "            # select a subset of the points with the largest point variance for maximum temporal movement\n",
        "            if self.downsample_method == 'var':\n",
        "                temporal_patchlet_points = patchlet_points.reshape(b, t, n, self.k, d).permute(0, 2, 1, 3, 4).reshape(b,n,-1,d)\n",
        "                patchlet_variance = torch.linalg.norm(torch.var(temporal_patchlet_points, -2), dim=-1)\n",
        "            elif self.downsample_method == 'mean_var_t':\n",
        "                patchlet_variance = torch.linalg.norm(torch.var(torch.mean(patchlet_points.reshape(b, t, n, self.k, d), -2), 1), dim=-1)\n",
        "            else:\n",
        "                raise ValueError(\"downsample method not supported \")\n",
        "            _, selected_idxs = torch.topk(patchlet_variance, self.npoints)\n",
        "            selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, self.npoints)\n",
        "            patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "            patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "            distances = utils.index_points(distances, selected_idxs)\n",
        "            idxs = utils.index_points(idxs, selected_idxs)\n",
        "            patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "            n = self.npoints\n",
        "\n",
        "\n",
        "        # reshape all to bxtxnxk\n",
        "        distances, idxs = distances.reshape(b, t, n, self.k), idxs.reshape(b, t, n, self.k)\n",
        "        patchlets, patchlet_points = patchlets.reshape(b, t, n, self.k), patchlet_points.reshape(b, t, n, self.k, d)\n",
        "        patchlet_feats = patchlet_feats.reshape(b, t, n, self.k, d_feat)\n",
        "\n",
        "        normalized_patchlet_points = patchlet_points - patchlet_points[:, 0, :, [0], :].unsqueeze(1).detach() # normalize the patchlet around the center point of the first frame\n",
        "        patchlet_feats = torch.cat([patchlet_feats, normalized_patchlet_points], -1)\n",
        "\n",
        "        return {'idx': idxs, 'distances': distances, 'patchlets': patchlets,\n",
        "                'patchlet_points': patchlet_points, 'patchlet_feats': patchlet_feats,\n",
        "                'normalized_patchlet_points': normalized_patchlet_points, 'fps_idx': fps_idx,\n",
        "                'x_current': out_x.reshape(b, t, n_out, d)}\n",
        "\n",
        "\n",
        "\n",
        "class TPatchExtractorBidirectional(nn.Module):\n",
        "    def __init__(self, k=16, sample_mode='nn', npoints=None, add_centroid_jitter=None, downsample_method=None,\n",
        "                 radius=None, temporal_stride=8):\n",
        "        super(TPatchExtractorBidirectional, self).__init__()\n",
        "        self.k = k\n",
        "        self.radius = radius\n",
        "        self.sample_mode = sample_mode\n",
        "        self.downsample_method = downsample_method\n",
        "        self.npoints = npoints\n",
        "        self.add_centroid_jitter = add_centroid_jitter\n",
        "        self.res = faiss.StandardGpuResources()\n",
        "        self.res.setDefaultNullStreamAllDevices()\n",
        "\n",
        "    # def get_tpatches(self, x1, x2, feat_seq, flip=False):\n",
        "    #\n",
        "    #     b, t, n, d = x1.shape\n",
        "    #     n_out = n\n",
        "    #\n",
        "    #     if feat_seq is None:\n",
        "    #         feat_seq = x1\n",
        "    #         d_feat = d\n",
        "    #     else:\n",
        "    #         d_feat = feat_seq.shape[-1]\n",
        "    #\n",
        "    #     out_x = torch.empty(b, t, n_out, d)\n",
        "    #     patchlets = torch.empty(b, t, n, self.k, device=x1.device, dtype=torch.long)\n",
        "    #     distances_i = torch.empty(b, t, n, self.k, device=x1.device)\n",
        "    #     idxs_i = torch.empty(b, t, n, self.k, device=x1.device, dtype=torch.long)\n",
        "    #     patchlet_points = torch.empty(b, t, n, self.k, d, device=x1.device)\n",
        "    #     patchlet_feats = torch.empty(b, t, n, self.k, d_feat, device=x1.device)\n",
        "    #\n",
        "    #     # loop over the data to reorder the indices to form the patchlets\n",
        "    #     x_current = x2[:, 0]\n",
        "    #     feat_seq_2 = torch.cat([feat_seq[:, [0]], feat_seq], dim=1)[:, :-1]\n",
        "    #     for i in range(0, t):\n",
        "    #         x_next = x1[:, i]\n",
        "    #         distances, idxs = get_knn(x_current[..., 0:3], x_next[..., 0:3], k=self.k, res=self.res, method='keops',\n",
        "    #                                   radius=self.radius)\n",
        "    #         if self.sample_mode == 'nn':\n",
        "    #             x_current = utils.index_points(x_next, idxs)[:, :, 0, :]\n",
        "    #         elif self.sample_mode == 'randn':\n",
        "    #             rand_idx = torch.randint(self.k, (b, n, 1), device=x_next.device, dtype=torch.int64).repeat(\n",
        "    #                 [1, 1, 3]).unsqueeze(2)\n",
        "    #             x_current = torch.gather(utils.index_points(x_next, idxs).squeeze(), dim=2, index=rand_idx).squeeze()\n",
        "    #         elif self.sample_mode == 'gt':\n",
        "    #             # only works when point correspondence is known and points are already aligned\n",
        "    #             # if self.downsample_method == 'fps':\n",
        "    #             #     x_current = utils.index_points(x_next, fps_idx).contiguous()\n",
        "    #             # else:\n",
        "    #             x_current = x_next\n",
        "    #         else:\n",
        "    #             raise ValueError(\"sample mode not supported\")\n",
        "    #\n",
        "    #         out_x[:, i] = x_current\n",
        "    #         if self.add_centroid_jitter is not None  and not self.sample_mode == 'gt':\n",
        "    #             x_current = x_current + self.add_centroid_jitter * torch.randn_like(x_current)\n",
        "    #\n",
        "    #         distances_i[:, i], idxs_i[:, i] = distances, idxs\n",
        "    #         patchlets[:, i] = idxs_i[:, i]\n",
        "    #         patchlet_points[:, i] = utils.index_points(x_next, idxs).squeeze()\n",
        "    #         patchlet_feats[:, i] = utils.index_points(feat_seq_2[:, i], idxs).squeeze()\n",
        "    #\n",
        "    #     distances = distances_i\n",
        "    #     idxs = idxs_i\n",
        "    #     if flip: # reverse temporal order\n",
        "    #         patchlet_feats = torch.flip(patchlet_feats, [1])\n",
        "    #         patchlet_points = torch.flip(patchlet_points, [1])\n",
        "    #         idxs = torch.flip(idxs, [1])\n",
        "    #         distances = torch.flip(distances, [1])\n",
        "    #         patchlets = torch.flip(patchlets, [1])\n",
        "    #\n",
        "    #     patchlet_feats = patchlet_feats.reshape(b * t, n, self.k, d_feat)\n",
        "    #     patchlet_points = patchlet_points.reshape(b * t, n, self.k, d)\n",
        "    #     idxs = idxs.reshape(b * t, n, self.k)\n",
        "    #     distances = distances.reshape(b * t, n, self.k)\n",
        "    #     patchlets = patchlets.reshape(b * t, n, self.k)\n",
        "    #\n",
        "    #     fps_idx = None\n",
        "    #     if self.downsample_method == 'fps':\n",
        "    #         # select a subset of the points using fps for maximum coverage\n",
        "    #         selected_idxs = utils.farthest_point_sample(x1[:, 0].contiguous(), self.npoints).to(torch.int64)\n",
        "    #         selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, self.npoints)\n",
        "    #         patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "    #         patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "    #         distances = utils.index_points(distances, selected_idxs)\n",
        "    #         idxs = utils.index_points(idxs, selected_idxs)\n",
        "    #         patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "    #         n = self.npoints\n",
        "    #     elif self.downsample_method == 'var' or self.downsample_method == 'mean_var_t':\n",
        "    #         # select a subset of the points with the largest point variance for maximum temporal movement\n",
        "    #         if self.downsample_method == 'var':\n",
        "    #             temporal_patchlet_points = patchlet_points.reshape(b, t, n, self.k, d).\\\n",
        "    #                 permute(0, 2, 1, 3, 4).reshape(b, n,-1, d)\n",
        "    #             patchlet_variance = torch.linalg.norm(torch.var(temporal_patchlet_points, -2), dim=-1)\n",
        "    #         elif self.downsample_method == 'mean_var_t':\n",
        "    #             patchlet_variance = torch.linalg.norm(\n",
        "    #                 torch.var(torch.mean(patchlet_points.reshape(b, t, n, self.k, d), -2), 1), dim=-1)\n",
        "    #         else:\n",
        "    #             raise ValueError(\"downsample method not supported \")\n",
        "    #         _, selected_idxs = torch.topk(patchlet_variance, self.npoints)\n",
        "    #         selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, self.npoints)\n",
        "    #         patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "    #         patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "    #         distances = utils.index_points(distances, selected_idxs)\n",
        "    #         idxs = utils.index_points(idxs, selected_idxs)\n",
        "    #         patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "    #         n = self.npoints\n",
        "    #\n",
        "    #     return patchlet_points, patchlet_feats, distances, idxs, patchlets, n, d_feat, fps_idx, out_x\n",
        "\n",
        "    def forward(self, point_seq, feat_seq=None):\n",
        "        b, t, n, d = point_seq.shape\n",
        "        n_original = n\n",
        "        n_out = n\n",
        "\n",
        "        # forward patchlets\n",
        "        x1 = point_seq\n",
        "        x2 = torch.cat([point_seq[:, [0]], point_seq], dim=1)[:, :-1]\n",
        "        patchlet_points1, patchlet_feats1, distances1, idxs1, patchlets1, n, d_feat, fps_idx, out_x1 = \\\n",
        "            get_tpatches(x1, x2, feat_seq, flip=False,\n",
        "                              k=self.k, radius=self.radius, res=self.res, sample_mode=self.sample_mode,\n",
        "                              add_centroid_jitter=self.add_centroid_jitter,\n",
        "                              downsample_method=self.downsample_method, npoints=self.npoints )\n",
        "\n",
        "        #backward patchlets\n",
        "        x1 = torch.flip(point_seq, [1])\n",
        "        x2 = torch.cat([x1[:, [0]], x1], dim=1)[:, :-1]\n",
        "        patchlet_points2, patchlet_feats2, distances2, idxs2, patchlets2, _, _, fps_idx2, out_x2 = \\\n",
        "            get_tpatches(x1, x2, feat_seq, flip=True,\n",
        "                              k=self.k, radius=self.radius, res=self.res, sample_mode=self.sample_mode,\n",
        "                              add_centroid_jitter=self.add_centroid_jitter,\n",
        "                              downsample_method=self.downsample_method, npoints=self.npoints )\n",
        "\n",
        "        # randomly select a subset\n",
        "        rand_idxs = torch.randperm(n)[:int(n/2)]\n",
        "        patchlets = torch.cat([patchlets1[:, rand_idxs, :], patchlets2[:, rand_idxs, :]], 1)\n",
        "        patchlet_feats = torch.cat([patchlet_feats1[:, rand_idxs, :], patchlet_feats2[:, rand_idxs, :]], 1)\n",
        "        patchlet_points = torch.cat([patchlet_points1[:, rand_idxs, :], patchlet_points2[:, rand_idxs, :]], 1)\n",
        "        distances = torch.cat([distances1[:, rand_idxs, :], distances2[:, rand_idxs, :]], 1)\n",
        "        idxs = torch.cat([idxs1[:, rand_idxs, :], idxs2[:, rand_idxs, :]], 1)\n",
        "        out_x = out_x1 # remove after debug, out_x is unused\n",
        "\n",
        "        # reshape all to bxtxnxk\n",
        "        distances, idxs = distances.reshape(b, t, n, self.k), idxs.reshape(b, t, n, self.k)\n",
        "        patchlets, patchlet_points = patchlets.reshape(b, t, n, self.k), patchlet_points.reshape(b, t, n, self.k, d)\n",
        "        patchlet_feats = patchlet_feats.reshape(b, t, n, self.k, d_feat)\n",
        "\n",
        "        normalized_patchlet_points = patchlet_points - patchlet_points[:, 0, :, [0], :].unsqueeze(1).detach() # normalize the patchlet around the center point of the first frame\n",
        "        patchlet_feats = torch.cat([patchlet_feats, normalized_patchlet_points], -1)\n",
        "\n",
        "        return {'idx': idxs, 'distances': distances, 'patchlets': patchlets,\n",
        "                'patchlet_points': patchlet_points, 'patchlet_feats': patchlet_feats,\n",
        "                'normalized_patchlet_points': normalized_patchlet_points, 'fps_idx': fps_idx,\n",
        "                'x_current': out_x.reshape(b, t, n_out, d)}\n",
        "\n",
        "\n",
        "\n",
        "class TPatchExtractorStrided(nn.Module):\n",
        "    def __init__(self, k=16, sample_mode='nn', npoints=None, add_centroid_jitter=None, downsample_method=None,\n",
        "                 radius=None, temporal_stride=8):\n",
        "        super(TPatchExtractorStrided, self).__init__()\n",
        "        self.k = k\n",
        "        self.radius = radius\n",
        "        self.sample_mode = sample_mode\n",
        "        self.downsample_method = downsample_method\n",
        "        self.npoints = npoints\n",
        "        self.add_centroid_jitter = add_centroid_jitter\n",
        "        self.res = faiss.StandardGpuResources()\n",
        "        self.res.setDefaultNullStreamAllDevices()\n",
        "        self.temporal_stride = temporal_stride\n",
        "\n",
        "    # def get_tpatches(self, x1, x2, feat_seq, flip=False):\n",
        "    #\n",
        "    #     b, t, n, d = x1.shape\n",
        "    #     n_out = n\n",
        "    #\n",
        "    #     if feat_seq is None:\n",
        "    #         feat_seq = x1\n",
        "    #         d_feat = d\n",
        "    #     else:\n",
        "    #         d_feat = feat_seq.shape[-1]\n",
        "    #\n",
        "    #     out_x = torch.empty(b, t, n_out, d)\n",
        "    #     patchlets = torch.empty(b, t, n, self.k, device=x1.device, dtype=torch.long)\n",
        "    #     distances_i = torch.empty(b, t, n, self.k, device=x1.device)\n",
        "    #     idxs_i = torch.empty(b, t, n, self.k, device=x1.device, dtype=torch.long)\n",
        "    #     patchlet_points = torch.empty(b, t, n, self.k, d, device=x1.device)\n",
        "    #     patchlet_feats = torch.empty(b, t, n, self.k, d_feat, device=x1.device)\n",
        "    #\n",
        "    #     # loop over the data to reorder the indices to form the patchlets\n",
        "    #     x_current = x2[:, 0]\n",
        "    #     feat_seq_2 = torch.cat([feat_seq[:, [0]], feat_seq], dim=1)[:, :-1]\n",
        "    #     for i in range(0, t):\n",
        "    #         x_next = x1[:, i]\n",
        "    #         distances, idxs = get_knn(x_current[..., 0:3], x_next[..., 0:3], k=self.k, res=self.res, method='keops',\n",
        "    #                                   radius=self.radius)\n",
        "    #         if self.sample_mode == 'nn':\n",
        "    #             x_current = utils.index_points(x_next, idxs)[:, :, 0, :]\n",
        "    #         elif self.sample_mode == 'randn':\n",
        "    #             rand_idx = torch.randint(self.k, (b, n, 1), device=x_next.device, dtype=torch.int64).repeat(\n",
        "    #                 [1, 1, 3]).unsqueeze(2)\n",
        "    #             x_current = torch.gather(utils.index_points(x_next, idxs).squeeze(), dim=2, index=rand_idx).squeeze()\n",
        "    #         elif self.sample_mode == 'gt':\n",
        "    #             # only works when point correspondence is known and points are already aligned\n",
        "    #             # if self.downsample_method == 'fps':\n",
        "    #             #     x_current = utils.index_points(x_next, fps_idx).contiguous()\n",
        "    #             # else:\n",
        "    #             x_current = x_next\n",
        "    #         else:\n",
        "    #             raise ValueError(\"sample mode not supported\")\n",
        "    #\n",
        "    #         out_x[:, i] = x_current\n",
        "    #         if self.add_centroid_jitter is not None  and not self.sample_mode == 'gt':\n",
        "    #             x_current = x_current + self.add_centroid_jitter * torch.randn_like(x_current)\n",
        "    #\n",
        "    #         distances_i[:, i], idxs_i[:, i] = distances, idxs\n",
        "    #         patchlets[:, i] = idxs_i[:, i]\n",
        "    #         patchlet_points[:, i] = utils.index_points(x_next, idxs).squeeze()\n",
        "    #         patchlet_feats[:, i] = utils.index_points(feat_seq_2[:, i], idxs).squeeze()\n",
        "    #\n",
        "    #     distances = distances_i\n",
        "    #     idxs = idxs_i\n",
        "    #     if flip: # reverse temporal order\n",
        "    #         patchlet_feats = torch.flip(patchlet_feats, [1])\n",
        "    #         patchlet_points = torch.flip(patchlet_points, [1])\n",
        "    #         idxs = torch.flip(idxs, [1])\n",
        "    #         distances = torch.flip(distances, [1])\n",
        "    #         patchlets = torch.flip(patchlets, [1])\n",
        "    #\n",
        "    #     patchlet_feats = patchlet_feats.reshape(b * t, n, self.k, d_feat)\n",
        "    #     patchlet_points = patchlet_points.reshape(b * t, n, self.k, d)\n",
        "    #     idxs = idxs.reshape(b * t, n, self.k)\n",
        "    #     distances = distances.reshape(b * t, n, self.k)\n",
        "    #     patchlets = patchlets.reshape(b * t, n, self.k)\n",
        "    #\n",
        "    #     fps_idx = None\n",
        "    #     if self.downsample_method == 'fps':\n",
        "    #         # select a subset of the points using fps for maximum coverage\n",
        "    #         selected_idxs = utils.farthest_point_sample(x1[:, 0].contiguous(), self.npoints).to(torch.int64)\n",
        "    #         selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, self.npoints)\n",
        "    #         patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "    #         patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "    #         distances = utils.index_points(distances, selected_idxs)\n",
        "    #         idxs = utils.index_points(idxs, selected_idxs)\n",
        "    #         patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "    #         n = self.npoints\n",
        "    #     elif self.downsample_method == 'var' or self.downsample_method == 'mean_var_t':\n",
        "    #         # select a subset of the points with the largest point variance for maximum temporal movement\n",
        "    #         if self.downsample_method == 'var':\n",
        "    #             temporal_patchlet_points = patchlet_points.reshape(b, t, n, self.k, d).\\\n",
        "    #                 permute(0, 2, 1, 3, 4).reshape(b, n,-1, d)\n",
        "    #             patchlet_variance = torch.linalg.norm(torch.var(temporal_patchlet_points, -2), dim=-1)\n",
        "    #         elif self.downsample_method == 'mean_var_t':\n",
        "    #             patchlet_variance = torch.linalg.norm(\n",
        "    #                 torch.var(torch.mean(patchlet_points.reshape(b, t, n, self.k, d), -2), 1), dim=-1)\n",
        "    #         else:\n",
        "    #             raise ValueError(\"downsample method not supported \")\n",
        "    #         _, selected_idxs = torch.topk(patchlet_variance, self.npoints)\n",
        "    #         selected_idxs = selected_idxs.unsqueeze(1).repeat([1, t, 1]).reshape(-1, self.npoints)\n",
        "    #         patchlet_points = utils.index_points(patchlet_points, selected_idxs)\n",
        "    #         patchlet_feats = utils.index_points(patchlet_feats, selected_idxs)\n",
        "    #         distances = utils.index_points(distances, selected_idxs)\n",
        "    #         idxs = utils.index_points(idxs, selected_idxs)\n",
        "    #         patchlets = utils.index_points(patchlets, selected_idxs)\n",
        "    #         n = self.npoints\n",
        "    #\n",
        "    #     return patchlet_points, patchlet_feats, distances, idxs, patchlets, n, d_feat, fps_idx, out_x\n",
        "\n",
        "    def forward(self, point_seq, feat_seq=None):\n",
        "        b, t, n, d = point_seq.shape\n",
        "        n_original = n\n",
        "        n_out = n\n",
        "\n",
        "        assert t % self.temporal_stride == 0\n",
        "        n_temporal_segments = int(t / self.temporal_stride)\n",
        "        patchlets_accum, patchlet_points_accum, patchlet_feats_accum, distances_accum,\\\n",
        "            idxs_accum, out_x_accum = [], [], [], [], [], []\n",
        "        for i in range(n_temporal_segments):\n",
        "            x1 = point_seq[:, i*self.temporal_stride:(i+1)*self.temporal_stride]\n",
        "            x2 = torch.cat([x1[:, [0]], x1], dim=1)[:, :-1]\n",
        "            feats = feat_seq[:, i*self.temporal_stride:(i+1)*self.temporal_stride] if feat_seq is not None else None\n",
        "            patchlet_points, patchlet_feats, distances, idxs, patchlets, n, d_feat, fps_idx, out_x = \\\n",
        "                get_tpatches(x1, x2, feats, flip=False,\n",
        "                              k=self.k, radius=self.radius, res=self.res, sample_mode=self.sample_mode,\n",
        "                              add_centroid_jitter=self.add_centroid_jitter,\n",
        "                              downsample_method=self.downsample_method, npoints=self.npoints )\n",
        "\n",
        "            #bidirectional\n",
        "            x1 = torch.flip(x1, [1])\n",
        "            x2 = torch.cat([x1[:, [0]], x1], dim=1)[:, :-1]\n",
        "            patchlet_points2, patchlet_feats2, distances2, idxs2, patchlets2, _, _, fps_idx2, out_x2 = \\\n",
        "                get_tpatches(x1, x2, feat_seq, flip=True,\n",
        "                              k=self.k, radius=self.radius, res=self.res, sample_mode=self.sample_mode,\n",
        "                              add_centroid_jitter=self.add_centroid_jitter,\n",
        "                              downsample_method=self.downsample_method, npoints=self.npoints )\n",
        "\n",
        "            # randomly select a subset\n",
        "            rand_idxs = torch.randperm(n)[:int(n / 2)]\n",
        "            patchlets = torch.cat([patchlets[:, rand_idxs, :], patchlets2[:, rand_idxs, :]], 1)\n",
        "            patchlet_feats = torch.cat([patchlet_feats[:, rand_idxs, :], patchlet_feats2[:, rand_idxs, :]], 1)\n",
        "            patchlet_points = torch.cat([patchlet_points[:, rand_idxs, :], patchlet_points2[:, rand_idxs, :]], 1)\n",
        "            distances = torch.cat([distances[:, rand_idxs, :], distances2[:, rand_idxs, :]], 1)\n",
        "            idxs = torch.cat([idxs[:, rand_idxs, :], idxs2[:, rand_idxs, :]], 1)\n",
        "            out_x = out_x  # remove after debug, out_x is unused\n",
        "\n",
        "            patchlets_accum.append(patchlets.reshape(b, self.temporal_stride, n, self.k))\n",
        "            patchlet_points_accum.append(patchlet_points.reshape(b, self.temporal_stride, n, self.k, d))\n",
        "            patchlet_feats_accum.append(patchlet_feats.reshape(b, self.temporal_stride, n, self.k, d_feat))\n",
        "            distances_accum.append(distances.reshape(b, self.temporal_stride, n, self.k))\n",
        "            idxs_accum.append(idxs.reshape(b, self.temporal_stride, n, self.k))\n",
        "            out_x_accum.append(out_x.reshape(b, self.temporal_stride, n_original, d))\n",
        "\n",
        "        patchlets = torch.cat(patchlets_accum, 1)\n",
        "        patchlet_points = torch.cat(patchlet_points_accum, 1)\n",
        "        patchlet_feats = torch.cat(patchlet_feats_accum, 1)\n",
        "        distances = torch.cat(distances_accum, 1)\n",
        "        idxs = torch.cat(idxs_accum, 1)\n",
        "        out_x = torch.cat(out_x_accum, 1)\n",
        "\n",
        "        normalized_patchlet_points = patchlet_points.detach().clone()\n",
        "        for i in range(n_temporal_segments):\n",
        "            normalized_patchlet_points[:, i*self.temporal_stride:(i+1)*self.temporal_stride] -= \\\n",
        "                normalized_patchlet_points[:, i * self.temporal_stride, :, [0], :].unsqueeze(1).detach()\n",
        "        patchlet_feats = torch.cat([patchlet_feats, normalized_patchlet_points], -1)\n",
        "\n",
        "        return {'idx': idxs, 'distances': distances, 'patchlets': patchlets,\n",
        "                'patchlet_points': patchlet_points, 'patchlet_feats': patchlet_feats,\n",
        "                'normalized_patchlet_points': normalized_patchlet_points, 'fps_idx': fps_idx,\n",
        "                'x_current': out_x.reshape(b, t, n_out, d)}\n",
        "\n",
        "\n",
        "\n",
        "class TPatchExtractorModStrided(nn.Module):\n",
        "    def __init__(self, k=16, sample_mode='nn', npoints=None, add_centroid_jitter=None, downsample_method=None,\n",
        "                 radius=None, temporal_stride=8):\n",
        "        super(TPatchExtractorModStrided, self).__init__()\n",
        "        self.k = k\n",
        "        self.radius = radius\n",
        "        self.sample_mode = sample_mode\n",
        "        self.downsample_method = downsample_method\n",
        "        self.npoints = npoints\n",
        "        self.add_centroid_jitter = add_centroid_jitter\n",
        "        self.res = faiss.StandardGpuResources()\n",
        "        self.res.setDefaultNullStreamAllDevices()\n",
        "        self.temporal_stride = temporal_stride\n",
        "    def forward(self, point_seq, feat_seq=None):\n",
        "        b, t, n, d = point_seq.shape\n",
        "        n_original = n\n",
        "        n_out = n\n",
        "\n",
        "        distances, idxs = get_knn(point_seq[..., n, 0:3], point_seq[..., n, 0:3], k=self.k, res=self.res, method='keops',\n",
        "                                  radius=self.radius)\n",
        "        point_patches = utils.index_points(point_seq, idxs)[:, :, 0, :]\n",
        "\n",
        "        # assert t % self.temporal_stride == 0\n",
        "        # n_temporal_segments = int(t / self.temporal_stride)\n",
        "        # patchlets_accum, patchlet_points_accum, patchlet_feats_accum, distances_accum,\\\n",
        "        #     idxs_accum, out_x_accum = [], [], [], [], [], []\n",
        "        # for i in range(n_temporal_segments):\n",
        "        #     x1 = point_seq[:, i*self.temporal_stride:(i+1)*self.temporal_stride]\n",
        "        #     x2 = torch.cat([x1[:, [0]], x1], dim=1)[:, :-1]\n",
        "        #     feats = feat_seq[:, i*self.temporal_stride:(i+1)*self.temporal_stride] if feat_seq is not None else None\n",
        "        #     patchlet_points, patchlet_feats, distances, idxs, patchlets, n, d_feat, fps_idx, out_x = \\\n",
        "        #         get_tpatches(x1, x2, feats, flip=False,\n",
        "        #                       k=self.k, radius=self.radius, res=self.res, sample_mode=self.sample_mode,\n",
        "        #                       add_centroid_jitter=self.add_centroid_jitter,\n",
        "        #                       downsample_method=self.downsample_method, npoints=self.npoints )\n",
        "        #\n",
        "        #     #bidirectional\n",
        "        #     x1 = torch.flip(x1, [1])\n",
        "        #     x2 = torch.cat([x1[:, [0]], x1], dim=1)[:, :-1]\n",
        "        #     patchlet_points2, patchlet_feats2, distances2, idxs2, patchlets2, _, _, fps_idx2, out_x2 = \\\n",
        "        #         get_tpatches(x1, x2, feat_seq, flip=True,\n",
        "        #                       k=self.k, radius=self.radius, res=self.res, sample_mode=self.sample_mode,\n",
        "        #                       add_centroid_jitter=self.add_centroid_jitter,\n",
        "        #                       downsample_method=self.downsample_method, npoints=self.npoints )\n",
        "        #\n",
        "        #     # randomly select a subset\n",
        "        #     rand_idxs = torch.randperm(n)[:int(n / 2)]\n",
        "        #     patchlets = torch.cat([patchlets[:, rand_idxs, :], patchlets2[:, rand_idxs, :]], 1)\n",
        "        #     patchlet_feats = torch.cat([patchlet_feats[:, rand_idxs, :], patchlet_feats2[:, rand_idxs, :]], 1)\n",
        "        #     patchlet_points = torch.cat([patchlet_points[:, rand_idxs, :], patchlet_points2[:, rand_idxs, :]], 1)\n",
        "        #     distances = torch.cat([distances[:, rand_idxs, :], distances2[:, rand_idxs, :]], 1)\n",
        "        #     idxs = torch.cat([idxs[:, rand_idxs, :], idxs2[:, rand_idxs, :]], 1)\n",
        "        #     out_x = out_x  # remove after debug, out_x is unused\n",
        "        #\n",
        "        #     patchlets_accum.append(patchlets.reshape(b, self.temporal_stride, n, self.k))\n",
        "        #     patchlet_points_accum.append(patchlet_points.reshape(b, self.temporal_stride, n, self.k, d))\n",
        "        #     patchlet_feats_accum.append(patchlet_feats.reshape(b, self.temporal_stride, n, self.k, d_feat))\n",
        "        #     distances_accum.append(distances.reshape(b, self.temporal_stride, n, self.k))\n",
        "        #     idxs_accum.append(idxs.reshape(b, self.temporal_stride, n, self.k))\n",
        "        #     out_x_accum.append(out_x.reshape(b, self.temporal_stride, n_original, d))\n",
        "        #\n",
        "        # patchlets = torch.cat(patchlets_accum, 1)\n",
        "        # patchlet_points = torch.cat(patchlet_points_accum, 1)\n",
        "        # patchlet_feats = torch.cat(patchlet_feats_accum, 1)\n",
        "        # distances = torch.cat(distances_accum, 1)\n",
        "        # idxs = torch.cat(idxs_accum, 1)\n",
        "        # out_x = torch.cat(out_x_accum, 1)\n",
        "        #\n",
        "        # normalized_patchlet_points = patchlet_points.detach().clone()\n",
        "        # for i in range(n_temporal_segments):\n",
        "        #     normalized_patchlet_points[:, i*self.temporal_stride:(i+1)*self.temporal_stride] -= \\\n",
        "        #         normalized_patchlet_points[:, i * self.temporal_stride, :, [0], :].unsqueeze(1).detach()\n",
        "        # patchlet_feats = torch.cat([patchlet_feats, normalized_patchlet_points], -1)\n",
        "\n",
        "        return {'idx': idxs, 'distances': distances, 'patchlets': patchlets,\n",
        "                'patchlet_points': patchlet_points, 'patchlet_feats': patchlet_feats,\n",
        "                'normalized_patchlet_points': normalized_patchlet_points, 'fps_idx': fps_idx,\n",
        "                'x_current': out_x.reshape(b, t, n_out, d)}\n",
        "                \"\"\"\n",
        "\n",
        "# Modify extractors.py.\n",
        "with open('../models/extractors.py', 'w') as python_file:\n",
        "  python_file.writelines(extractors_py)"
      ],
      "metadata": {
        "id": "iKnfMgr1QNq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run_MSR-Action3D_experiment.sh"
      ],
      "metadata": {
        "id": "DCifh33EPQ6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_MSR_Action3D_experiment_script = \"\"\"\n",
        "#!/usr/bin/env bash\n",
        "\n",
        "GPU_IDX=0\n",
        "export CUDA_DEVICE_ORDER=\"PCI_BUS_ID\"\n",
        "export CUDA_VISIBLE_DEVICES=$GPU_IDX\n",
        "\n",
        "IDENTIFIER='debug'\n",
        "CONFIG='configs/msr-action3d/config_msr_action3d.yaml'\n",
        "LOGDIR='./log/'\n",
        "\n",
        "python train.py --identifier $IDENTIFIER --config $CONFIG --logdir $LOGDIR --fix_random_seed\n",
        "# python test.py --identifier $IDENTIFIER --model_ckpt '000200.pt' --logdir $LOGDIR --fix_random_seed\n",
        "# python ./evaluate.py --identifier $IDENTIFIER --logdir $LOGDIR\n",
        "\"\"\"\n",
        "\n",
        "with open('../run_MSR-Action3D_experiment.sh', 'w') as python_file:\n",
        "  python_file.writelines(run_MSR_Action3D_experiment_script)\n",
        "\n",
        "# Move up to the parent directory.\n",
        "change_directory('..')"
      ],
      "metadata": {
        "id": "DNebv0atKbHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Python Packages"
      ],
      "metadata": {
        "id": "ZgJFA2exdHIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja faiss-gpu faiss-cpu pykeops wandb"
      ],
      "metadata": {
        "id": "xnxiaeJVMWd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70f8ec31-cde8-47d0-c7ac-557304234f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pykeops\n",
            "  Downloading pykeops-2.2.3.tar.gz (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Collecting pybind11 (from pykeops)\n",
            "  Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keopscore==2.2.3 (from pykeops)\n",
            "  Downloading keopscore-2.2.3.tar.gz (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pykeops, keopscore\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykeops: filename=pykeops-2.2.3-py3-none-any.whl size=118640 sha256=2f66935d22791ce5d330f7419eb54e9d5129ec61d8a633b9260d73197e7a58be\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/8b/c7/25e5194a7138fd564c3ef3e275ae0155c207cd85d7ab347817\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keopscore: filename=keopscore-2.2.3-py3-none-any.whl size=172486 sha256=6c772d734e0a762b29e6e2fb131db4b4a78ad7b16d78f00a567867c5d070d11e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/d8/ee/29900acfbbd7ee0f3b05981d3d172baad4c3b5d40cbf4c5d74\n",
            "Successfully built pykeops keopscore\n",
            "Installing collected packages: ninja, faiss-gpu, smmap, setproctitle, sentry-sdk, pybind11, keopscore, faiss-cpu, docker-pycreds, pykeops, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 faiss-cpu-1.8.0 faiss-gpu-1.7.2 gitdb-4.0.11 keopscore-2.2.3 ninja-1.11.1.1 pybind11-2.12.0 pykeops-2.2.3 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train.py"
      ],
      "metadata": {
        "id": "QTEYYF1whWKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "change_directory('/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction')"
      ],
      "metadata": {
        "id": "Y_5UFxWvWDs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_py = \"\"\"\n",
        "# Author: Yizhak Ben-Shabat (Itzik), 2022\n",
        "# train 3DInAction\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "import argparse\n",
        "import i3d_utils as utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from models.pointnet import feature_transform_regularizer\n",
        "from models import build_model\n",
        "from datasets import build_dataloader\n",
        "\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--logdir', type=str, default='./log/', help='path to model save dir')\n",
        "parser.add_argument('--identifier', type=str, default='debug', help='unique run identifier')\n",
        "parser.add_argument('--config', type=str, default='./configs/dfaust/config_dfaust.yaml', help='path to yaml config file')\n",
        "parser.add_argument('--fix_random_seed', action='store_true', default=False, help='fix random seed')\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "def main():\n",
        "    cfg = yaml.safe_load(open(args.config))\n",
        "    logdir = os.path.join(args.logdir, args.identifier)\n",
        "    os.makedirs(logdir, exist_ok=True)\n",
        "\n",
        "    # TODO: move to cfg project_name, entity\n",
        "    if cfg['DATA'].get('name') == 'DFAUST':\n",
        "        project_name = 'DFAUST'\n",
        "    elif cfg['DATA'].get('name') == 'IKEA_EGO':\n",
        "        project_name = 'IKEA EGO'\n",
        "    elif cfg['DATA'].get('name') == 'IKEA_ASM':\n",
        "        project_name = 'IKEA ASM'\n",
        "    elif cfg['DATA'].get('name') == 'MSR-Action3D':\n",
        "        project_name = 'MSR-Action3D'\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    wandb_run = wandb.init(project=project_name, entity='mkjohn', save_code=True)\n",
        "    cfg['WANDB'] = {'id': wandb_run.id, 'project': wandb_run.project, 'entity': wandb_run.entity}\n",
        "\n",
        "    with open(os.path.join(logdir, 'config.yaml'), 'w') as outfile:\n",
        "        yaml.dump(cfg, outfile, default_flow_style=False)\n",
        "\n",
        "    wandb_run.name = args.identifier\n",
        "    wandb.config.update(cfg)  # adds all the arguments as config variables\n",
        "    wandb.run.log_code(\".\")\n",
        "    # define our custom x axis metric\n",
        "    wandb.define_metric(\"train/step\")\n",
        "    wandb.define_metric(\"train/*\", step_metric=\"train/step\")\n",
        "    wandb.define_metric(\"test/*\", step_metric=\"train/step\")\n",
        "\n",
        "    # need to add argparse\n",
        "    run(cfg, logdir)\n",
        "\n",
        "def run(cfg, logdir):\n",
        "    n_epochs = cfg['TRAINING']['n_epochs']\n",
        "    lr = cfg['TRAINING']['lr']\n",
        "    batch_size = cfg['TRAINING']['batch_size']\n",
        "    refine, refine_epoch = cfg['TRAINING']['refine'], cfg['TRAINING']['refine_epoch']\n",
        "    pretrained_model = cfg['TRAINING']['pretrained_model']\n",
        "    pc_model = cfg['MODEL']['pc_model']\n",
        "    frames_per_clip = cfg['DATA']['frames_per_clip']\n",
        "    num_steps_per_update = cfg['TRAINING']['steps_per_update']\n",
        "    save_every = cfg['save_every']\n",
        "\n",
        "    if args.fix_random_seed:\n",
        "        seed = cfg['seed']\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    os.system('cp \"%s\" \"%s\"' % (__file__, logdir))  # backup the current training file\n",
        "    os.makedirs(os.path.join(logdir, 'models'), exist_ok=True)\n",
        "    #os.system(\"cp '%s' '%s'\" % ('/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/models/*.py', os.path.join(logdir, 'models')))  # backup the models files\n",
        "\n",
        "    # build dataloader and dataset\n",
        "    train_dataloader, train_dataset = build_dataloader(config=cfg, training=True, shuffle=False) # should be unshuffled because of sampler\n",
        "    test_dataloader, test_dataset = build_dataloader(config=cfg, training=False, shuffle=True)\n",
        "\n",
        "    num_classes = train_dataset.num_classes\n",
        "\n",
        "    # build model\n",
        "    model = build_model(cfg['MODEL'], num_classes, frames_per_clip)\n",
        "\n",
        "    if pretrained_model is not None:\n",
        "        checkpoints = torch.load(pretrained_model)\n",
        "        model.load_state_dict(checkpoints[\"model_state_dict\"])  # load trained model\n",
        "        model.replace_logits(num_classes)\n",
        "\n",
        "    if refine:\n",
        "        if refine_epoch == 0:\n",
        "            raise ValueError(\"You set the refine epoch to 0. No need to refine, just retrain.\")\n",
        "        refine_model_filename = os.path.join(logdir, str(refine_epoch).zfill(6)+'.pt')\n",
        "        checkpoint = torch.load(refine_model_filename)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "    model.cuda()\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "    best_model_trained_yet_and_its_accuracy = [None, 51.25]\n",
        "\n",
        "    # define optimizer and scheduler\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1E-6)\n",
        "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)\n",
        "\n",
        "    if refine:\n",
        "        lr_sched.load_state_dict(checkpoint[\"lr_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "    steps = 0\n",
        "    n_examples = 0\n",
        "    train_num_batch = len(train_dataloader)\n",
        "    test_num_batch = len(test_dataloader)\n",
        "    refine_flag = True\n",
        "\n",
        "    pbar = tqdm(total=n_epochs, desc='Training', dynamic_ncols=True)\n",
        "    pbar.update(refine_epoch)\n",
        "    while steps <= n_epochs:\n",
        "        if steps <= refine_epoch and refine and refine_flag:\n",
        "            # lr_sched.step()\n",
        "            steps += 1\n",
        "            n_examples += len(train_dataset.clip_set)\n",
        "            continue\n",
        "        else:\n",
        "            refine_flag = False\n",
        "        # Each epoch has a training and validation phase\n",
        "\n",
        "        test_batchind = -1\n",
        "        test_fraction_done = 0.0\n",
        "        test_enum = enumerate(test_dataloader, 0)\n",
        "        tot_loss = 0.0\n",
        "        tot_loc_loss = 0.0\n",
        "        tot_cls_loss = 0.0\n",
        "        num_iter = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Iterate over data.\n",
        "        avg_acc = []\n",
        "        loader_pbar = tqdm(total=len(train_dataloader), dynamic_ncols=True, leave=False)\n",
        "        for train_batchind, data in enumerate(train_dataloader):\n",
        "            num_iter += 1\n",
        "            # get the inputs\n",
        "            inputs = data[1]\n",
        "            labels = data[0]\n",
        "            # inputs, labels, vid_idx, frame_pad = data['inputs'], data['labels'], data['vid_idx'], data['frame_pad']\n",
        "            in_channel = cfg['MODEL'].get('in_channel', 3)\n",
        "            inputs = inputs[:, :, 0:in_channel, :]\n",
        "            inputs = inputs.cuda().requires_grad_().contiguous()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            out_dict = model(inputs)\n",
        "            per_frame_logits = out_dict['pred']\n",
        "\n",
        "            labels = labels.unsqueeze(1) + torch.zeros((per_frame_logits.shape[0], per_frame_logits.shape[2])).cuda()\n",
        "            labels = labels.to(dtype = torch.long)\n",
        "\n",
        "            # compute localization loss\n",
        "            loc_loss = F.cross_entropy(per_frame_logits, labels.to(dtype = torch.long))\n",
        "            tot_loc_loss += loc_loss.item()\n",
        "\n",
        "            # compute classification loss (with max-pooling along time dim1 x dim2)\n",
        "            cls_loss = F.cross_entropy(torch.max(per_frame_logits, dim=2)[0], torch.max(labels, dim=1)[0])\n",
        "            tot_cls_loss += cls_loss.item()\n",
        "            loss = (0.5 * loc_loss + 0.5 * cls_loss) / num_steps_per_update\n",
        "            if pc_model == 'pn1' or pc_model == 'pn1_4d_basic':\n",
        "                trans, trans_feat = out_dict['trans'], out_dict['trans_feat']\n",
        "                loss += 0.001 * feature_transform_regularizer(trans) + 0.001 * feature_transform_regularizer(trans_feat)\n",
        "\n",
        "            tot_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            acc = utils.accuracy_v2(torch.argmax(per_frame_logits, dim=1), labels)\n",
        "            avg_acc.append(acc.item())\n",
        "\n",
        "            train_fraction_done = (train_batchind + 1) / train_num_batch\n",
        "\n",
        "            if num_iter == num_steps_per_update or train_batchind == len(train_dataloader)-1:\n",
        "                n_steps = num_steps_per_update\n",
        "                if train_batchind == len(train_dataloader)-1:\n",
        "                    n_steps = num_iter\n",
        "                n_examples += batch_size*n_steps\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                # log train losses\n",
        "                log_dict = {\n",
        "                    \"train/step\": n_examples,\n",
        "                    \"train/loss\": tot_loss / n_steps,\n",
        "                    \"train/cls_loss\": tot_cls_loss / n_steps,\n",
        "                    \"train/loc_loss\": tot_loc_loss / n_steps,\n",
        "                    \"train/Accuracy\": np.mean(avg_acc),\n",
        "                    \"train/lr\":  optimizer.param_groups[0]['lr'],\n",
        "                    \"train/epoch\": steps,\n",
        "                }\n",
        "                wandb.log(log_dict)\n",
        "\n",
        "                num_iter = 0\n",
        "                tot_loss = 0.\n",
        "\n",
        "            if test_fraction_done <= train_fraction_done and test_batchind + 1 < test_num_batch:\n",
        "                model.eval()\n",
        "                test_batchind, data = next(test_enum)\n",
        "                inputs = data[1]\n",
        "                labels = data[0]\n",
        "                # inputs, labels, vid_idx, frame_pad = data['inputs'], data['labels'], data['vid_idx'], data['frame_pad']\n",
        "                in_channel = cfg['MODEL'].get('in_channel', 3)\n",
        "                inputs = inputs[:, :, 0:in_channel, :]\n",
        "                inputs = inputs.cuda().requires_grad_().contiguous()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out_dict = model(inputs)\n",
        "                    per_frame_logits = out_dict['pred']\n",
        "\n",
        "                    labels = labels.unsqueeze(1) + torch.zeros((per_frame_logits.shape[0], per_frame_logits.shape[2])).cuda()\n",
        "                    labels = labels.to(dtype = torch.long)\n",
        "\n",
        "                    # compute localization loss\n",
        "                    loc_loss = F.cross_entropy(per_frame_logits, labels)\n",
        "                    # compute classification loss (with max-pooling along time dim1 x dim2)\n",
        "                    cls_loss = F.cross_entropy(torch.max(per_frame_logits, dim=2)[0],\n",
        "                                                                  torch.max(labels, dim = 1)[0])\n",
        "                    loss = (0.5 * loc_loss + 0.5 * cls_loss) / num_steps_per_update\n",
        "                    if pc_model == 'pn1' or pc_model == 'pn1_4d_basic':\n",
        "                        trans, trans_feat = out_dict['trans'], out_dict['trans_feat']\n",
        "                        loss += (0.001 * feature_transform_regularizer(trans) +\n",
        "                                 0.001 * feature_transform_regularizer(trans_feat)) / num_steps_per_update\n",
        "                    acc = utils.accuracy_v2(torch.argmax(per_frame_logits, dim=1), labels)\n",
        "\n",
        "                log_dict = {\n",
        "                    \"test/step\": n_examples,\n",
        "                    \"test/loss\": loss.item(),\n",
        "                    \"test/cls_loss\": loc_loss.item(),\n",
        "                    \"test/loc_loss\": cls_loss.item(),\n",
        "                    \"test/Accuracy\": acc.item()\n",
        "                }\n",
        "                wandb.log(log_dict)\n",
        "                test_fraction_done = (test_batchind + 1) / test_num_batch\n",
        "                model.train()\n",
        "\n",
        "            loader_pbar.update()\n",
        "        loader_pbar.close()\n",
        "\n",
        "        if steps % save_every == 0 or steps == n_epochs:\n",
        "            # save model\n",
        "            torch.save({\"model_state_dict\": model.module.state_dict(),\n",
        "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                        \"lr_state_dict\": lr_sched.state_dict()},\n",
        "                       os.path.join(logdir, str(steps).zfill(6) + '.pt'))\n",
        "\n",
        "        steps += 1\n",
        "        lr_sched.step()\n",
        "        pbar.update()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\"\"\"\n",
        "with open('train.py', 'w') as python_file:\n",
        "  python_file.writelines(train_py)"
      ],
      "metadata": {
        "id": "GYssZGmHhXp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python models/setup.py install"
      ],
      "metadata": {
        "id": "l2Ctx3gzQadw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Experiment Using the MSR-Action3D Dataset"
      ],
      "metadata": {
        "id": "s4hjFRSUdK-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.chdir('/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/')"
      ],
      "metadata": {
        "id": "Yd66a6WxaYFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!./run_experiment.sh"
      ],
      "metadata": {
        "id": "O6Mj0LmEaQGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod u=rwx run_MSR-Action3D_experiment.sh"
      ],
      "metadata": {
        "id": "5KOC5CsQD7bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch -l\n",
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgZQYecLFldh",
        "outputId": "3d79b2c2-1051-4f84-d6d7-ae12c64d6a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mdev\u001b[m\n",
            "  dev-mathew\u001b[m\n",
            "* \u001b[32mdev\u001b[m\n",
            "  dev-mathew\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_MSR-Action3D_experiment.sh"
      ],
      "metadata": {
        "id": "zMAOqe4BK__7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ee22b5-8455-4fcc-a1ce-fd2e00612921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG\n",
            "DEBUG\n",
            "DEBUG\n",
            "DEBUG\n",
            "DEBUG-22\n",
            "DEBUG-27\n",
            "DEBUG-31\n",
            "DEBUG\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmkjohn\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/wandb/run-20240504_200630-3d11vv6l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mold-lightsaber-13\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mkjohn/MSR-Action3D\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mkjohn/MSR-Action3D/runs/3d11vv6l\u001b[0m\n",
            "Number of clips in the train set:1555\n",
            "Number of clips in the test set:1038\n",
            "Training:   0% 0/3000 [00:00<?, ?it/s]\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.84it/s]\u001b[A\n",
            "Training:  90% 2701/3000 [00:00<00:00, 7599.97it/s]\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  7.76it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  9.20it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  9.09it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Training:  98% 2950/3000 [00:20<00:00, 107.54it/s] \n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Training:  98% 2952/3000 [00:20<00:00, 106.84it/s]\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                         \u001b[A\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Training: 100% 3000/3000 [00:23<00:00, 126.47it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/Accuracy ▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁█▇▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/cls_loss ▆▆▇▇▃▃▆▄▅▆▅▁▆▆▃▃▅▄▅▅▂▅▆█▇▃▆▆▃▄▂▇▄▆▃▆█▇▄▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/loc_loss ▆▆▇█▄▄▆▄▅▆▅▁▆▆▃▄▅▄▅▅▂▅▆█▅▃▅▆▃▃▂▆▄▆▃▅▇█▄▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      test/loss ▆▆▇▇▄▄▆▄▅▆▅▁▆▆▃▃▅▄▅▅▂▅▆█▆▃▅▆▃▃▂▆▄▆▃▆▇▇▄▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      test/step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/Accuracy ▅▆▅█▇▄▄▂▃▅▆▃▅▃▅▃▅▄▅▁▂▆▄▅▆▆▂▂▆▅▅▄▃▁▂▆▃▂▃▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/cls_loss ▄▄▄▁▃▄▄▆▅▄▃▅▄▆▄▆▅▆▅▆▇▄▄▄▄▅▆▆▄▅▄▅▆▆█▅▅▆▆▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/loc_loss ▄▃▄▁▂▅▅▇▆▄▃▆▅▇▄▇▄▅▅█▇▄▄▄▃▄▇▇▃▅▄▆▆▇█▄▅▅▆▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/loss ▄▄▄▁▂▄▄▇▆▄▃▆▅▆▄▇▄▆▅▇▇▄▄▄▃▅▆▆▄▅▄▅▆▆█▅▅▅▆▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/lr ██▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/Accuracy 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/cls_loss 6.42009\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/loc_loss 6.22244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      test/loss 0.79016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      test/step 7013293\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/Accuracy 51.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/cls_loss 1.24224\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    train/epoch 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/loc_loss 1.29223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/loss 0.1584\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/lr 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/step 7013293\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mold-lightsaber-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mkjohn/MSR-Action3D/runs/3d11vv6l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mkjohn/MSR-Action3D\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 99 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/wandb/run-20240504_200630-3d11vv6l/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save wandb files to Google Drive."
      ],
      "metadata": {
        "id": "J9keHDCjxMhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_document['TRAINING']['n_epochs'] -= 300\n",
        "yaml_document['TRAINING']['refine_epoch'] -= 300"
      ],
      "metadata": {
        "id": "PnVIPXauMQQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_1 = \"/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/log/debug/{:06d}.pt\".format(yaml_document['TRAINING']['n_epochs'])\n",
        "file_2 = \"/content/drive/My Drive/Colab Notebooks/COMPSCI 674/Final Project/CS-674-Final-Project-3dInAction/log/debug/{:06d}.pt\".format(yaml_document['TRAINING']['n_epochs'])\n",
        "\n",
        "copy_file(file_2, file_1)\n",
        "\n",
        "yaml_document['TRAINING']['n_epochs'] += 300\n",
        "yaml_document['TRAINING']['refine_epoch'] += 300\n",
        "\n",
        "out_file_path = '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/configs/msr-action3d/'\n",
        "\n",
        "newdir(out_file_path, exist_ok = True)\n",
        "\n",
        "with open(out_file_path + 'config_msr_action3d.yaml', 'w') as yaml_file:\n",
        "  yaml.safe_dump(yaml_document, yaml_file)"
      ],
      "metadata": {
        "id": "goaj01Nnw0yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch -c dev dev-mathew"
      ],
      "metadata": {
        "id": "AMimaGM2OXb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch --list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqERxRIYOlnz",
        "outputId": "c4481364-635e-425a-e256-5e25345be15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mdev\u001b[m\n",
            "  dev-mathew\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --system --add user.name GitUser5877857139983029"
      ],
      "metadata": {
        "id": "y_Y4NruwPVmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --list --system"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a2e881-a53f-4ed0-fcd8-8f00f35ee6c6",
        "id": "TU5HafCJQLYD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filter.lfs.required=true\n",
            "filter.lfs.clean=git-lfs clean -- %f\n",
            "filter.lfs.smudge=git-lfs smudge -- %f\n",
            "filter.lfs.process=git-lfs filter-process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goQx5iOoaDCM",
        "outputId": "e95dbe5a-9432-4d17-dc43-98ae0f0669cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat .git/config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dVnbCoDQsRZ",
        "outputId": "174975fe-75b4-40ec-daa5-a21e87897905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[core]\n",
            "\trepositoryformatversion = 0\n",
            "\tfilemode = true\n",
            "\tbare = false\n",
            "\tlogallrefupdates = true\n",
            "[remote \"origin\"]\n",
            "\turl = https://github.com/EfranH25/CS-674-Final-Project-3dInAction.git\n",
            "\tfetch = +refs/heads/*:refs/remotes/origin/*\n",
            "[branch \"dev\"]\n",
            "\tremote = origin\n",
            "\tmerge = refs/heads/dev\n",
            "[branch \"dev-mathew\"]\n",
            "\tremote = origin\n",
            "\tmerge = refs/heads/dev\n",
            "[gui]\n",
            "\twmstate = zoomed\n",
            "\tgeometry = 1109x563+224+224 216 255\n",
            "[user]\n",
            "\tname = GitUser5877857139983029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!(type -p wget >/dev/null || (sudo apt update && sudo apt-get install wget -y)) \\\n",
        "&& sudo mkdir -p -m 755 /etc/apt/keyrings \\\n",
        "&& wget -qO- https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo tee /etc/apt/keyrings/githubcli-archive-keyring.gpg > /dev/null \\\n",
        "&& sudo chmod go+r /etc/apt/keyrings/githubcli-archive-keyring.gpg \\\n",
        "&& echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \\\n",
        "&& sudo apt update \\\n",
        "&& sudo apt install gh -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2YoAhMSTy8t",
        "outputId": "1263f74c-c34c-405d-cddc-b090ac03e1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.82)] [Co\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r                                                                               \rGet:4 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\u001b[33m\r0% [2 InRelease 38.8 kB/119 kB 33%] [Connecting to security.ubuntu.com (91.189.\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                    \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r                                                                    \r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers]\u001b[0m\r                                              \rHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "\u001b[33m\r                                              \r0% [Waiting for headers]\u001b[0m\r                        \rHit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:12 https://cli.github.com/packages stable/main amd64 Packages [344 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,371 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,037 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,756 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,077 kB]\n",
            "Fetched 7,310 kB in 2s (4,027 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gh\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 13.6 MB of archives.\n",
            "After this operation, 50.0 MB of additional disk space will be used.\n",
            "Get:1 https://cli.github.com/packages stable/main amd64 gh amd64 2.49.0 [13.6 MB]\n",
            "Fetched 13.6 MB in 0s (36.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package gh.\n",
            "(Reading database ... 121920 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/gh_2.49.0_amd64.deb ...\n",
            "Unpacking gh (2.49.0) ...\n",
            "Setting up gh (2.49.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install gh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksvp29UMT9yD",
        "outputId": "6fcf1468-0cef-442a-bead-f5b9873ebfb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Connecting to security.ubuntu.com (91.189.91.82)] [Connecting to cloud.r-pr\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,371 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,756 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,037 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,077 kB]\n",
            "Fetched 7,306 kB in 2s (4,224 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  gh\n",
            "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 6,242 kB of archives.\n",
            "After this operation, 33.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gh amd64 2.4.0+dfsg1-2 [6,242 kB]\n",
            "Fetched 6,242 kB in 0s (13.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package gh.\n",
            "(Reading database ... 121920 files and directories currently installed.)\n",
            "Preparing to unpack .../gh_2.4.0+dfsg1-2_amd64.deb ...\n",
            "Unpacking gh (2.4.0+dfsg1-2) ...\n",
            "Setting up gh (2.4.0+dfsg1-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gh status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRjzaeKlUrP5",
        "outputId": "361f4b1a-5365-4a95-8c55-33dd9b508e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To get started with GitHub CLI, please run:  gh auth login\n",
            "Alternatively, populate the GH_TOKEN environment variable with a GitHub API authentication token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"my secret API key\" > my_token_file"
      ],
      "metadata": {
        "id": "CUqvJakgXL_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gh auth login --with-token < my_token_file"
      ],
      "metadata": {
        "id": "OzYXlTDHUXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K1T03QWa9E5",
        "outputId": "46c0618c-db7d-4194-8049-d349d6f0afab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unknown command \"status\" for \"gh\"\n",
            "\n",
            "Usage:  gh <command> <subcommand> [flags]\n",
            "\n",
            "Available commands:\n",
            "  actions\n",
            "  alias\n",
            "  api\n",
            "  auth\n",
            "  browse\n",
            "  codespace\n",
            "  completion\n",
            "  config\n",
            "  extension\n",
            "  gist\n",
            "  gpg-key\n",
            "  help\n",
            "  issue\n",
            "  pr\n",
            "  release\n",
            "  repo\n",
            "  run\n",
            "  secret\n",
            "  ssh-key\n",
            "  workflow\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gh repo list EfranH25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ7z4TkcYi74",
        "outputId": "d41b17a1-0d9f-4d8d-f6e3-aaec88524783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Showing 19 of 19 repositories in @EfranH25\n",
            "\n",
            "\u001b[0;2;4;37mNAME                    \u001b[0m  \u001b[0;2;4;37mDESCRIPTION         \u001b[0m  \u001b[0;2;4;37mINFO        \u001b[0m  \u001b[0;2;4;37mUPDATED           \u001b[0m\n",
            "\u001b[0;1;39mEfranH25/CS-674-Final...\u001b[0m  This is the repos...  \u001b[0;90mpublic, fork\u001b[0m  \u001b[0;90mabout 1 day ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Generative-A...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 4 months ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Airbnb-Machi...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 4 months ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/IBM-Data-Sci...\u001b[0m  This repo holds m...  \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 1 year ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/ansible        \u001b[0m  Ansible is a radi...  \u001b[0;90mpublic, fork\u001b[0m  \u001b[0;90mabout 2 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/markdown-here  \u001b[0m  Google Chrome, Fi...  \u001b[0;90mpublic, fork\u001b[0m  \u001b[0;90mabout 2 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Coursera-Pyt...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 2 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Spoon-Knife    \u001b[0m  This repo is for ...  \u001b[0;90mpublic, fork\u001b[0m  \u001b[0;90mabout 2 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/API            \u001b[0m  Learn how to use ...  \u001b[0;90mpublic, fork\u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Cleaning-Dat...\u001b[0m  Cleaning Data for...  \u001b[0;90mpublic, fork\u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Excel-Samples  \u001b[0m  This Repo is to d...  \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Tableau-Proj...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Newegg-GPU-D...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/1985-Wage-Da...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/-Cat-Dog-Mac...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/SQL-Snippets   \u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/COVID-Neural...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/Hacker-Rank-...\u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n",
            "\u001b[0;1;39mEfranH25/ML-Minis       \u001b[0m                        \u001b[0;90mpublic      \u001b[0m  \u001b[0;90mabout 3 years ago\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gh repo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGdko5oXZB8y",
        "outputId": "ac0e60aa-ccb9-4d7f-e0b4-b0d3304026ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Work with GitHub repositories.\n",
            "\n",
            "\u001b[0;1;39mUSAGE\u001b[0m\n",
            "  gh repo <command> [flags]\n",
            "\n",
            "\u001b[0;1;39mGENERAL COMMANDS\u001b[0m\n",
            "  create:      Create a new repository\n",
            "  list:        List repositories owned by user or organization\n",
            "\n",
            "\u001b[0;1;39mTARGETED COMMANDS\u001b[0m\n",
            "  archive:     Archive a repository\n",
            "  clone:       Clone a repository locally\n",
            "  delete:      Delete a repository\n",
            "  deploy-key:  Manage deploy keys in a repository\n",
            "  edit:        Edit repository settings\n",
            "  fork:        Create a fork of a repository\n",
            "  rename:      Rename a repository\n",
            "  set-default: Configure default repository for this directory\n",
            "  sync:        Sync a repository\n",
            "  unarchive:   Unarchive a repository\n",
            "  view:        View a repository\n",
            "\n",
            "\u001b[0;1;39mINHERITED FLAGS\u001b[0m\n",
            "  --help   Show help for command\n",
            "\n",
            "\u001b[0;1;39mARGUMENTS\u001b[0m\n",
            "  A repository can be supplied as an argument in any of the following formats:\n",
            "  - \"OWNER/REPO\"\n",
            "  - by URL, e.g. \"https://github.com/OWNER/REPO\"\n",
            "\n",
            "\u001b[0;1;39mEXAMPLES\u001b[0m\n",
            "  $ gh repo create\n",
            "  $ gh repo clone cli/cli\n",
            "  $ gh repo view --web\n",
            "\n",
            "\u001b[0;1;39mLEARN MORE\u001b[0m\n",
            "  Use `gh <command> <subcommand> --help` for more information about a command.\n",
            "  Read the manual at https://cli.github.com/manual\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gh repo sync EfranH25/CS-674-Final-Project-3dInAction -b dev-mathew"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A2i1VdtXjY_",
        "outputId": "0b464108-6a68-49d4-9484-a5ceaab85874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[0;32m✓\u001b[0m Synced the \"EfranH25:main\" branch from \"sitzikbs:main\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://github.com/EfranH25/CS-674-Final-Project-3dInAction.git dev-mathew"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTsOaQhFahrc",
        "outputId": "a84824cd-5c89-4a7b-b968-679d48cdd773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git -c user.name=GitUser5877857139983029 push https://github.com/EfranH25/CS-674-Final-Project-3dInAction.git dev-mathew"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HKyIYWcOpk_",
        "outputId": "a6d468ec-493d-4b2d-8ed5-16201597e4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ]
}