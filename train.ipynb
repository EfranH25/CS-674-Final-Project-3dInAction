{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_IDX=0\n",
    "CUDA_DEVICE_ORDER=\"PCI_BUS_ID\"\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "#IDENTIFIER='tpatches_debug'\n",
    "IDENTIFIER='set_transformer'\n",
    "\n",
    "CONFIG='configs\\ikeaasm\\config_ikeaasm.yaml'\n",
    "\n",
    "LOGDIR='./log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import i3d_utils as utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from models.pointnet import feature_transform_regularizer\n",
    "from models import build_model\n",
    "from datasets import build_dataloader\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--logdir', type=str, default='./log/', help='path to model save dir')\n",
    "parser.add_argument('--identifier', type=str, default='debug', help='unique run identifier')\n",
    "parser.add_argument('--config', type=str, default='./configs/dfaust/config_dfaust.yaml', help='path to yaml config file')\n",
    "parser.add_argument('--fix_random_seed', action='store_true', default=False, help='fix random seed')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(LOGDIR='./log/', config='configs\\\\ikeaasm\\\\config_ikeaasm.yaml', fix_random_seed=False, identifier='set_transformer', logdir='./log/')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.identifier = IDENTIFIER\n",
    "args.config = CONFIG\n",
    "args.LOGDIR = LOGDIR\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cfg = yaml.safe_load(open(args.config))\n",
    "    logdir = os.path.join(args.logdir, args.identifier)\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "    # TODO: move to cfg project_name, entity\n",
    "    if cfg['DATA'].get('name') == 'DFAUST':\n",
    "        project_name = 'DFAUST'\n",
    "    elif cfg['DATA'].get('name') == 'IKEA_EGO':\n",
    "        project_name = 'IKEA EGO'\n",
    "    elif cfg['DATA'].get('name') == 'IKEA_ASM':\n",
    "        project_name = 'IKEA ASM'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    print(cfg)\n",
    "    print(project_name)\n",
    "    \n",
    "    #wandb_run = wandb.init(project=project_name, entity='cgmlab', save_code=True)\n",
    "    #cfg['WANDB'] = {'id': wandb_run.id, 'project': wandb_run.project, 'entity': wandb_run.entity}\n",
    "\n",
    "    with open(os.path.join(logdir, 'config.yaml'), 'w') as outfile:\n",
    "        yaml.dump(cfg, outfile, default_flow_style=False)\n",
    "\n",
    "    #wandb_run.name = args.identifier\n",
    "    #wandb.config.update(cfg)  # adds all the arguments as config variables\n",
    "    #wandb.run.log_code(\".\")\n",
    "    # define our custom x axis metric\n",
    "    #wandb.define_metric(\"train/step\")\n",
    "    #wandb.define_metric(\"train/*\", step_metric=\"train/step\")\n",
    "    #wandb.define_metric(\"test/*\", step_metric=\"train/step\")\n",
    "\n",
    "    # need to add argparse\n",
    "    \n",
    "    print('-------- about to run stuff!')\n",
    "    run(cfg, logdir)\n",
    "\n",
    "def run(cfg, logdir):\n",
    "    n_epochs = cfg['TRAINING']['n_epochs']\n",
    "    lr = cfg['TRAINING']['lr']\n",
    "    batch_size = cfg['TRAINING']['batch_size']\n",
    "    refine, refine_epoch = cfg['TRAINING']['refine'], cfg['TRAINING']['refine_epoch']\n",
    "    pretrained_model = cfg['TRAINING']['pretrained_model']\n",
    "    pc_model = cfg['MODEL']['pc_model']\n",
    "    frames_per_clip = cfg['DATA']['frames_per_clip']\n",
    "    num_steps_per_update = cfg['TRAINING']['steps_per_update']\n",
    "    save_every = cfg['save_every']\n",
    "\n",
    "    if args.fix_random_seed:\n",
    "        seed = cfg['seed']\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.system('cp %s %s' % ('train.py', logdir))  # backup the current training file\n",
    "    os.makedirs(os.path.join(logdir, 'models'), exist_ok=True)\n",
    "    os.system('cp %s %s' % ('models/*.py', os.path.join(logdir, 'models')))  # backup the models files\n",
    "\n",
    "    # build dataloader and dataset\n",
    "    train_dataloader, train_dataset = build_dataloader(config=cfg, training=True, shuffle=False) # should be unshuffled because of sampler\n",
    "    test_dataloader, test_dataset = build_dataloader(config=cfg, training=False, shuffle=True)\n",
    "\n",
    "    num_classes = train_dataset.num_classes\n",
    "\n",
    "    # build model\n",
    "    model = build_model(cfg['MODEL'], num_classes, frames_per_clip)\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        checkpoints = torch.load(pretrained_model)\n",
    "        model.load_state_dict(checkpoints[\"model_state_dict\"])  # load trained model\n",
    "        model.replace_logits(num_classes)\n",
    "\n",
    "    if refine:\n",
    "        if refine_epoch == 0:\n",
    "            raise ValueError(\"You set the refine epoch to 0. No need to refine, just retrain.\")\n",
    "        refine_model_filename = os.path.join(logdir, str(refine_epoch).zfill(6)+'.pt')\n",
    "        checkpoint = torch.load(refine_model_filename)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    model.cuda()\n",
    "    \n",
    "    #print('---------------', model.cuda())\n",
    "    \n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    # define optimizer and scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1E-6)\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)\n",
    "\n",
    "    if refine:\n",
    "        lr_sched.load_state_dict(checkpoint[\"lr_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    steps = 0\n",
    "    n_examples = 0\n",
    "    train_num_batch = len(train_dataloader)\n",
    "    test_num_batch = len(test_dataloader)\n",
    "    refine_flag = True\n",
    "\n",
    "    pbar = tqdm(total=n_epochs, desc='Training', dynamic_ncols=True)\n",
    "    while steps <= n_epochs:\n",
    "        if steps <= refine_epoch and refine and refine_flag:\n",
    "            # lr_sched.step()\n",
    "            steps += 1\n",
    "            n_examples += len(train_dataset.clip_set)\n",
    "            continue\n",
    "        else:\n",
    "            refine_flag = False\n",
    "        # Each epoch has a training and validation phase\n",
    "\n",
    "        test_batchind = -1\n",
    "        test_fraction_done = 0.0\n",
    "        test_enum = enumerate(test_dataloader, 0)\n",
    "        tot_loss = 0.0\n",
    "        tot_loc_loss = 0.0\n",
    "        tot_cls_loss = 0.0\n",
    "        num_iter = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Iterate over data.\n",
    "        avg_acc = []\n",
    "        loader_pbar = tqdm(total=len(train_dataloader), dynamic_ncols=True, leave=False)\n",
    "        for train_batchind, data in enumerate(train_dataloader):\n",
    "            num_iter += 1\n",
    "            # get the inputs\n",
    "            inputs, labels, vid_idx, frame_pad = data['inputs'], data['labels'], data['vid_idx'], data['frame_pad']\n",
    "            in_channel = cfg['MODEL'].get('in_channel', 3)\n",
    "            inputs = inputs[:, :, 0:in_channel, :]\n",
    "            inputs = inputs.cuda().requires_grad_().contiguous()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            out_dict = model(inputs)\n",
    "            per_frame_logits = out_dict['pred']\n",
    "\n",
    "            # compute localization loss\n",
    "            loc_loss = F.binary_cross_entropy_with_logits(per_frame_logits, labels)\n",
    "            tot_loc_loss += loc_loss.item()\n",
    "\n",
    "            # compute classification loss (with max-pooling along time B x C x T)\n",
    "            cls_loss = F.binary_cross_entropy_with_logits(torch.max(per_frame_logits, dim=2)[0], torch.max(labels, dim=2)[0])\n",
    "            tot_cls_loss += cls_loss.item()\n",
    "            loss = (0.5 * loc_loss + 0.5 * cls_loss) / num_steps_per_update\n",
    "            if pc_model == 'pn1' or pc_model == 'pn1_4d_basic':\n",
    "                trans, trans_feat = out_dict['trans'], out_dict['trans_feat']\n",
    "                loss += 0.001 * feature_transform_regularizer(trans) + 0.001 * feature_transform_regularizer(trans_feat)\n",
    "\n",
    "            tot_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            acc = utils.accuracy_v2(torch.argmax(per_frame_logits, dim=1), torch.argmax(labels, dim=1))\n",
    "            avg_acc.append(acc.item())\n",
    "\n",
    "            train_fraction_done = (train_batchind + 1) / train_num_batch\n",
    "\n",
    "            if num_iter == num_steps_per_update or train_batchind == len(train_dataloader)-1:\n",
    "                n_steps = num_steps_per_update\n",
    "                if train_batchind == len(train_dataloader)-1:\n",
    "                    n_steps = num_iter\n",
    "                n_examples += batch_size*n_steps\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # log train losses\n",
    "                log_dict = {\n",
    "                    \"train/step\": n_examples,\n",
    "                    \"train/loss\": tot_loss / n_steps,\n",
    "                    \"train/cls_loss\": tot_cls_loss / n_steps,\n",
    "                    \"train/loc_loss\": tot_loc_loss / n_steps,\n",
    "                    \"train/Accuracy\": np.mean(avg_acc),\n",
    "                    \"train/lr\":  optimizer.param_groups[0]['lr'],\n",
    "                    \"train/epoch\": steps,\n",
    "                }\n",
    "                #wandb.log(log_dict)\n",
    "\n",
    "                num_iter = 0\n",
    "                tot_loss = 0.\n",
    "\n",
    "            if test_fraction_done <= train_fraction_done and test_batchind + 1 < test_num_batch:\n",
    "                model.eval()\n",
    "                test_batchind, data = next(test_enum)\n",
    "                inputs, labels, vid_idx, frame_pad = data['inputs'], data['labels'], data['vid_idx'], data['frame_pad']\n",
    "                in_channel = cfg['MODEL'].get('in_channel', 3)\n",
    "                inputs = inputs[:, :, 0:in_channel, :]\n",
    "                inputs = inputs.cuda().requires_grad_().contiguous()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    out_dict = model(inputs)\n",
    "                    per_frame_logits = out_dict['pred']\n",
    "                    # compute localization loss\n",
    "                    loc_loss = F.binary_cross_entropy_with_logits(per_frame_logits, labels)\n",
    "                    # compute classification loss (with max-pooling along time B x C x T)\n",
    "                    cls_loss = F.binary_cross_entropy_with_logits(torch.max(per_frame_logits, dim=2)[0],\n",
    "                                                                  torch.max(labels, dim=2)[0])\n",
    "                    loss = (0.5 * loc_loss + 0.5 * cls_loss) / num_steps_per_update\n",
    "                    if pc_model == 'pn1' or pc_model == 'pn1_4d_basic':\n",
    "                        trans, trans_feat = out_dict['trans'], out_dict['trans_feat']\n",
    "                        loss += (0.001 * feature_transform_regularizer(trans) +\n",
    "                                 0.001 * feature_transform_regularizer(trans_feat)) / num_steps_per_update\n",
    "                    acc = utils.accuracy_v2(torch.argmax(per_frame_logits, dim=1), torch.argmax(labels, dim=1))\n",
    "\n",
    "                log_dict = {\n",
    "                    \"test/step\": n_examples,\n",
    "                    \"test/loss\": loss.item(),\n",
    "                    \"test/cls_loss\": loc_loss.item(),\n",
    "                    \"test/loc_loss\": cls_loss.item(),\n",
    "                    \"test/Accuracy\": acc.item()\n",
    "                }\n",
    "                #wandb.log(log_dict)\n",
    "                test_fraction_done = (test_batchind + 1) / test_num_batch\n",
    "                model.train()\n",
    "\n",
    "            loader_pbar.update()\n",
    "        loader_pbar.close()\n",
    "\n",
    "        if steps % save_every == 0 or steps == n_epochs:\n",
    "            # save model\n",
    "            torch.save({\"model_state_dict\": model.module.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"lr_state_dict\": lr_sched.state_dict()},\n",
    "                       os.path.join(logdir, str(steps).zfill(6) + '.pt'))\n",
    "\n",
    "        steps += 1\n",
    "        lr_sched.step()\n",
    "        pbar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 0, 'save_every': 5, 'num_workers': 0, 'MODEL': {'pc_model': 'set_transformer', '3DMFV': {'n_gaussians': 8}, 'SET_TRANSFORMER': {'dim_input': 3, 'num_outputs': 1, 'num_inds': 32, 'dim_hidden': 512, 'num_heads': 4, 'ln': False, 'temporal_smoothing': 0}, 'TPATCHES': {'centroid_jitter': 0.001, 'sample_mode': 'nn', 'k': [16, 16, 16], 'npoints': [512, 128, None], 'temp_conv': 7, 'downsample_method': 'fps', 'radius': [None, None, None], 'type': 'skip_con', 'attn_num_heads': 4, 'bidirectional': True}}, 'TRAINING': {'lr': 0.001, 'steps_per_update': 8, 'batch_size': 2, 'n_epochs': 1, 'refine': False, 'refine_epoch': 0, 'pretrained_model': None, 'aug': ['']}, 'TESTING': {'batch_size': 2, 'aug': [''], 'set': 'test'}, 'DATA': {'name': 'IKEA_ASM', 'dataset_path': 'datasets\\\\data\\\\IKEA ASM\\\\ANU_ikea_dataset_smaller_clips\\\\32', 'frame_skip': 1, 'frames_per_clip': 32, 'data_sampler': 'weighted', 'n_points': 4096, 'in_channel': 6}}\n",
      "IKEA ASM\n",
      "-------- about to run stuff!\n",
      "trainset contains 21833 clips\n",
      "Number of clips in the train set:21833\n",
      "testset contains 10064 clips\n",
      "Number of clips in the test set:10064\n",
      "--------------- SetTransformerTemporal(\n",
      "  (enc): Sequential(\n",
      "    (0): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=3, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=3, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=3, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (classifier12): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (final_layer): Linear(in_features=256, out_features=33, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#wandb_run.name = args.identifier\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#wandb.config.update(cfg)  # adds all the arguments as config variables\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#wandb.run.log_code(\".\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# need to add argparse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------- about to run stuff!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 139\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(cfg, logdir)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# compute localization loss\u001b[39;00m\n\u001b[0;32m    138\u001b[0m loc_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(per_frame_logits, labels)\n\u001b[1;32m--> 139\u001b[0m tot_loc_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloc_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# compute classification loss (with max-pooling along time B x C x T)\u001b[39;00m\n\u001b[0;32m    142\u001b[0m cls_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(torch\u001b[38;5;241m.\u001b[39mmax(per_frame_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mmax(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpatches_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
