{"cells":[{"cell_type":"code","source":["!pip list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3k67xxOeFLIH","executionInfo":{"status":"ok","timestamp":1715911500383,"user_tz":240,"elapsed":2099,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}},"outputId":"0ca87e55-5572-4a12-f9b0-428734259528"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["Package                          Version\n","-------------------------------- ---------------------\n","absl-py                          1.4.0\n","aiohttp                          3.9.5\n","aiosignal                        1.3.1\n","alabaster                        0.7.16\n","albumentations                   1.3.1\n","altair                           4.2.2\n","annotated-types                  0.6.0\n","anyio                            3.7.1\n","appdirs                          1.4.4\n","argon2-cffi                      23.1.0\n","argon2-cffi-bindings             21.2.0\n","array_record                     0.5.1\n","arviz                            0.15.1\n","astropy                          5.3.4\n","astunparse                       1.6.3\n","async-timeout                    4.0.3\n","atpublic                         4.1.0\n","attrs                            23.2.0\n","audioread                        3.0.1\n","autograd                         1.6.2\n","Babel                            2.15.0\n","backcall                         0.2.0\n","beautifulsoup4                   4.12.3\n","bidict                           0.23.1\n","bigframes                        1.5.0\n","bleach                           6.1.0\n","blinker                          1.4\n","blis                             0.7.11\n","blosc2                           2.0.0\n","bokeh                            3.3.4\n","bqplot                           0.12.43\n","branca                           0.7.2\n","build                            1.2.1\n","CacheControl                     0.14.0\n","cachetools                       5.3.3\n","catalogue                        2.0.10\n","certifi                          2024.2.2\n","cffi                             1.16.0\n","chardet                          5.2.0\n","charset-normalizer               3.3.2\n","chex                             0.1.86\n","click                            8.1.7\n","click-plugins                    1.1.1\n","cligj                            0.7.2\n","cloudpathlib                     0.16.0\n","cloudpickle                      2.2.1\n","cmake                            3.27.9\n","cmdstanpy                        1.2.2\n","colorcet                         3.1.0\n","colorlover                       0.3.0\n","colour                           0.1.5\n","community                        1.0.0b1\n","confection                       0.1.4\n","cons                             0.4.6\n","contextlib2                      21.6.0\n","contourpy                        1.2.1\n","cryptography                     42.0.7\n","cuda-python                      12.2.1\n","cudf-cu12                        24.4.1\n","cufflinks                        0.17.3\n","cupy-cuda12x                     12.2.0\n","cvxopt                           1.3.2\n","cvxpy                            1.3.4\n","cycler                           0.12.1\n","cymem                            2.0.8\n","Cython                           3.0.10\n","dask                             2023.8.1\n","datascience                      0.17.6\n","db-dtypes                        1.2.0\n","dbus-python                      1.2.18\n","debugpy                          1.6.6\n","decorator                        4.4.2\n","defusedxml                       0.7.1\n","distributed                      2023.8.1\n","distro                           1.7.0\n","dlib                             19.24.4\n","dm-tree                          0.1.8\n","docstring_parser                 0.16\n","docutils                         0.18.1\n","dopamine_rl                      4.0.9\n","duckdb                           0.10.2\n","earthengine-api                  0.1.402\n","easydict                         1.13\n","ecos                             2.0.13\n","editdistance                     0.6.2\n","eerepr                           0.0.4\n","en-core-web-sm                   3.7.1\n","entrypoints                      0.4\n","et-xmlfile                       1.1.0\n","etils                            1.7.0\n","etuples                          0.3.9\n","exceptiongroup                   1.2.1\n","fastai                           2.7.15\n","fastcore                         1.5.34\n","fastdownload                     0.0.7\n","fastjsonschema                   2.19.1\n","fastprogress                     1.0.3\n","fastrlock                        0.8.2\n","filelock                         3.14.0\n","fiona                            1.9.6\n","firebase-admin                   5.3.0\n","Flask                            2.2.5\n","flatbuffers                      24.3.25\n","flax                             0.8.3\n","folium                           0.14.0\n","fonttools                        4.51.0\n","frozendict                       2.4.4\n","frozenlist                       1.4.1\n","fsspec                           2023.6.0\n","future                           0.18.3\n","gast                             0.5.4\n","gcsfs                            2023.6.0\n","GDAL                             3.6.4\n","gdown                            5.1.0\n","geemap                           0.32.1\n","gensim                           4.3.2\n","geocoder                         1.38.1\n","geographiclib                    2.0\n","geopandas                        0.13.2\n","geopy                            2.3.0\n","gin-config                       0.5.0\n","glob2                            0.7\n","google                           2.0.3\n","google-ai-generativelanguage     0.6.2\n","google-api-core                  2.11.1\n","google-api-python-client         2.84.0\n","google-auth                      2.27.0\n","google-auth-httplib2             0.1.1\n","google-auth-oauthlib             1.2.0\n","google-cloud-aiplatform          1.51.0\n","google-cloud-bigquery            3.21.0\n","google-cloud-bigquery-connection 1.12.1\n","google-cloud-bigquery-storage    2.25.0\n","google-cloud-core                2.3.3\n","google-cloud-datastore           2.15.2\n","google-cloud-firestore           2.11.1\n","google-cloud-functions           1.13.3\n","google-cloud-iam                 2.15.0\n","google-cloud-language            2.13.3\n","google-cloud-resource-manager    1.12.3\n","google-cloud-storage             2.8.0\n","google-cloud-translate           3.11.3\n","google-colab                     1.0.0\n","google-crc32c                    1.5.0\n","google-generativeai              0.5.2\n","google-pasta                     0.2.0\n","google-resumable-media           2.7.0\n","googleapis-common-protos         1.63.0\n","googledrivedownloader            0.4\n","graphviz                         0.20.3\n","greenlet                         3.0.3\n","grpc-google-iam-v1               0.13.0\n","grpcio                           1.63.0\n","grpcio-status                    1.48.2\n","gspread                          6.0.2\n","gspread-dataframe                3.3.1\n","gym                              0.25.2\n","gym-notices                      0.0.8\n","h5netcdf                         1.3.0\n","h5py                             3.9.0\n","holidays                         0.48\n","holoviews                        1.17.1\n","html5lib                         1.1\n","httpimport                       1.3.1\n","httplib2                         0.22.0\n","huggingface-hub                  0.20.3\n","humanize                         4.7.0\n","hyperopt                         0.2.7\n","ibis-framework                   8.0.0\n","idna                             3.7\n","imageio                          2.31.6\n","imageio-ffmpeg                   0.4.9\n","imagesize                        1.4.1\n","imbalanced-learn                 0.10.1\n","imgaug                           0.4.0\n","importlib_metadata               7.1.0\n","importlib_resources              6.4.0\n","imutils                          0.5.4\n","inflect                          7.0.0\n","iniconfig                        2.0.0\n","intel-openmp                     2023.2.4\n","ipyevents                        2.0.2\n","ipyfilechooser                   0.6.0\n","ipykernel                        5.5.6\n","ipyleaflet                       0.18.2\n","ipython                          7.34.0\n","ipython-genutils                 0.2.0\n","ipython-sql                      0.5.0\n","ipytree                          0.2.2\n","ipywidgets                       7.7.1\n","itsdangerous                     2.2.0\n","jax                              0.4.26\n","jaxlib                           0.4.26+cuda12.cudnn89\n","jeepney                          0.7.1\n","jieba                            0.42.1\n","Jinja2                           3.1.4\n","joblib                           1.4.2\n","jsonpickle                       3.0.4\n","jsonschema                       4.19.2\n","jsonschema-specifications        2023.12.1\n","jupyter-client                   6.1.12\n","jupyter-console                  6.1.0\n","jupyter_core                     5.7.2\n","jupyter-server                   1.24.0\n","jupyterlab_pygments              0.3.0\n","jupyterlab_widgets               3.0.10\n","kaggle                           1.6.12\n","kagglehub                        0.2.5\n","keras                            2.15.0\n","keyring                          23.5.0\n","kiwisolver                       1.4.5\n","langcodes                        3.4.0\n","language_data                    1.2.0\n","launchpadlib                     1.10.16\n","lazr.restfulclient               0.14.4\n","lazr.uri                         1.0.6\n","lazy_loader                      0.4\n","libclang                         18.1.1\n","librosa                          0.10.2\n","lightgbm                         4.1.0\n","linkify-it-py                    2.0.3\n","llvmlite                         0.41.1\n","locket                           1.0.0\n","logical-unification              0.4.6\n","lxml                             4.9.4\n","malloy                           2023.1067\n","marisa-trie                      1.1.1\n","Markdown                         3.6\n","markdown-it-py                   3.0.0\n","MarkupSafe                       2.1.5\n","matplotlib                       3.7.1\n","matplotlib-inline                0.1.7\n","matplotlib-venn                  0.11.10\n","mdit-py-plugins                  0.4.0\n","mdurl                            0.1.2\n","miniKanren                       1.0.3\n","missingno                        0.5.2\n","mistune                          0.8.4\n","mizani                           0.9.3\n","mkl                              2023.2.0\n","ml-dtypes                        0.2.0\n","mlxtend                          0.22.0\n","more-itertools                   10.1.0\n","moviepy                          1.0.3\n","mpmath                           1.3.0\n","msgpack                          1.0.8\n","multidict                        6.0.5\n","multipledispatch                 1.0.0\n","multitasking                     0.0.11\n","murmurhash                       1.0.10\n","music21                          9.1.0\n","natsort                          8.4.0\n","nbclassic                        1.0.0\n","nbclient                         0.10.0\n","nbconvert                        6.5.4\n","nbformat                         5.10.4\n","nest-asyncio                     1.6.0\n","networkx                         3.3\n","nibabel                          4.0.2\n","nltk                             3.8.1\n","notebook                         6.5.5\n","notebook_shim                    0.2.4\n","numba                            0.58.1\n","numexpr                          2.10.0\n","numpy                            1.25.2\n","nvtx                             0.2.10\n","oauth2client                     4.1.3\n","oauthlib                         3.2.2\n","opencv-contrib-python            4.8.0.76\n","opencv-python                    4.8.0.76\n","opencv-python-headless           4.9.0.80\n","openpyxl                         3.1.2\n","opt-einsum                       3.3.0\n","optax                            0.2.2\n","orbax-checkpoint                 0.4.4\n","osqp                             0.6.2.post8\n","packaging                        24.0\n","pandas                           2.0.3\n","pandas-datareader                0.10.0\n","pandas-gbq                       0.19.2\n","pandas-stubs                     2.0.3.230814\n","pandocfilters                    1.5.1\n","panel                            1.3.8\n","param                            2.1.0\n","parso                            0.8.4\n","parsy                            2.1\n","partd                            1.4.2\n","pathlib                          1.0.1\n","patsy                            0.5.6\n","peewee                           3.17.5\n","pexpect                          4.9.0\n","pickleshare                      0.7.5\n","Pillow                           9.4.0\n","pip                              23.1.2\n","pip-tools                        6.13.0\n","platformdirs                     4.2.1\n","plotly                           5.15.0\n","plotnine                         0.12.4\n","pluggy                           1.5.0\n","polars                           0.20.2\n","pooch                            1.8.1\n","portpicker                       1.5.2\n","prefetch-generator               1.0.3\n","preshed                          3.0.9\n","prettytable                      3.10.0\n","proglog                          0.1.10\n","progressbar2                     4.2.0\n","prometheus_client                0.20.0\n","promise                          2.3\n","prompt-toolkit                   3.0.43\n","prophet                          1.1.5\n","proto-plus                       1.23.0\n","protobuf                         3.20.3\n","psutil                           5.9.5\n","psycopg2                         2.9.9\n","ptyprocess                       0.7.0\n","py-cpuinfo                       9.0.0\n","py4j                             0.10.9.7\n","pyarrow                          14.0.2\n","pyarrow-hotfix                   0.6\n","pyasn1                           0.6.0\n","pyasn1_modules                   0.4.0\n","pycocotools                      2.0.7\n","pycparser                        2.22\n","pydantic                         2.7.1\n","pydantic_core                    2.18.2\n","pydata-google-auth               1.8.2\n","pydot                            1.4.2\n","pydot-ng                         2.0.0\n","pydotplus                        2.0.2\n","PyDrive                          1.3.1\n","PyDrive2                         1.6.3\n","pyerfa                           2.0.1.4\n","pygame                           2.5.2\n","Pygments                         2.16.1\n","PyGObject                        3.42.1\n","PyJWT                            2.3.0\n","pymc                             5.10.4\n","pymystem3                        0.2.0\n","pynvjitlink-cu12                 0.2.3\n","PyOpenGL                         3.1.7\n","pyOpenSSL                        24.1.0\n","pyparsing                        3.1.2\n","pyperclip                        1.8.2\n","pyproj                           3.6.1\n","pyproject_hooks                  1.1.0\n","pyshp                            2.3.1\n","PySocks                          1.7.1\n","pytensor                         2.18.6\n","pytest                           7.4.4\n","python-apt                       0.0.0\n","python-box                       7.1.1\n","python-dateutil                  2.8.2\n","python-louvain                   0.16\n","python-slugify                   8.0.4\n","python-utils                     3.8.2\n","pytz                             2023.4\n","pyviz_comms                      3.0.2\n","PyWavelets                       1.6.0\n","PyYAML                           6.0.1\n","pyzmq                            24.0.1\n","qdldl                            0.1.7.post2\n","qudida                           0.0.4\n","ratelim                          0.1.6\n","referencing                      0.35.1\n","regex                            2023.12.25\n","requests                         2.31.0\n","requests-oauthlib                1.3.1\n","requirements-parser              0.9.0\n","rich                             13.7.1\n","rmm-cu12                         24.4.0\n","rpds-py                          0.18.1\n","rpy2                             3.4.2\n","rsa                              4.9\n","safetensors                      0.4.3\n","scikit-image                     0.19.3\n","scikit-learn                     1.2.2\n","scipy                            1.11.4\n","scooby                           0.10.0\n","scs                              3.2.4.post1\n","seaborn                          0.13.1\n","SecretStorage                    3.3.1\n","Send2Trash                       1.8.3\n","sentencepiece                    0.1.99\n","setuptools                       67.7.2\n","shapely                          2.0.4\n","six                              1.16.0\n","sklearn-pandas                   2.2.0\n","smart-open                       6.4.0\n","sniffio                          1.3.1\n","snowballstemmer                  2.2.0\n","sortedcontainers                 2.4.0\n","soundfile                        0.12.1\n","soupsieve                        2.5\n","soxr                             0.3.7\n","spacy                            3.7.4\n","spacy-legacy                     3.0.12\n","spacy-loggers                    1.0.5\n","Sphinx                           5.0.2\n","sphinxcontrib-applehelp          1.0.8\n","sphinxcontrib-devhelp            1.0.6\n","sphinxcontrib-htmlhelp           2.0.5\n","sphinxcontrib-jsmath             1.0.1\n","sphinxcontrib-qthelp             1.0.7\n","sphinxcontrib-serializinghtml    1.1.10\n","SQLAlchemy                       2.0.30\n","sqlglot                          20.11.0\n","sqlparse                         0.5.0\n","srsly                            2.4.8\n","stanio                           0.5.0\n","statsmodels                      0.14.2\n","StrEnum                          0.4.15\n","sympy                            1.12\n","tables                           3.8.0\n","tabulate                         0.9.0\n","tbb                              2021.12.0\n","tblib                            3.0.0\n","tenacity                         8.3.0\n","tensorboard                      2.15.2\n","tensorboard-data-server          0.7.2\n","tensorflow                       2.15.0\n","tensorflow-datasets              4.9.4\n","tensorflow-estimator             2.15.0\n","tensorflow-gcs-config            2.15.0\n","tensorflow-hub                   0.16.1\n","tensorflow-io-gcs-filesystem     0.37.0\n","tensorflow-metadata              1.15.0\n","tensorflow-probability           0.23.0\n","tensorstore                      0.1.45\n","termcolor                        2.4.0\n","terminado                        0.18.1\n","text-unidecode                   1.3\n","textblob                         0.17.1\n","tf_keras                         2.15.1\n","tf-slim                          1.1.0\n","thinc                            8.2.3\n","threadpoolctl                    3.5.0\n","tifffile                         2024.5.10\n","tinycss2                         1.3.0\n","tokenizers                       0.19.1\n","toml                             0.10.2\n","tomli                            2.0.1\n","toolz                            0.12.1\n","torch                            2.2.1+cu121\n","torchaudio                       2.2.1+cu121\n","torchdata                        0.7.1\n","torchsummary                     1.5.1\n","torchtext                        0.17.1\n","torchvision                      0.17.1+cu121\n","tornado                          6.3.3\n","tqdm                             4.66.4\n","traitlets                        5.7.1\n","traittypes                       0.2.1\n","transformers                     4.40.2\n","triton                           2.2.0\n","tweepy                           4.14.0\n","typer                            0.9.4\n","types-pytz                       2024.1.0.20240417\n","types-setuptools                 69.5.0.20240513\n","typing_extensions                4.11.0\n","tzdata                           2024.1\n","tzlocal                          5.2\n","uc-micro-py                      1.0.3\n","uritemplate                      4.1.1\n","urllib3                          2.0.7\n","vega-datasets                    0.9.0\n","wadllib                          1.3.6\n","wasabi                           1.1.2\n","wcwidth                          0.2.13\n","weasel                           0.3.4\n","webcolors                        1.13\n","webencodings                     0.5.1\n","websocket-client                 1.8.0\n","Werkzeug                         3.0.3\n","wheel                            0.43.0\n","widgetsnbextension               3.6.6\n","wordcloud                        1.9.3\n","wrapt                            1.14.1\n","xarray                           2023.7.0\n","xarray-einstats                  0.7.0\n","xgboost                          2.0.3\n","xlrd                             2.0.1\n","xyzservices                      2024.4.0\n","yarl                             1.9.4\n","yellowbrick                      1.5\n","yfinance                         0.2.38\n","zict                             3.0.0\n","zipp                             3.18.1\n"]}]},{"cell_type":"markdown","metadata":{"id":"IYKHHwKgVzC1"},"source":["# Mount Google Drive"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2009,"status":"ok","timestamp":1715911502389,"user":{"displayName":"Mathew John","userId":"02352606196281189679"},"user_tz":240},"id":"9yhpVFLHVvqg","outputId":"3de0b9b3-b162-4c95-db06-184f4205b339"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"QArPELINWCnF"},"source":["# Import Statements"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"p1kzPDtFSUcO","executionInfo":{"status":"ok","timestamp":1715911502389,"user_tz":240,"elapsed":10,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["import torch\n","import torch.nn as tnn\n","import torch.cuda as tcuda\n","import numpy as NumPy\n","\n","# If CUDA is available, run code on GPU. Else, run code on CPU.\n","if tcuda.is_available():\n","  this_device = torch.device('cuda:0')\n","else:\n","  this_device = torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"hI_HPScc5gGa"},"source":["# Load Datasets"]},{"cell_type":"code","source":["dataset_used = 'MSR-Action3D'"],"metadata":{"id":"G1PpPubKlXMD","executionInfo":{"status":"ok","timestamp":1715911502389,"user_tz":240,"elapsed":10,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":["## Subsampling Size"],"metadata":{"id":"JE9oejx_13Pj"}},{"cell_type":"code","source":["point_cloud_frame_subsampling_size_DFAUST = 1024"],"metadata":{"id":"HiKCn1ma16Rc","executionInfo":{"status":"ok","timestamp":1715911502390,"user_tz":240,"elapsed":10,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":["## Training/Validation/Test Split Percentage"],"metadata":{"id":"U2Xf0Wmqqm5U"}},{"cell_type":"code","source":["training_split = 0.60\n","validation_split = 0.30\n","test_split = 0.10"],"metadata":{"id":"hlLXNmZdqr18","executionInfo":{"status":"ok","timestamp":1715911502390,"user_tz":240,"elapsed":10,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cA8252bWMKqN"},"source":["## IKEA ASM Dataset"]},{"cell_type":"markdown","source":["### Load the IKEA ASM Dataset's video."],"metadata":{"id":"lsJ-9El57tia"}},{"cell_type":"code","execution_count":106,"metadata":{"id":"W51niKdc5fe3","executionInfo":{"status":"ok","timestamp":1715911502390,"user_tz":240,"elapsed":10,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"IKEA-ASM\":\n","  npz_file = '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/\\\n","IKEA/ANU_ikea_dataset_point\\\n","_cloud_video/processed_frames/Lack_Coffee_Table/0004_b\\\n","lack_floor_06_03_2019_08_21_11_46/dev3/point_cloud_video.npz'\n","  ikea_asm_pt_cld_video = NumPy.load(npz_file)['frames']\n","\n","  # Print the shape of the loaded dataset.\n","  print(ikea_asm_pt_cld_video.shape)"]},{"cell_type":"markdown","source":["### Create Tensors of the IKEA ASM Dataset's Video and Its Labels"],"metadata":{"id":"JFqsrLl17waL"}},{"cell_type":"code","execution_count":107,"metadata":{"id":"ky3RNph27DP_","executionInfo":{"status":"ok","timestamp":1715911502390,"user_tz":240,"elapsed":9,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"IKEA-ASM\":\n","  # Set the num_frames, T and N variables using the data from the IKEA ASM dataset.\n","  num_frames, N, _3 = ikea_asm_pt_cld_video.shape\n","  T = num_frames - 1\n","\n","  # Make S hold the point cloud video from the IKEA ASM dataset.\n","  S = torch.from_numpy(ikea_asm_pt_cld_video).to(device = this_device).unsqueeze(0)"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"Go5rqBn1BJhF","executionInfo":{"status":"ok","timestamp":1715911502390,"user_tz":240,"elapsed":9,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"IKEA-ASM\":\n","  # Read the action annotations from an .npy file into a variable.\n","  action_annotations_path = '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/IKEA/action_annotations/gt_action.npy'\n","  actions = NumPy.load(action_annotations_path, allow_pickle = True)\n","\n","  # Display information about the action annotations.\n","  print(type(actions))\n","  print(actions.dtype)\n","  print(actions.shape)\n","  print(actions.ndim)\n","\n","  # Convert the action annotations to a dictionary and store the dictionary in a variable.\n","  actions_list = actions.tolist()\n","\n","  # Display information about the actions annotation dictionary.\n","  print(type(actions_list))\n","  print(actions_list.keys())\n","  print(len(actions_list['scan_name']))\n","  len(actions_list['gt_labels'])\n","  # help(actions_list['scan_name'])\n","\n","  # Store the index of the loaded point cloud video's action annotations in a variable.\n","  index_of_pt_cld_video = actions_list['scan_name'].index('Lack_Coffee_Table/0004_black_floor_06_03_2019_08_21_11_46')\n","\n","  # Store the ground truth labels of the loaded point cloud video in a variable.\n","  ground_truth_labels = torch.from_numpy(actions_list['gt_labels'][index_of_pt_cld_video])\n","\n","  # Display information about the ground truth labels of the loaded point cloud video.\n","  ground_truth_labels.shape\n","\n","  # Store the ground truth labels of the first 1500 frames of the loaded point cloud video in a variable.\n","  ikea_asm_pt_cld_video_action_labels = ground_truth_labels[:1500].unsqueeze(0)\n","\n","  # Print information about the action labels of the point cloud video frames.\n","  print(torch.max(ikea_asm_pt_cld_video_action_labels))\n","  print(torch.min(ikea_asm_pt_cld_video_action_labels))\n","\n","  # Store the number of action classes in a variable.\n","  num_action_classes = torch.max(ikea_asm_pt_cld_video_action_labels) + 1"]},{"cell_type":"markdown","metadata":{"id":"avtiUin7MNGQ"},"source":["## MSR-Action3D Dataset"]},{"cell_type":"markdown","source":["### Load the MSR-Action3D Dataset"],"metadata":{"id":"TuowLKy6GvWm"}},{"cell_type":"code","execution_count":109,"metadata":{"id":"Mubj0sT_MRML","executionInfo":{"status":"ok","timestamp":1715911503061,"user_tz":240,"elapsed":680,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"MSR-Action3D\":\n","  import pickle\n","  import sys\n","\n","  # Load the MSR-Action3D dataset's depth map sequences and their class labels.\n","  msr_action3d_path = '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/MSRAction3D_fps/'\n","  #msr_action3d_path = '/content/drive/MyDrive/Colab Notebooks/'\n","\n","  with open(msr_action3d_path + 'MSRAction3D_FPS_Videos.pickle' , mode = 'rb') as msr_action3d_pickle_file:\n","    msr_action3d_depth_map_sequences = pickle.load(msr_action3d_pickle_file)\n","  msr_action3d_depth_map_sequence_labels = NumPy.load(msr_action3d_path + 'MSRAction3D_FPS_Video_Labels.npz')['labels']"]},{"cell_type":"code","source":["if dataset_used == \"MSR-Action3D\":\n","  # Print out the shapes of the depth map sequences in the MSR-Action3D dataset.\n","  for index, video in enumerate(msr_action3d_depth_map_sequences):\n","    print(index + 1, \"-->\", video.shape)"],"metadata":{"id":"jps6rh1VFoTj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715911503797,"user_tz":240,"elapsed":738,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}},"outputId":"8e5d76dc-dfa9-44cf-98ae-ca759e1b226b"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["1 --> (1, 28, 2048, 3)\n","2 --> (1, 23, 2048, 3)\n","3 --> (1, 47, 2048, 3)\n","4 --> (1, 35, 2048, 3)\n","5 --> (1, 43, 2048, 3)\n","6 --> (1, 29, 2048, 3)\n","7 --> (1, 50, 2048, 3)\n","8 --> (1, 48, 2048, 3)\n","9 --> (1, 26, 2048, 3)\n","10 --> (1, 34, 2048, 3)\n","11 --> (1, 55, 2048, 3)\n","12 --> (1, 51, 2048, 3)\n","13 --> (1, 42, 2048, 3)\n","14 --> (1, 38, 2048, 3)\n","15 --> (1, 37, 2048, 3)\n","16 --> (1, 33, 2048, 3)\n","17 --> (1, 16, 2048, 3)\n","18 --> (1, 31, 2048, 3)\n","19 --> (1, 19, 2048, 3)\n","20 --> (1, 69, 2048, 3)\n","21 --> (1, 40, 2048, 3)\n","22 --> (1, 38, 2048, 3)\n","23 --> (1, 40, 2048, 3)\n","24 --> (1, 30, 2048, 3)\n","25 --> (1, 30, 2048, 3)\n","26 --> (1, 34, 2048, 3)\n","27 --> (1, 31, 2048, 3)\n","28 --> (1, 36, 2048, 3)\n","29 --> (1, 37, 2048, 3)\n","30 --> (1, 46, 2048, 3)\n","31 --> (1, 50, 2048, 3)\n","32 --> (1, 46, 2048, 3)\n","33 --> (1, 45, 2048, 3)\n","34 --> (1, 38, 2048, 3)\n","35 --> (1, 37, 2048, 3)\n","36 --> (1, 35, 2048, 3)\n","37 --> (1, 30, 2048, 3)\n","38 --> (1, 55, 2048, 3)\n","39 --> (1, 55, 2048, 3)\n","40 --> (1, 36, 2048, 3)\n","41 --> (1, 38, 2048, 3)\n","42 --> (1, 29, 2048, 3)\n","43 --> (1, 40, 2048, 3)\n","44 --> (1, 47, 2048, 3)\n","45 --> (1, 61, 2048, 3)\n","46 --> (1, 40, 2048, 3)\n","47 --> (1, 48, 2048, 3)\n","48 --> (1, 38, 2048, 3)\n","49 --> (1, 45, 2048, 3)\n","50 --> (1, 67, 2048, 3)\n","51 --> (1, 36, 2048, 3)\n","52 --> (1, 38, 2048, 3)\n","53 --> (1, 37, 2048, 3)\n","54 --> (1, 37, 2048, 3)\n","55 --> (1, 46, 2048, 3)\n","56 --> (1, 54, 2048, 3)\n","57 --> (1, 42, 2048, 3)\n","58 --> (1, 45, 2048, 3)\n","59 --> (1, 47, 2048, 3)\n","60 --> (1, 58, 2048, 3)\n","61 --> (1, 62, 2048, 3)\n","62 --> (1, 42, 2048, 3)\n","63 --> (1, 48, 2048, 3)\n","64 --> (1, 56, 2048, 3)\n","65 --> (1, 43, 2048, 3)\n","66 --> (1, 32, 2048, 3)\n","67 --> (1, 44, 2048, 3)\n","68 --> (1, 31, 2048, 3)\n","69 --> (1, 39, 2048, 3)\n","70 --> (1, 34, 2048, 3)\n","71 --> (1, 42, 2048, 3)\n","72 --> (1, 37, 2048, 3)\n","73 --> (1, 36, 2048, 3)\n","74 --> (1, 43, 2048, 3)\n","75 --> (1, 45, 2048, 3)\n","76 --> (1, 41, 2048, 3)\n","77 --> (1, 34, 2048, 3)\n","78 --> (1, 30, 2048, 3)\n","79 --> (1, 48, 2048, 3)\n","80 --> (1, 36, 2048, 3)\n","81 --> (1, 52, 2048, 3)\n","82 --> (1, 36, 2048, 3)\n","83 --> (1, 40, 2048, 3)\n","84 --> (1, 45, 2048, 3)\n","85 --> (1, 29, 2048, 3)\n","86 --> (1, 19, 2048, 3)\n","87 --> (1, 30, 2048, 3)\n","88 --> (1, 53, 2048, 3)\n","89 --> (1, 31, 2048, 3)\n","90 --> (1, 57, 2048, 3)\n","91 --> (1, 36, 2048, 3)\n","92 --> (1, 46, 2048, 3)\n","93 --> (1, 27, 2048, 3)\n","94 --> (1, 26, 2048, 3)\n","95 --> (1, 29, 2048, 3)\n","96 --> (1, 31, 2048, 3)\n","97 --> (1, 33, 2048, 3)\n","98 --> (1, 51, 2048, 3)\n","99 --> (1, 47, 2048, 3)\n","100 --> (1, 27, 2048, 3)\n","101 --> (1, 57, 2048, 3)\n","102 --> (1, 32, 2048, 3)\n","103 --> (1, 41, 2048, 3)\n","104 --> (1, 26, 2048, 3)\n","105 --> (1, 47, 2048, 3)\n","106 --> (1, 42, 2048, 3)\n","107 --> (1, 47, 2048, 3)\n","108 --> (1, 29, 2048, 3)\n","109 --> (1, 64, 2048, 3)\n","110 --> (1, 26, 2048, 3)\n","111 --> (1, 35, 2048, 3)\n","112 --> (1, 32, 2048, 3)\n","113 --> (1, 51, 2048, 3)\n","114 --> (1, 39, 2048, 3)\n","115 --> (1, 50, 2048, 3)\n","116 --> (1, 31, 2048, 3)\n","117 --> (1, 34, 2048, 3)\n","118 --> (1, 34, 2048, 3)\n","119 --> (1, 36, 2048, 3)\n","120 --> (1, 44, 2048, 3)\n","121 --> (1, 76, 2048, 3)\n","122 --> (1, 37, 2048, 3)\n","123 --> (1, 38, 2048, 3)\n","124 --> (1, 44, 2048, 3)\n","125 --> (1, 38, 2048, 3)\n","126 --> (1, 34, 2048, 3)\n","127 --> (1, 26, 2048, 3)\n","128 --> (1, 39, 2048, 3)\n","129 --> (1, 41, 2048, 3)\n","130 --> (1, 44, 2048, 3)\n","131 --> (1, 58, 2048, 3)\n","132 --> (1, 36, 2048, 3)\n","133 --> (1, 52, 2048, 3)\n","134 --> (1, 24, 2048, 3)\n","135 --> (1, 36, 2048, 3)\n","136 --> (1, 32, 2048, 3)\n","137 --> (1, 36, 2048, 3)\n","138 --> (1, 38, 2048, 3)\n","139 --> (1, 38, 2048, 3)\n","140 --> (1, 26, 2048, 3)\n","141 --> (1, 57, 2048, 3)\n","142 --> (1, 28, 2048, 3)\n","143 --> (1, 46, 2048, 3)\n","144 --> (1, 38, 2048, 3)\n","145 --> (1, 23, 2048, 3)\n","146 --> (1, 40, 2048, 3)\n","147 --> (1, 42, 2048, 3)\n","148 --> (1, 44, 2048, 3)\n","149 --> (1, 52, 2048, 3)\n","150 --> (1, 32, 2048, 3)\n","151 --> (1, 46, 2048, 3)\n","152 --> (1, 25, 2048, 3)\n","153 --> (1, 30, 2048, 3)\n","154 --> (1, 33, 2048, 3)\n","155 --> (1, 28, 2048, 3)\n","156 --> (1, 30, 2048, 3)\n","157 --> (1, 37, 2048, 3)\n","158 --> (1, 44, 2048, 3)\n","159 --> (1, 45, 2048, 3)\n","160 --> (1, 42, 2048, 3)\n","161 --> (1, 25, 2048, 3)\n","162 --> (1, 34, 2048, 3)\n","163 --> (1, 36, 2048, 3)\n","164 --> (1, 40, 2048, 3)\n","165 --> (1, 54, 2048, 3)\n","166 --> (1, 53, 2048, 3)\n","167 --> (1, 34, 2048, 3)\n","168 --> (1, 44, 2048, 3)\n","169 --> (1, 46, 2048, 3)\n","170 --> (1, 38, 2048, 3)\n","171 --> (1, 35, 2048, 3)\n","172 --> (1, 36, 2048, 3)\n","173 --> (1, 46, 2048, 3)\n","174 --> (1, 33, 2048, 3)\n","175 --> (1, 39, 2048, 3)\n","176 --> (1, 42, 2048, 3)\n","177 --> (1, 43, 2048, 3)\n","178 --> (1, 50, 2048, 3)\n","179 --> (1, 53, 2048, 3)\n","180 --> (1, 57, 2048, 3)\n","181 --> (1, 55, 2048, 3)\n","182 --> (1, 45, 2048, 3)\n","183 --> (1, 44, 2048, 3)\n","184 --> (1, 26, 2048, 3)\n","185 --> (1, 24, 2048, 3)\n","186 --> (1, 55, 2048, 3)\n","187 --> (1, 40, 2048, 3)\n","188 --> (1, 33, 2048, 3)\n","189 --> (1, 40, 2048, 3)\n","190 --> (1, 49, 2048, 3)\n","191 --> (1, 46, 2048, 3)\n","192 --> (1, 48, 2048, 3)\n","193 --> (1, 42, 2048, 3)\n","194 --> (1, 37, 2048, 3)\n","195 --> (1, 24, 2048, 3)\n","196 --> (1, 36, 2048, 3)\n","197 --> (1, 52, 2048, 3)\n","198 --> (1, 44, 2048, 3)\n","199 --> (1, 22, 2048, 3)\n","200 --> (1, 47, 2048, 3)\n","201 --> (1, 24, 2048, 3)\n","202 --> (1, 53, 2048, 3)\n","203 --> (1, 54, 2048, 3)\n","204 --> (1, 42, 2048, 3)\n","205 --> (1, 41, 2048, 3)\n","206 --> (1, 49, 2048, 3)\n","207 --> (1, 54, 2048, 3)\n","208 --> (1, 44, 2048, 3)\n","209 --> (1, 48, 2048, 3)\n","210 --> (1, 41, 2048, 3)\n","211 --> (1, 30, 2048, 3)\n","212 --> (1, 29, 2048, 3)\n","213 --> (1, 31, 2048, 3)\n","214 --> (1, 31, 2048, 3)\n","215 --> (1, 53, 2048, 3)\n","216 --> (1, 44, 2048, 3)\n","217 --> (1, 54, 2048, 3)\n","218 --> (1, 21, 2048, 3)\n","219 --> (1, 48, 2048, 3)\n","220 --> (1, 39, 2048, 3)\n","221 --> (1, 58, 2048, 3)\n","222 --> (1, 40, 2048, 3)\n","223 --> (1, 28, 2048, 3)\n","224 --> (1, 71, 2048, 3)\n","225 --> (1, 30, 2048, 3)\n","226 --> (1, 38, 2048, 3)\n","227 --> (1, 42, 2048, 3)\n","228 --> (1, 49, 2048, 3)\n","229 --> (1, 37, 2048, 3)\n","230 --> (1, 40, 2048, 3)\n","231 --> (1, 44, 2048, 3)\n","232 --> (1, 34, 2048, 3)\n","233 --> (1, 37, 2048, 3)\n","234 --> (1, 42, 2048, 3)\n","235 --> (1, 37, 2048, 3)\n","236 --> (1, 63, 2048, 3)\n","237 --> (1, 46, 2048, 3)\n","238 --> (1, 46, 2048, 3)\n","239 --> (1, 31, 2048, 3)\n","240 --> (1, 66, 2048, 3)\n","241 --> (1, 34, 2048, 3)\n","242 --> (1, 42, 2048, 3)\n","243 --> (1, 30, 2048, 3)\n","244 --> (1, 50, 2048, 3)\n","245 --> (1, 47, 2048, 3)\n","246 --> (1, 46, 2048, 3)\n","247 --> (1, 44, 2048, 3)\n","248 --> (1, 37, 2048, 3)\n","249 --> (1, 50, 2048, 3)\n","250 --> (1, 27, 2048, 3)\n","251 --> (1, 22, 2048, 3)\n","252 --> (1, 38, 2048, 3)\n","253 --> (1, 35, 2048, 3)\n","254 --> (1, 34, 2048, 3)\n","255 --> (1, 38, 2048, 3)\n","256 --> (1, 23, 2048, 3)\n","257 --> (1, 29, 2048, 3)\n","258 --> (1, 32, 2048, 3)\n","259 --> (1, 33, 2048, 3)\n","260 --> (1, 18, 2048, 3)\n","261 --> (1, 48, 2048, 3)\n","262 --> (1, 44, 2048, 3)\n","263 --> (1, 40, 2048, 3)\n","264 --> (1, 39, 2048, 3)\n","265 --> (1, 39, 2048, 3)\n","266 --> (1, 53, 2048, 3)\n","267 --> (1, 38, 2048, 3)\n","268 --> (1, 35, 2048, 3)\n","269 --> (1, 39, 2048, 3)\n","270 --> (1, 43, 2048, 3)\n","271 --> (1, 27, 2048, 3)\n","272 --> (1, 39, 2048, 3)\n","273 --> (1, 45, 2048, 3)\n","274 --> (1, 38, 2048, 3)\n","275 --> (1, 51, 2048, 3)\n","276 --> (1, 56, 2048, 3)\n","277 --> (1, 28, 2048, 3)\n","278 --> (1, 20, 2048, 3)\n","279 --> (1, 53, 2048, 3)\n","280 --> (1, 20, 2048, 3)\n","281 --> (1, 41, 2048, 3)\n","282 --> (1, 28, 2048, 3)\n","283 --> (1, 34, 2048, 3)\n","284 --> (1, 36, 2048, 3)\n","285 --> (1, 35, 2048, 3)\n","286 --> (1, 42, 2048, 3)\n","287 --> (1, 30, 2048, 3)\n","288 --> (1, 34, 2048, 3)\n","289 --> (1, 43, 2048, 3)\n","290 --> (1, 37, 2048, 3)\n","291 --> (1, 31, 2048, 3)\n","292 --> (1, 41, 2048, 3)\n","293 --> (1, 70, 2048, 3)\n","294 --> (1, 51, 2048, 3)\n","295 --> (1, 35, 2048, 3)\n","296 --> (1, 49, 2048, 3)\n","297 --> (1, 40, 2048, 3)\n","298 --> (1, 47, 2048, 3)\n","299 --> (1, 29, 2048, 3)\n","300 --> (1, 32, 2048, 3)\n","301 --> (1, 28, 2048, 3)\n","302 --> (1, 51, 2048, 3)\n","303 --> (1, 52, 2048, 3)\n","304 --> (1, 30, 2048, 3)\n","305 --> (1, 42, 2048, 3)\n","306 --> (1, 43, 2048, 3)\n","307 --> (1, 28, 2048, 3)\n","308 --> (1, 37, 2048, 3)\n","309 --> (1, 34, 2048, 3)\n","310 --> (1, 38, 2048, 3)\n","311 --> (1, 32, 2048, 3)\n","312 --> (1, 52, 2048, 3)\n","313 --> (1, 33, 2048, 3)\n","314 --> (1, 28, 2048, 3)\n","315 --> (1, 38, 2048, 3)\n","316 --> (1, 31, 2048, 3)\n","317 --> (1, 46, 2048, 3)\n","318 --> (1, 31, 2048, 3)\n","319 --> (1, 49, 2048, 3)\n","320 --> (1, 35, 2048, 3)\n","321 --> (1, 37, 2048, 3)\n","322 --> (1, 32, 2048, 3)\n","323 --> (1, 34, 2048, 3)\n","324 --> (1, 52, 2048, 3)\n","325 --> (1, 42, 2048, 3)\n","326 --> (1, 35, 2048, 3)\n","327 --> (1, 21, 2048, 3)\n","328 --> (1, 41, 2048, 3)\n","329 --> (1, 43, 2048, 3)\n","330 --> (1, 29, 2048, 3)\n","331 --> (1, 39, 2048, 3)\n","332 --> (1, 39, 2048, 3)\n","333 --> (1, 44, 2048, 3)\n","334 --> (1, 37, 2048, 3)\n","335 --> (1, 60, 2048, 3)\n","336 --> (1, 52, 2048, 3)\n","337 --> (1, 33, 2048, 3)\n","338 --> (1, 51, 2048, 3)\n","339 --> (1, 15, 2048, 3)\n","340 --> (1, 35, 2048, 3)\n","341 --> (1, 38, 2048, 3)\n","342 --> (1, 32, 2048, 3)\n","343 --> (1, 37, 2048, 3)\n","344 --> (1, 31, 2048, 3)\n","345 --> (1, 39, 2048, 3)\n","346 --> (1, 40, 2048, 3)\n","347 --> (1, 50, 2048, 3)\n","348 --> (1, 40, 2048, 3)\n","349 --> (1, 49, 2048, 3)\n","350 --> (1, 33, 2048, 3)\n","351 --> (1, 37, 2048, 3)\n","352 --> (1, 27, 2048, 3)\n","353 --> (1, 26, 2048, 3)\n","354 --> (1, 35, 2048, 3)\n","355 --> (1, 39, 2048, 3)\n","356 --> (1, 48, 2048, 3)\n","357 --> (1, 41, 2048, 3)\n","358 --> (1, 24, 2048, 3)\n","359 --> (1, 32, 2048, 3)\n","360 --> (1, 29, 2048, 3)\n","361 --> (1, 50, 2048, 3)\n","362 --> (1, 35, 2048, 3)\n","363 --> (1, 49, 2048, 3)\n","364 --> (1, 34, 2048, 3)\n","365 --> (1, 38, 2048, 3)\n","366 --> (1, 36, 2048, 3)\n","367 --> (1, 43, 2048, 3)\n","368 --> (1, 39, 2048, 3)\n","369 --> (1, 39, 2048, 3)\n","370 --> (1, 44, 2048, 3)\n","371 --> (1, 53, 2048, 3)\n","372 --> (1, 51, 2048, 3)\n","373 --> (1, 31, 2048, 3)\n","374 --> (1, 42, 2048, 3)\n","375 --> (1, 27, 2048, 3)\n","376 --> (1, 38, 2048, 3)\n","377 --> (1, 49, 2048, 3)\n","378 --> (1, 57, 2048, 3)\n","379 --> (1, 49, 2048, 3)\n","380 --> (1, 45, 2048, 3)\n","381 --> (1, 28, 2048, 3)\n","382 --> (1, 33, 2048, 3)\n","383 --> (1, 51, 2048, 3)\n","384 --> (1, 47, 2048, 3)\n","385 --> (1, 36, 2048, 3)\n","386 --> (1, 41, 2048, 3)\n","387 --> (1, 28, 2048, 3)\n","388 --> (1, 34, 2048, 3)\n","389 --> (1, 38, 2048, 3)\n","390 --> (1, 37, 2048, 3)\n","391 --> (1, 37, 2048, 3)\n","392 --> (1, 53, 2048, 3)\n","393 --> (1, 100, 2048, 3)\n","394 --> (1, 49, 2048, 3)\n","395 --> (1, 39, 2048, 3)\n","396 --> (1, 62, 2048, 3)\n","397 --> (1, 32, 2048, 3)\n","398 --> (1, 54, 2048, 3)\n","399 --> (1, 56, 2048, 3)\n","400 --> (1, 37, 2048, 3)\n","401 --> (1, 56, 2048, 3)\n","402 --> (1, 47, 2048, 3)\n","403 --> (1, 43, 2048, 3)\n","404 --> (1, 38, 2048, 3)\n","405 --> (1, 30, 2048, 3)\n","406 --> (1, 39, 2048, 3)\n","407 --> (1, 26, 2048, 3)\n","408 --> (1, 34, 2048, 3)\n","409 --> (1, 55, 2048, 3)\n","410 --> (1, 28, 2048, 3)\n","411 --> (1, 44, 2048, 3)\n","412 --> (1, 37, 2048, 3)\n","413 --> (1, 28, 2048, 3)\n","414 --> (1, 47, 2048, 3)\n","415 --> (1, 28, 2048, 3)\n","416 --> (1, 45, 2048, 3)\n","417 --> (1, 13, 2048, 3)\n","418 --> (1, 31, 2048, 3)\n","419 --> (1, 45, 2048, 3)\n","420 --> (1, 29, 2048, 3)\n","421 --> (1, 39, 2048, 3)\n","422 --> (1, 44, 2048, 3)\n","423 --> (1, 31, 2048, 3)\n","424 --> (1, 57, 2048, 3)\n","425 --> (1, 40, 2048, 3)\n","426 --> (1, 45, 2048, 3)\n","427 --> (1, 38, 2048, 3)\n","428 --> (1, 39, 2048, 3)\n","429 --> (1, 42, 2048, 3)\n","430 --> (1, 30, 2048, 3)\n","431 --> (1, 68, 2048, 3)\n","432 --> (1, 41, 2048, 3)\n","433 --> (1, 33, 2048, 3)\n","434 --> (1, 20, 2048, 3)\n","435 --> (1, 35, 2048, 3)\n","436 --> (1, 35, 2048, 3)\n","437 --> (1, 42, 2048, 3)\n","438 --> (1, 45, 2048, 3)\n","439 --> (1, 45, 2048, 3)\n","440 --> (1, 40, 2048, 3)\n","441 --> (1, 46, 2048, 3)\n","442 --> (1, 28, 2048, 3)\n","443 --> (1, 31, 2048, 3)\n","444 --> (1, 38, 2048, 3)\n","445 --> (1, 21, 2048, 3)\n","446 --> (1, 26, 2048, 3)\n","447 --> (1, 54, 2048, 3)\n","448 --> (1, 37, 2048, 3)\n","449 --> (1, 34, 2048, 3)\n","450 --> (1, 35, 2048, 3)\n","451 --> (1, 24, 2048, 3)\n","452 --> (1, 46, 2048, 3)\n","453 --> (1, 22, 2048, 3)\n","454 --> (1, 38, 2048, 3)\n","455 --> (1, 16, 2048, 3)\n","456 --> (1, 20, 2048, 3)\n","457 --> (1, 49, 2048, 3)\n","458 --> (1, 26, 2048, 3)\n","459 --> (1, 27, 2048, 3)\n","460 --> (1, 55, 2048, 3)\n","461 --> (1, 59, 2048, 3)\n","462 --> (1, 33, 2048, 3)\n","463 --> (1, 40, 2048, 3)\n","464 --> (1, 38, 2048, 3)\n","465 --> (1, 39, 2048, 3)\n","466 --> (1, 60, 2048, 3)\n","467 --> (1, 48, 2048, 3)\n","468 --> (1, 34, 2048, 3)\n","469 --> (1, 50, 2048, 3)\n","470 --> (1, 37, 2048, 3)\n","471 --> (1, 55, 2048, 3)\n","472 --> (1, 41, 2048, 3)\n","473 --> (1, 39, 2048, 3)\n","474 --> (1, 35, 2048, 3)\n","475 --> (1, 44, 2048, 3)\n","476 --> (1, 41, 2048, 3)\n","477 --> (1, 25, 2048, 3)\n","478 --> (1, 40, 2048, 3)\n","479 --> (1, 49, 2048, 3)\n","480 --> (1, 41, 2048, 3)\n","481 --> (1, 37, 2048, 3)\n","482 --> (1, 71, 2048, 3)\n","483 --> (1, 30, 2048, 3)\n","484 --> (1, 26, 2048, 3)\n","485 --> (1, 66, 2048, 3)\n","486 --> (1, 40, 2048, 3)\n","487 --> (1, 28, 2048, 3)\n","488 --> (1, 48, 2048, 3)\n","489 --> (1, 40, 2048, 3)\n","490 --> (1, 49, 2048, 3)\n","491 --> (1, 38, 2048, 3)\n","492 --> (1, 48, 2048, 3)\n","493 --> (1, 40, 2048, 3)\n","494 --> (1, 45, 2048, 3)\n","495 --> (1, 38, 2048, 3)\n","496 --> (1, 37, 2048, 3)\n","497 --> (1, 36, 2048, 3)\n","498 --> (1, 31, 2048, 3)\n","499 --> (1, 30, 2048, 3)\n","500 --> (1, 35, 2048, 3)\n","501 --> (1, 47, 2048, 3)\n","502 --> (1, 40, 2048, 3)\n","503 --> (1, 33, 2048, 3)\n","504 --> (1, 19, 2048, 3)\n","505 --> (1, 20, 2048, 3)\n","506 --> (1, 72, 2048, 3)\n","507 --> (1, 45, 2048, 3)\n","508 --> (1, 32, 2048, 3)\n","509 --> (1, 51, 2048, 3)\n","510 --> (1, 34, 2048, 3)\n","511 --> (1, 57, 2048, 3)\n","512 --> (1, 24, 2048, 3)\n","513 --> (1, 18, 2048, 3)\n","514 --> (1, 67, 2048, 3)\n","515 --> (1, 36, 2048, 3)\n","516 --> (1, 36, 2048, 3)\n","517 --> (1, 44, 2048, 3)\n","518 --> (1, 43, 2048, 3)\n","519 --> (1, 60, 2048, 3)\n","520 --> (1, 37, 2048, 3)\n","521 --> (1, 44, 2048, 3)\n","522 --> (1, 31, 2048, 3)\n","523 --> (1, 35, 2048, 3)\n","524 --> (1, 31, 2048, 3)\n","525 --> (1, 45, 2048, 3)\n","526 --> (1, 40, 2048, 3)\n","527 --> (1, 41, 2048, 3)\n","528 --> (1, 29, 2048, 3)\n","529 --> (1, 45, 2048, 3)\n","530 --> (1, 42, 2048, 3)\n","531 --> (1, 38, 2048, 3)\n","532 --> (1, 34, 2048, 3)\n","533 --> (1, 26, 2048, 3)\n","534 --> (1, 42, 2048, 3)\n","535 --> (1, 41, 2048, 3)\n","536 --> (1, 51, 2048, 3)\n","537 --> (1, 36, 2048, 3)\n","538 --> (1, 37, 2048, 3)\n","539 --> (1, 42, 2048, 3)\n","540 --> (1, 34, 2048, 3)\n","541 --> (1, 58, 2048, 3)\n","542 --> (1, 33, 2048, 3)\n","543 --> (1, 33, 2048, 3)\n","544 --> (1, 58, 2048, 3)\n","545 --> (1, 52, 2048, 3)\n","546 --> (1, 34, 2048, 3)\n","547 --> (1, 51, 2048, 3)\n","548 --> (1, 47, 2048, 3)\n","549 --> (1, 44, 2048, 3)\n","550 --> (1, 33, 2048, 3)\n","551 --> (1, 51, 2048, 3)\n","552 --> (1, 255, 2048, 3)\n","553 --> (1, 38, 2048, 3)\n","554 --> (1, 57, 2048, 3)\n","555 --> (1, 31, 2048, 3)\n","556 --> (1, 36, 2048, 3)\n","557 --> (1, 34, 2048, 3)\n","558 --> (1, 41, 2048, 3)\n","559 --> (1, 41, 2048, 3)\n","560 --> (1, 31, 2048, 3)\n","561 --> (1, 28, 2048, 3)\n","562 --> (1, 51, 2048, 3)\n","563 --> (1, 50, 2048, 3)\n","564 --> (1, 48, 2048, 3)\n","565 --> (1, 33, 2048, 3)\n","566 --> (1, 33, 2048, 3)\n","567 --> (1, 33, 2048, 3)\n"]}]},{"cell_type":"code","source":["if dataset_used == \"MSR-Action3D\":\n","  num_action_classes = 20"],"metadata":{"id":"8YwvgUSsP305","executionInfo":{"status":"ok","timestamp":1715911503798,"user_tz":240,"elapsed":8,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":["### Create the MSRAction3DDataset Class to Batch Depth Map Subsequences."],"metadata":{"id":"im6UpedBG4sF"}},{"cell_type":"code","source":["if dataset_used == \"MSR-Action3D\":\n","  class MSRAction3DDataset(torch.utils.data.Dataset):\n","    def __init__(self, labels, subsequences, start_index, end_index):\n","      # Call the __init__ function of the Dataset superclass.\n","      super(MSRAction3DDataset, self).__init__()\n","\n","      # Store the labels and subsequences in class variables.\n","      self.labels = labels[start_index: end_index].to(device = this_device)\n","      self.subsequences = subsequences[start_index: end_index].to(device = this_device)\n","    def __getitem__(self, integral_key):\n","      # Implemented the __getitem__ method of this dataset.\n","      return (self.labels[integral_key], self.subsequences[integral_key])\n","    def __len__(self):\n","      # Implemented the __len__ method of this dataset.\n","      return len(self.labels)\n","    def __getitems__(self, batch_indices):\n","      # Implemented the __getitems__ method of this dataset.\n","      return (self.labels[batch_indices], self.subsequences[batch_indices])"],"metadata":{"id":"FiPDSRo6G4cC","executionInfo":{"status":"ok","timestamp":1715911503798,"user_tz":240,"elapsed":6,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":["### Construct a DataLoader to Batch Samples from MSRAction3D Dataset"],"metadata":{"id":"cYYlRBaAHSyh"}},{"cell_type":"code","execution_count":113,"metadata":{"id":"6parxh4lHbv9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715911504730,"user_tz":240,"elapsed":938,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}},"outputId":"71959a30-9718-4254-cf0d-4ee75bd91a3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2593]) torch.Size([2593, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n","torch.Size([32]) torch.Size([32, 8, 2048, 3])\n"]}],"source":["if dataset_used == \"MSR-Action3D\":\n","  # Store the number of deoth maps per clip in a variable.\n","  clip_size = 8\n","\n","  # Initialize a dictionary to hold the MSRAction3D clips and their labels.\n","  MSRAction3D_dataset = {'labels': [], 'clips': []}\n","\n","  # Loop through the depth map sequences of the MSRAction3D Dataset.\n","  for index, depth_map_sequence in enumerate(msr_action3d_depth_map_sequences):\n","    label = msr_action3d_depth_map_sequence_labels[index]\n","    num_depth_maps = depth_map_sequence.shape[1]\n","    clips = list(torch.Tensor(depth_map_sequence[0]).split(clip_size))\n","    if num_depth_maps % clip_size != 0:\n","      clips = clips[:-1]\n","    MSRAction3D_dataset['labels'].append(label + torch.zeros((num_depth_maps // clip_size, )))\n","    [MSRAction3D_dataset['clips'].append(clip[None]) for clip in clips]\n","\n","  # Concatenate all the label Tensors in the dataset together to form a single Tensor. Update the\n","  # 'labels' key with the single Tensor. Similarly, concatenate all the clip Tensors into a single\n","  # Tensor and store the Tensor at the 'clips' key in the DFAUST dataset.\n","  MSRAction3D_dataset['labels'] = torch.concatenate(MSRAction3D_dataset['labels'])\n","  MSRAction3D_dataset['clips'] = torch.concatenate(MSRAction3D_dataset['clips'])\n","\n","  # Print out the shapes of the labels and the clips.\n","  print(MSRAction3D_dataset['labels'].shape, MSRAction3D_dataset['clips'].shape)\n","\n","  # Store the training, validation and testing datasets in three separate variables.\n","  training_msraction3d_dataset = MSRAction3DDataset(\n","          MSRAction3D_dataset['labels'],\n","          MSRAction3D_dataset['clips'],\n","          0,\n","          int(MSRAction3D_dataset['labels'].shape[0] * training_split)\n","          )\n","  validation_msraction3d_dataset = MSRAction3DDataset(\n","          MSRAction3D_dataset['labels'],\n","          MSRAction3D_dataset['clips'],\n","          int(MSRAction3D_dataset['labels'].shape[0] * training_split),\n","          int(MSRAction3D_dataset['labels'].shape[0] * (training_split + validation_split))\n","          )\n","  testing_msraction3d_dataset = MSRAction3DDataset(\n","          MSRAction3D_dataset['labels'],\n","          MSRAction3D_dataset['clips'],\n","          int(MSRAction3D_dataset['labels'].shape[0] * (training_split + validation_split)),\n","          MSRAction3D_dataset['labels'].shape[0]\n","          )\n","\n","  # Store the batch size to use during training.\n","  dataset_batch_size = 32\n","\n","  # Store the objects that load the training dataset, the validation dataset and the test dataset\n","  # in variables.\n","  training_data_loader = torch.utils.data.DataLoader(\n","      dataset = training_msraction3d_dataset,\n","      batch_sampler = torch.utils.data.BatchSampler(\n","          sampler = torch.utils.data.RandomSampler(data_source = training_msraction3d_dataset),\n","          batch_size = dataset_batch_size,\n","          drop_last = True),\n","      collate_fn = lambda batch: batch\n","  )\n","  validation_data_loader = torch.utils.data.DataLoader(\n","      dataset = validation_msraction3d_dataset,\n","      batch_sampler = torch.utils.data.BatchSampler(\n","          sampler = torch.utils.data.RandomSampler(data_source = validation_msraction3d_dataset),\n","          batch_size = dataset_batch_size,\n","          drop_last = True),\n","      collate_fn = lambda batch: batch\n","  )\n","  testing_data_loader = torch.utils.data.DataLoader(\n","      dataset = testing_msraction3d_dataset,\n","      batch_sampler = torch.utils.data.BatchSampler(\n","          sampler = torch.utils.data.RandomSampler(data_source = testing_msraction3d_dataset),\n","          batch_size = dataset_batch_size,\n","          drop_last = True),\n","      collate_fn = lambda batch: batch\n","  )\n","\n","  # Delete the old MSRAction3D dataset variables to save memory.\n","  # del msraction3d_dataset, msraction3d_data_loader\n","\n","  # Print out the shapes of the batches in the MSRAction3D dataset.\n","  for batch in training_data_loader:\n","    labels, clips = batch\n","    print(labels.shape, clips.shape)"]},{"cell_type":"markdown","metadata":{"id":"FSGPaMHzdrt7"},"source":["## DFAUST"]},{"cell_type":"markdown","source":["### Load the DFAUST dataset"],"metadata":{"id":"i-w2LU1J26_H"}},{"cell_type":"code","execution_count":114,"metadata":{"id":"bDDypQndds8C","executionInfo":{"status":"ok","timestamp":1715911504731,"user_tz":240,"elapsed":15,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"DFAUST\":\n","  import pickle\n","\n","  # Load the DFAUST point cloud videos of the subject 50020 from Google Drive.\n","  dfaust_path = '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/DFAUST/downloads/scans/50020/'\n","  with open(dfaust_path + '50020.pickle' , mode = 'rb') as dfaust_pickle_file:\n","    dfaust_pt_cld_videos_labels = pickle.load(dfaust_pickle_file)\n","\n","  # Store the number of action classes in the DFAUST dataset in a variable.\n","  num_action_classes = 13"]},{"cell_type":"markdown","metadata":{"id":"lsQFuIUhx9Fu"},"source":["### Downsample Each Point Cloud Frame"]},{"cell_type":"markdown","source":["Downsampling each point cloud frame that has around 100K points to have a number of points that isn't too large to do computation on."],"metadata":{"id":"H8pbLIZt2FVn"}},{"cell_type":"code","execution_count":115,"metadata":{"id":"Ag1dfgMayFI5","executionInfo":{"status":"ok","timestamp":1715911504731,"user_tz":240,"elapsed":13,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"DFAUST\":\n","  # Initialize a random number generator.\n","  random_number_generator = NumPy.random.default_rng()\n","\n","  # Loop through the keys of the DFAUST dataset dictionary.\n","  for action in dfaust_pt_cld_videos_labels:\n","    # Get the label to video dictionary of the current action.\n","    label_to_video_dict = dfaust_pt_cld_videos_labels[action]\n","\n","    # Print out information about the current action and its label to video dictionary.\n","    print(\"Action: {:20s} Label: {:2d} Video Frame Length: {:3d}\".format(\n","        action.name,\n","        label_to_video_dict['label'],\n","        len(label_to_video_dict['video'])\n","        )\n","    )\n","\n","    # Store the number of frames that are in the video of the current action in a variable.\n","    number_of_frames_in_video = len(label_to_video_dict['video'])\n","\n","    # Loop through each frame of the video of the current action.\n","    for i in range(number_of_frames_in_video):\n","      # Uniformly randomly sample a small number of points from the current\n","      # point cloud frame and replace the current point cloud frame with the\n","      # random sample. Output the change in the dimensions of the current frame.\n","      print(\"{}->\".format(label_to_video_dict['video'][i].shape), end = '')\n","      dfaust_pt_cld_videos_labels[action]['video'][i] = random_number_generator.choice(\n","        label_to_video_dict['video'][i],\n","        size = point_cloud_frame_subsampling_size_DFAUST,\n","        replace = False,\n","        axis = 0\n","        )\n","      print(\"{}\".format(dfaust_pt_cld_videos_labels[action]['video'][i].shape), end = '')\n","\n","      if i < number_of_frames_in_video - 1:\n","        # If the current frame isn't the last frame, print a string that separates the output.\n","        print(\", \", end = '')\n","\n","    # Concatenate the samples of each point cloud frames of the current video together to make\n","    # a new video. Replace the old video with the new video in the DFAUST dataset.\n","    dfaust_pt_cld_videos_labels[action]['video'] = torch.Tensor(dfaust_pt_cld_videos_labels[action]['video'])\n","\n","    # Print out information about the current action and its label to video dictionary.\n","    print(\"\\nAction: {:20s} Label: {:2d} Video Shape: {}\\n\\n\".format(\n","      action.name,\n","      label_to_video_dict['label'],\n","      tuple(dfaust_pt_cld_videos_labels[action]['video'].shape)\n","      )\n","    )"]},{"cell_type":"markdown","source":["### DFAUST Dataset Class for Batching Video Clips"],"metadata":{"id":"NytwlB0A4SDT"}},{"cell_type":"code","execution_count":116,"metadata":{"id":"1xJkdQPF4xo1","executionInfo":{"status":"ok","timestamp":1715911504731,"user_tz":240,"elapsed":13,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"DFAUST\":\n","  class DFAUSTDataset(torch.utils.data.Dataset):\n","    def __init__(self, labels, clips, start_index, end_index):\n","      # Call the __init__ function of the Dataset superclass.\n","      super(DFAUSTDataset, self).__init__()\n","\n","      # Store the labels and video clips in class variables.\n","      self.labels = labels.to(device = this_device)[start_index:end_index]\n","      self.clips = clips.to(device = this_device)[start_index:end_index]\n","    def __getitem__(self, integral_key):\n","      # Implemented the __getitem__ method of this dataset.\n","      return (self.labels[integral_key], self.clips[integral_key])\n","    def __len__(self):\n","      # Implemented the __len__ method of this dataset.\n","      return len(self.labels)\n","    def __getitems__(self, batch_indices):\n","      # Implemented the __getitems__ method of this dataset.\n","      return (self.labels[batch_indices], self.clips[batch_indices])"]},{"cell_type":"markdown","source":["### Create video clips from the videos of the DFAUST dataset"],"metadata":{"id":"Dk6yraIR6LPQ"}},{"cell_type":"code","execution_count":117,"metadata":{"id":"CQDoEogw4B44","executionInfo":{"status":"ok","timestamp":1715911504732,"user_tz":240,"elapsed":13,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["if dataset_used == \"DFAUST\":\n","  # Store the number of frames per clip in a variable.\n","  clip_size = 64\n","\n","  # Initialize a dictionary to hold the DFAUST clips and their labels.\n","  dfaust_dataset = {'labels': [], 'clips': []}\n","\n","  # Loop over actions in the DFAUST dataset.\n","  for action in dfaust_pt_cld_videos_labels:\n","    label_to_video_dict = dfaust_pt_cld_videos_labels[action]\n","    label = label_to_video_dict['label']\n","    video = label_to_video_dict['video']\n","    num_frames_in_current_video = video.shape[0]\n","    clips = list(video.split(clip_size))\n","    if num_frames_in_current_video % clip_size != 0:\n","      clips = clips[:-1]\n","    dfaust_dataset['labels'].append(label + torch.zeros((num_frames_in_current_video // clip_size, )))\n","    [dfaust_dataset['clips'].append(clip.unsqueeze(0)) for clip in clips]\n","\n","  # Concatenate all the label Tensors in the dataset together to form a single Tensor. Update the\n","  #'labels' key with the single Tensor. Similarly, concatenate all the clip Tensors into a single\n","  # Tensor and store the Tensor at the 'clips' key in the DFAUST dataset.\n","  dfaust_dataset['labels'] = torch.concatenate(dfaust_dataset['labels'])\n","  dfaust_dataset['clips'] = torch.concatenate(dfaust_dataset['clips'])\n","\n","  # Print out the shapes of the labels and the clips.\n","  print(dfaust_dataset['labels'].shape, dfaust_dataset['clips'].shape)\n","\n","  # Store the training, validation and testing datasets in three separate variables.\n","  training_dfaust_dataset = DFAUSTDataset(\n","          dfaust_dataset['labels'],\n","          dfaust_dataset['clips'],\n","          0,\n","          int(dfaust_dataset['labels'].shape[0] * training_split)\n","          )\n","  validation_dfaust_dataset = DFAUSTDataset(\n","          dfaust_dataset['labels'],\n","          dfaust_dataset['clips'],\n","          int(dfaust_dataset['labels'].shape[0] * training_split),\n","          int(dfaust_dataset['labels'].shape[0] * (training_split + validation_split))\n","          )\n","  testing_dfaust_dataset = DFAUSTDataset(\n","          dfaust_dataset['labels'],\n","          dfaust_dataset['clips'],\n","          int(dfaust_dataset['labels'].shape[0] * (training_split + validation_split)),\n","          dfaust_dataset['labels'].shape[0]\n","          )\n","\n","  # Store the batch size to use during training.\n","  dataset_batch_size = 4\n","\n","  # Store the objects that load the training dataset, the validation dataset and the test dataset\n","  # in variables.\n","  training_data_loader = torch.utils.data.DataLoader(\n","      dataset = training_dfaust_dataset,\n","      batch_sampler = torch.utils.data.BatchSampler(\n","          sampler = torch.utils.data.RandomSampler(data_source = training_dfaust_dataset),\n","          batch_size = dataset_batch_size,\n","          drop_last = True),\n","      collate_fn = lambda batch: batch\n","  )\n","  validation_data_loader = torch.utils.data.DataLoader(\n","      dataset = validation_dfaust_dataset,\n","      batch_sampler = torch.utils.data.BatchSampler(\n","          sampler = torch.utils.data.RandomSampler(data_source = validation_dfaust_dataset),\n","          batch_size = dataset_batch_size,\n","          drop_last = True),\n","      collate_fn = lambda batch: batch\n","  )\n","  testing_data_loader = torch.utils.data.DataLoader(\n","      dataset = testing_dfaust_dataset,\n","      batch_sampler = torch.utils.data.BatchSampler(\n","          sampler = torch.utils.data.RandomSampler(data_source = testing_dfaust_dataset),\n","          batch_size = dataset_batch_size,\n","          drop_last = True),\n","      collate_fn = lambda batch: batch\n","  )\n","\n","  # Delete the old DFAUST dataset variables to save memory.\n","  #del dfaust_dataset, dfaust_pt_cld_videos_labels\n","\n","  # Print out the shapes of the batches in the DFAUST dataset.\n","  for batch in training_data_loader:\n","    labels, clips = batch\n","    print(labels.shape, clips.shape)"]},{"cell_type":"markdown","metadata":{"id":"YT6cBo1vV-kL"},"source":["# General Code Cells"]},{"cell_type":"markdown","metadata":{"id":"r0ya9Hr7FMUl"},"source":["torch.split, torch.cat, modifying tensors, inf, grad, tuples, torch.flatten, torch.reshape"]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1715911504732,"user":{"displayName":"Mathew John","userId":"02352606196281189679"},"user_tz":240},"id":"DSGPzcPdFPmt","outputId":"ec275f1b-61bc-43d3-d1fb-29e2c4e728bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 10]) torch.Size([10, 10]) torch.Size([110, 10])\n","torch.Size([100]) torch.Size([10]) torch.Size([110])\n","torch.Size([100]) torch.Size([10])\n","torch.Size([4, 30])\n"]}],"source":["tsor1 = torch.rand((100, 10))\n","tsor2 = torch.rand((10, 10))\n","tsor3 = torch.cat((tsor1, tsor2))\n","print(tsor1.shape, tsor2.shape, tsor3.shape)\n","\n","tsor1 = torch.rand((100,))\n","tsor2 = torch.rand((10, ))\n","tsor3 = torch.cat((tsor1, tsor2), dim = 0)\n","print(tsor1.shape, tsor2.shape, tsor3.shape)\n","\n","tsor1_cp, tsor2_cp = torch.split(tsor3, [100, 10])\n","print(tsor1_cp.shape, tsor2_cp.shape)\n","\n","print(torch.rand((4, 5, 6)).flatten(start_dim = 1).shape)"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1715911504732,"user":{"displayName":"Mathew John","userId":"02352606196281189679"},"user_tz":240},"id":"obp3Zj9VeD9T","outputId":"59058804-278d-4493-e145-00c22ce2b4b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[7.9919e+04, 8.0642e+04, 8.4637e+04],\n","        [1.5815e-01, 7.0407e-01, 6.1994e-02],\n","        [8.6123e-02, 6.5282e-01, 6.2582e-01],\n","        [1.2195e-01, 7.2022e-01, 3.1094e-01],\n","        [5.7357e-01, 2.0844e-01, 2.1635e-01],\n","        [2.1254e-01, 2.7206e-03, 9.7142e-01],\n","        [9.0655e-01, 2.9097e-01, 1.5843e-01],\n","        [5.2971e-01, 7.4993e-01, 8.0825e-01],\n","        [3.0273e-01, 4.5733e-01, 2.8576e-01],\n","        [8.2918e-01, 8.9190e-01, 7.3537e-01]])\n","[tensor([7.9919e+09, 8.0642e+09, 8.4637e+09]), tensor([0.1581, 0.7041, 0.0620]), tensor([0.0861, 0.6528, 0.6258]), tensor([0.1220, 0.7202, 0.3109]), tensor([0.5736, 0.2084, 0.2164]), tensor([0.2125, 0.0027, 0.9714]), tensor([0.9065, 0.2910, 0.1584]), tensor([0.5297, 0.7499, 0.8082]), tensor([0.3027, 0.4573, 0.2858]), tensor([0.8292, 0.8919, 0.7354])]\n","tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [2., 2., 2., 2.],\n","        [2., 2., 2., 2.],\n","        [2., 2., 2., 2.],\n","        [2., 2., 2., 2.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.],\n","        [3., 3., 3., 3.]]) torch.Size([12, 4])\n","inf\n","torch.Size([3, 3, 2, 2]) torch.Size([2, 2])\n","None None tensor([[[[7.4090, 7.6024, 7.5994, 7.4048],\n","          [7.5997, 7.7980, 7.7951, 7.5956],\n","          [7.5974, 7.7959, 7.7927, 7.5934],\n","          [7.4039, 7.5977, 7.5945, 7.4006]],\n","\n","         [[7.4176, 7.6112, 7.6082, 7.4133],\n","          [7.6085, 7.8070, 7.8041, 7.6044],\n","          [7.6061, 7.8049, 7.8017, 7.6022],\n","          [7.4124, 7.6065, 7.6033, 7.4091]],\n","\n","         [[7.3041, 7.4948, 7.4918, 7.2998],\n","          [7.4921, 7.6876, 7.6847, 7.4880],\n","          [7.4898, 7.6855, 7.6824, 7.4858],\n","          [7.2990, 7.4901, 7.4869, 7.2956]]],\n","\n","\n","        [[[7.4090, 7.6024, 7.5994, 7.4048],\n","          [7.5997, 7.7980, 7.7951, 7.5956],\n","          [7.5974, 7.7959, 7.7927, 7.5934],\n","          [7.4039, 7.5977, 7.5945, 7.4006]],\n","\n","         [[7.4176, 7.6112, 7.6082, 7.4133],\n","          [7.6085, 7.8070, 7.8041, 7.6044],\n","          [7.6061, 7.8049, 7.8017, 7.6022],\n","          [7.4124, 7.6065, 7.6033, 7.4091]],\n","\n","         [[7.3041, 7.4948, 7.4918, 7.2998],\n","          [7.4921, 7.6876, 7.6847, 7.4880],\n","          [7.4898, 7.6855, 7.6824, 7.4858],\n","          [7.2990, 7.4901, 7.4869, 7.2956]]],\n","\n","\n","        [[[7.4090, 7.6024, 7.5994, 7.4048],\n","          [7.5997, 7.7980, 7.7951, 7.5956],\n","          [7.5974, 7.7959, 7.7927, 7.5934],\n","          [7.4039, 7.5977, 7.5945, 7.4006]],\n","\n","         [[7.4176, 7.6112, 7.6082, 7.4133],\n","          [7.6085, 7.8070, 7.8041, 7.6044],\n","          [7.6061, 7.8049, 7.8017, 7.6022],\n","          [7.4124, 7.6065, 7.6033, 7.4091]],\n","\n","         [[7.3041, 7.4948, 7.4918, 7.2998],\n","          [7.4921, 7.6876, 7.6847, 7.4880],\n","          [7.4898, 7.6855, 7.6824, 7.4858],\n","          [7.2990, 7.4901, 7.4869, 7.2956]]]])\n","tensor([[ 0.0234,  0.1169,  0.1706,  0.1478,  0.1308,  0.0255,  0.1152,  0.0865,\n","          0.0290,  0.1518],\n","        [ 0.0026,  0.0129,  0.0188,  0.0163,  0.0144,  0.0028,  0.0127,  0.0095,\n","          0.0032,  0.0167],\n","        [ 0.0039,  0.0192,  0.0280,  0.0243,  0.0215,  0.0042,  0.0189,  0.0142,\n","          0.0048,  0.0249],\n","        [ 0.0015,  0.0076,  0.0111,  0.0096,  0.0085,  0.0017,  0.0075,  0.0056,\n","          0.0019,  0.0098],\n","        [-0.0044, -0.0221, -0.0323, -0.0280, -0.0247, -0.0048, -0.0218, -0.0164,\n","         -0.0055, -0.0287],\n","        [ 0.0163,  0.0812,  0.1185,  0.1026,  0.0908,  0.0177,  0.0800,  0.0600,\n","          0.0202,  0.1054],\n","        [ 0.0213,  0.1063,  0.1550,  0.1343,  0.1188,  0.0232,  0.1047,  0.0786,\n","          0.0264,  0.1379],\n","        [ 0.0174,  0.0869,  0.1267,  0.1098,  0.0971,  0.0189,  0.0855,  0.0642,\n","          0.0216,  0.1127],\n","        [ 0.0148,  0.0739,  0.1078,  0.0934,  0.0826,  0.0161,  0.0728,  0.0546,\n","          0.0183,  0.0959],\n","        [ 0.0131,  0.0651,  0.0950,  0.0823,  0.0728,  0.0142,  0.0641,  0.0481,\n","          0.0162,  0.0845],\n","        [-0.0180, -0.0899, -0.1312, -0.1137, -0.1006, -0.0196, -0.0886, -0.0665,\n","         -0.0223, -0.1167],\n","        [ 0.0148,  0.0740,  0.1079,  0.0935,  0.0827,  0.0161,  0.0728,  0.0547,\n","          0.0184,  0.0960],\n","        [ 0.0167,  0.0834,  0.1216,  0.1054,  0.0932,  0.0182,  0.0821,  0.0616,\n","          0.0207,  0.1082],\n","        [ 0.0240,  0.1197,  0.1746,  0.1513,  0.1338,  0.0261,  0.1179,  0.0885,\n","          0.0297,  0.1553],\n","        [-0.0200, -0.0999, -0.1457, -0.1263, -0.1117, -0.0218, -0.0984, -0.0738,\n","         -0.0248, -0.1296],\n","        [ 0.0149,  0.0743,  0.1084,  0.0939,  0.0831,  0.0162,  0.0732,  0.0549,\n","          0.0184,  0.0964],\n","        [-0.0197, -0.0981, -0.1432, -0.1240, -0.1097, -0.0214, -0.0966, -0.0726,\n","         -0.0244, -0.1273],\n","        [ 0.0230,  0.1149,  0.1677,  0.1453,  0.1285,  0.0250,  0.1132,  0.0850,\n","          0.0285,  0.1492],\n","        [-0.0075, -0.0375, -0.0548, -0.0475, -0.0420, -0.0082, -0.0370, -0.0278,\n","         -0.0093, -0.0487],\n","        [ 0.0161,  0.0803,  0.1172,  0.1015,  0.0898,  0.0175,  0.0791,  0.0594,\n","          0.0199,  0.1042],\n","        [-0.0065, -0.0323, -0.0471, -0.0408, -0.0361, -0.0070, -0.0318, -0.0239,\n","         -0.0080, -0.0419],\n","        [ 0.0066,  0.0329,  0.0479,  0.0415,  0.0367,  0.0072,  0.0324,  0.0243,\n","          0.0082,  0.0426],\n","        [ 0.0090,  0.0450,  0.0657,  0.0569,  0.0504,  0.0098,  0.0444,  0.0333,\n","          0.0112,  0.0585],\n","        [ 0.0167,  0.0834,  0.1216,  0.1054,  0.0933,  0.0182,  0.0821,  0.0617,\n","          0.0207,  0.1082],\n","        [ 0.0067,  0.0336,  0.0490,  0.0425,  0.0376,  0.0073,  0.0331,  0.0249,\n","          0.0083,  0.0436],\n","        [ 0.0121,  0.0601,  0.0877,  0.0760,  0.0672,  0.0131,  0.0592,  0.0444,\n","          0.0149,  0.0780],\n","        [-0.0198, -0.0989, -0.1443, -0.1250, -0.1106, -0.0216, -0.0974, -0.0731,\n","         -0.0246, -0.1284],\n","        [ 0.0141,  0.0702,  0.1025,  0.0888,  0.0786,  0.0153,  0.0692,  0.0519,\n","          0.0174,  0.0912],\n","        [-0.0096, -0.0479, -0.0699, -0.0606, -0.0536, -0.0104, -0.0472, -0.0354,\n","         -0.0119, -0.0622],\n","        [-0.0102, -0.0511, -0.0745, -0.0646, -0.0571, -0.0111, -0.0503, -0.0378,\n","         -0.0127, -0.0663]]) None tensor([[0.1357, 0.6768, 0.9873, 0.8555, 0.7569, 0.1475, 0.6665, 0.5004, 0.1680,\n","         0.8783]])\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0.]])\n","3 1\n","(1, 2, 3) (tensor([7.9919e+09, 8.0642e+09, 8.4637e+09]), tensor([0.1581, 0.7041, 0.0620]), tensor([0.0861, 0.6528, 0.6258]), tensor([0.1220, 0.7202, 0.3109]), tensor([0.5736, 0.2084, 0.2164]), tensor([0.2125, 0.0027, 0.9714]), tensor([0.9065, 0.2910, 0.1584]), tensor([0.5297, 0.7499, 0.8082]), tensor([0.3027, 0.4573, 0.2858]), tensor([0.8292, 0.8919, 0.7354]))\n","torch.Size([3, 4, 5, 1])\n","tensor([[[5.4482e-01, 3.3795e-02],\n","         [3.0762e-01, 3.3306e-01],\n","         [1.5600e-01, 8.2038e-01],\n","         [4.8038e-01, 5.2906e-01],\n","         [2.5987e-01, 8.2360e-01],\n","         [2.0804e-01, 2.8843e-04]]])\n","tensor([[[[5.4482e-01, 3.3795e-02],\n","          [3.0762e-01, 3.3306e-01],\n","          [1.5600e-01, 8.2038e-01]],\n","\n","         [[4.8038e-01, 5.2906e-01],\n","          [2.5987e-01, 8.2360e-01],\n","          [2.0804e-01, 2.8843e-04]]]])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-119-0ee22555efad>:31: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n","  print(output.grad, conv_1.weight.grad, conv_2.weight.grad)\n"]}],"source":["def modify_list_or_tensor(x):\n","  x[0] *= 100000\n","  return x\n","\n","tsor1 = torch.rand((10, 3))\n","modify_list_or_tensor(tsor1)\n","print(tsor1)\n","\n","list1 = list(tsor1)\n","list1 = modify_list_or_tensor(list1)\n","print(list1)\n","\n","list2 = [tsor1.new_full((4, 4), 1), tsor1.new_full((4, 4), 2), tsor1.new_full((4, 4), 3)]\n","tsor2 = torch.cat(list2)\n","print(tsor2, tsor2.shape)\n","\n","print(float(\"infinity\"))\n","\n","tsor3 = torch.rand((3, 4, 5))\n","conv_1 = tnn.Conv2d(3, 3, 2, 1, 1)\n","conv_2 = tnn.Conv2d(3, 3, 4, 1, 1)\n","conv_1.weight.requires_grad = False\n","conv_1.weight *= 0\n","tsor4 = torch.Tensor([[4, 4], [4, 4]])\n","print(conv_1.weight.shape, tsor4.shape)\n","conv_1.weight += tsor4\n","conv_1.weight\n","relu_1 = tnn.ReLU()\n","output = torch.mean(conv_2(relu_1(conv_1(torch.rand((10, 3,  40, 40))))))\n","output.backward()\n","print(output.grad, conv_1.weight.grad, conv_2.weight.grad)\n","\n","fc_1 = tnn.Linear(10, 30)\n","fc_2 = tnn.Linear(30, 1)\n","fc_2_weight = fc_2.weight\n","fc_2.weight.requires_grad = False\n","input = torch.rand((1, 10))\n","input_tiled = input.T + torch.zeros((10, 30))\n","fc_2(fc_1(input)).backward()\n","print(fc_1.weight.grad, fc_2.weight.grad, input)\n","print(input_tiled * (fc_2_weight) - fc_1.weight.grad.T)\n","\n","tuple1 = (1, 2, 3)\n","print(len(tuple1), tuple1[0])\n","print(tuple(list(tuple1)), tuple(tsor1))\n","\n","max_pool_2d = tnn.MaxPool2d((1, 10))\n","input = torch.rand((3, 4, 5, 10))\n","print(max_pool_2d(input).shape)\n","\n","input = torch.rand((1, 6, 2))\n","print(input)\n","input = input.reshape((1, 2, 3, 2))\n","print(input)"]},{"cell_type":"markdown","metadata":{"id":"rvqhhPUNTOXu"},"source":["# Farthest Point Sampling (FPS)\n","FPS improves the computational efficiency of the algorithm. Using all the points in an initial point cloud frame is unnecessary because the t-patches of these points will overlap."]},{"cell_type":"markdown","source":["### Vanilla FPS"],"metadata":{"id":"9OV7GIyKP_iE"}},{"cell_type":"code","execution_count":120,"metadata":{"id":"2pz0ykI5laIH","executionInfo":{"status":"ok","timestamp":1715911504732,"user_tz":240,"elapsed":6,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["def FPS(frame, M):\n","  # Initialize a variable to hold the points that were\n","  # subasampled.\n","  subsampled_points = None\n","\n","  for i in range(M):\n","    # Print the current progress of subsampling.\n","    # print(\"FPS Progress: {:%}\".format((i + 1)/ M))\n","\n","    # Store the shape of the frame Tensor in\n","    # variables.\n","    N, D = frame.shape\n","\n","    if subsampled_points is not None:\n","      # If the subsampled_points variable is not None,\n","      # then initialize a variable to hold the sum of the L2 distances of each\n","      # point in the frame from all the subsampled points.\n","      distances_of_remaining_points_from_subsampled_points = []\n","\n","      for j in range(N):\n","        # Append the sum of the L2 distances of frame[j] from all the subsampled points.\n","        distances_of_remaining_points_from_subsampled_points.append(\n","            torch.sum(\n","                torch.sqrt(\n","                    torch.sum(\n","                        (frame[j].unsqueeze(0) - subsampled_points) ** 2,\n","                        dim = 1\n","                        )\n","                    )\n","                )\n","            )\n","\n","      # Find the index of the point among the remaining points that is the farthest from the\n","      # points that have been selected already.\n","      max_distance_point_index = torch.argmax(torch.Tensor(distances_of_remaining_points_from_subsampled_points))\n","\n","      # Concatenate the selected point with the subsampled_points variable.\n","      subsampled_points = torch.cat((subsampled_points, frame[max_distance_point_index].unsqueeze(0)))\n","\n","      # Split the frame Tensor into 3 parts. The first part is made of the first max_distance_point_index\n","      # points in frame. The second part consists of the point at max_distance_point_index and\n","      # the third part consists of the rest of the points in frame.\n","      frame_split_1, closest_point, frame_split_3 = torch.split(frame, [max_distance_point_index, 1, N - 1 - max_distance_point_index])\n","\n","      # Concatenate the first part and the last part together, reassign frame\n","      # with the result of concatenation, to remove the selected point from frame.\n","      frame = torch.cat((frame_split_1, frame_split_3))\n","    else:\n","      # If the subsampled_points variable is None, then choose a random point from the first point cloud frame.\n","      random_index = torch.randint(0, N, (1, )).item()\n","\n","      # Select the random point from frame and store it in the subsampled_points variable.\n","      subsampled_points = frame[random_index].unsqueeze(0)\n","\n","      # Split the frame Tensor into 3 parts. The first part is made of first random_index\n","      # points in frame. The second part consists of the point at random_index and\n","      # the third part consists of the rest of the points in frame.\n","      frame_split_1, random_point, frame_split_3 = torch.split(frame, [random_index, 1, N - 1 - random_index])\n","\n","      # Concatenate the first part and the last part together, reassign frame\n","      # with the result of concatenation, to remove the random point from frame.\n","      frame = torch.cat((frame_split_1, frame_split_3))\n","\n","  return subsampled_points"]},{"cell_type":"markdown","source":["Backward Pass using FPS"],"metadata":{"id":"fIvUNwC5AgXd"}},{"cell_type":"code","source":["input = torch.randn((20, 10))\n","input.requires_grad =True\n","lin1 = tnn.Linear(10, 30)\n","m = 4\n","lin1_output = lin1(FPS(input, m))\n","lin2 = tnn.Linear(30, 10)\n","output = lin2(lin1_output)\n","out_loss = tnn.MSELoss()\n","loss_val = out_loss(output, torch.zeros((m, 10)))\n","loss_val.backward()\n","print(input.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUPgVRpG6z9Y","executionInfo":{"status":"ok","timestamp":1715911505381,"user_tz":240,"elapsed":57,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}},"outputId":"06f26343-8d6c-445d-d067-096b61737fce"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-1.1623e-04, -5.7634e-03,  8.6144e-03,  1.9930e-03,  4.1224e-03,\n","         -1.6721e-03, -3.2604e-03,  9.3194e-04, -3.4247e-03,  2.3155e-03],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-9.4959e-04, -3.1939e-03,  4.2693e-03,  7.7647e-03,  3.9996e-03,\n","         -1.0014e-03,  7.5572e-05, -1.7359e-03, -8.0384e-04,  3.0900e-03],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-6.7931e-04, -5.8430e-03,  6.9393e-03,  7.3062e-03,  2.0758e-04,\n","         -2.1513e-04, -3.4492e-03, -5.1345e-03, -9.4246e-04,  4.9717e-03],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n","        [-3.2147e-03,  1.0956e-02, -3.1685e-03, -2.2706e-02, -7.6722e-03,\n","          7.7650e-03, -7.3600e-03,  5.0782e-03, -4.6847e-04, -1.0805e-02]])\n"]}]},{"cell_type":"markdown","source":["### Scikit-Learn K-Means Clustering\n"],"metadata":{"id":"mF75gkL7Miij"}},{"cell_type":"code","source":["import sklearn.cluster\n","\n","def KMeansSampling(frame, M):\n","  # Initialize a KMeans sampler.\n","  k_means_sampler = sklearn.cluster.KMeans(n_clusters = M, n_init = 10)\n","\n","  # Fit the KMeans sampler to the input frame.\n","  k_means_sampler.fit(frame.cpu().detach().numpy())\n","\n","  # Return the centers of the clusters of the frame as a Tensor.\n","  return torch.Tensor(k_means_sampler.cluster_centers_)"],"metadata":{"id":"BahYoQjnM6nE","executionInfo":{"status":"ok","timestamp":1715911505381,"user_tz":240,"elapsed":56,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bszGiXq9Tjy-"},"source":["# T-Patch Extractor"]},{"cell_type":"markdown","metadata":{"id":"HZW-Q-q7YchH"},"source":["## K-Nearest Neighbor Classifier"]},{"cell_type":"markdown","source":["### Vanilla KNN"],"metadata":{"id":"sgSuEJWeP8tF"}},{"cell_type":"code","execution_count":123,"metadata":{"id":"WfBv81XYYeW1","executionInfo":{"status":"ok","timestamp":1715911505381,"user_tz":240,"elapsed":56,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["def KNN(data, query, K):\n","  # Compute the L2 distances of the query point from the data points.\n","  L2_distances_from_query = torch.sqrt(torch.sum((data - query) ** 2, dim = 1)).to(this_device)\n","\n","  # Initialize a variable to hold the K nearest neighbors of the query point.\n","  k_nearest_neighbors = None\n","\n","  # Iterate K times.\n","  for i in range(K):\n","    # Store the index of the point in the data that is the (i + 1)^th closest to the query point\n","    # in a variable.\n","    min_distance_index = torch.argmin(L2_distances_from_query).to(this_device)\n","\n","    # Store the point in the data that is the (i + 1)^th closest to the query point\n","    # in a variable.\n","    closest_point = data[min_distance_index].unsqueeze(0).to(this_device)\n","\n","    # Update the L2 distance of the point that was the (i + 1)^th closest to\n","    # the query point in the L2_distances_from_query variable with infinity.\n","    L2_distances_from_query[min_distance_index] = float(\"infinity\")\n","\n","    if k_nearest_neighbors is not None:\n","      # If the k_nearest_neighbors variable is not None, then\n","      # concatenate the point in the data that is the (i + 1)^th closest to the query point\n","      # with the k_nearest_neighbors variable. Reassign the k_nearest_neighbors\n","      # variable with the result of the concatenation.\n","      k_nearest_neighbors = torch.cat((k_nearest_neighbors, closest_point)).to(this_device)\n","    else:\n","      # If the k_nearest_neighbors variable is None, then\n","      # assign it with the point in the data that is the closest to the query point.\n","      k_nearest_neighbors = closest_point\n","\n","  return k_nearest_neighbors"]},{"cell_type":"markdown","source":["### Scikit-Learn Ball Tree K-Nearest Neighbors"],"metadata":{"id":"wX0DAiWoNuw6"}},{"cell_type":"code","source":["import sklearn.neighbors\n","\n","def BallTreeKNN(data, query, K):\n","  # Initialize a Ball Tree to do the KNN algorithm\n","  ball_tree_knn = sklearn.neighbors.BallTree(data.cpu().numpy())\n","\n","  # Query the Ball Tree to get the K nearest neighbors of the query vector.\n","  k_nearest_neighbors = data[torch.Tensor(ball_tree_knn.query(query.numpy(), k = K, return_distance = False))]\n","\n","  return k_nearest_neighbors.to(device = this_device)"],"metadata":{"id":"PedER218ODPT","executionInfo":{"status":"ok","timestamp":1715911505381,"user_tz":240,"elapsed":55,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":124,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qP8CEmBPTrC2"},"source":["## Forward and Backward T-Patch Extractors"]},{"cell_type":"code","execution_count":125,"metadata":{"id":"qMl2NaG5djaP","executionInfo":{"status":"ok","timestamp":1715911505381,"user_tz":240,"elapsed":55,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["def extract_patches_in_frame(S, t, t_patches, query_points_frame_t, gaussian_noise_mu, gaussian_noise_std, K):\n","  # Store the current point cloud frame in a variable.\n","  current_frame = S[t]\n","\n","  # Initialize variables to hold the M patches in the current frame formed by the M query points\n","  # and the M query points of the next frame.\n","  P_t = []\n","  query_points_frame_t_plus_1 = []\n","\n","  # Iterate over the M query points for the current point cloud frame.\n","  for x_q_previous_t in query_points_frame_t:\n","    # Store a small Gaussian noise in a variable.\n","    gaussian_noise = torch.normal(gaussian_noise_mu, gaussian_noise_std, (1, )).to(this_device)\n","\n","    # Store the patch of the current query point of the current frame\n","    # in a variable.\n","    psi_t_q = KNN(current_frame, x_q_previous_t + gaussian_noise, K).unsqueeze(0).to(this_device)\n","\n","    # Store the query point x_q^t of the next frame in a variable.\n","    x_q_t = KNN(current_frame, x_q_previous_t, 1).to(this_device)\n","\n","    # Append the query point x_q^t to the list of query points for the next frame.\n","    query_points_frame_t_plus_1.append(x_q_t)\n","\n","    # Append the patch made by the current query point of the current frame to the list of patches formed by the\n","    # query points of the current frame.\n","    P_t.append(psi_t_q)\n","\n","  # Store the M patches in the current frame formed by the M query points\n","  # in the t_patches variable at the index t.\n","  t_patches[t] = torch.cat(P_t).to(this_device)\n","\n","  return query_points_frame_t_plus_1"]},{"cell_type":"code","execution_count":126,"metadata":{"id":"GPsSv338TCLT","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":56,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["def extract_forward_t_patches(S, M, K, subsampler, gaussian_noise_mu, gaussian_noise_std, verbose):\n","  # Print that the forward t-patches are being extracted.\n","  print(\"Extracting forward t-patches.\") if verbose else print('', end = '')\n","\n","  # Store the size of S along dimensions 0, 1 and 3 in variables.\n","  N_S = S.shape[0]\n","  dim_1_size = S.shape[1]\n","  dim_3_size = S.shape[3]\n","\n","  # Initialize a variable to hold the forward t-patches of the input point cloud sequences.\n","  point_cloud_sequences_forward_t_patches = torch.zeros((N_S, dim_1_size, M, K, dim_3_size)).to(this_device)\n","\n","  # Iterate over the point cloud sequences.\n","  for index in range(N_S):\n","    # Store the first point cloud frame in the variable S_0.\n","    S_0 = S[index][0]\n","\n","    # Do subsampling on S_0 to get M query points\n","    # from the first point cloud frame. Also, print\n","    # that subsampling is being done.\n","    print(\"Subsampling {} points from S_0 of shape {} x {}.\".format(M, S_0.shape[0], S_0.shape[1])) if verbose else print('', end = '')\n","    S_tilde_0 = subsampler(S_0, M).to(this_device)\n","\n","    # Initialize a variable to hold the forward t-patches.\n","    forward_t_patches = torch.zeros((dim_1_size, M, K, dim_3_size)).to(this_device)\n","\n","    # Store the query points of the initial frame in a variable.\n","    query_points_frame_t = S_tilde_0\n","\n","    # Iterate over the frames in the point cloud sequence.\n","    for t in range(dim_1_size):\n","      # Update the M query points of the current frame.\n","      query_points_frame_t = extract_patches_in_frame(S[index], t, forward_t_patches, query_points_frame_t, gaussian_noise_mu, gaussian_noise_std, K)\n","\n","    # Store the forward t-patches of the current point cloud sequence in the tensor\n","    # that holds the forward t-patches of all input point cloud sequences.\n","    point_cloud_sequences_forward_t_patches[index] = forward_t_patches\n","\n","  return point_cloud_sequences_forward_t_patches.flatten(start_dim = 3)\n","\n","def extract_backward_t_patches(S, M, K, subsampler, gaussian_noise_mu, gaussian_noise_std, verbose):\n","  # Print that the backward t-patches are being extracted.\n","  print(\"Extracting backward t-patches.\") if verbose else print('', end = '')\n","\n","  # Store the size of S along dimensions 0, 1 and 3 in variables.\n","  N_S = S.shape[0]\n","  dim_1_size = S.shape[1]\n","  dim_3_size = S.shape[3]\n","\n","  # Initialize a variable to hold the backward t-patches of the input point cloud sequences.\n","  point_cloud_sequences_backward_t_patches = torch.zeros((N_S, dim_1_size, M, K, dim_3_size)).to(this_device)\n","\n","  # Iterate over the point cloud sequences.\n","  for index in range(N_S):\n","    # Store the last point cloud frame in the variable S_T.\n","    S_T = S[index][dim_1_size - 1]\n","\n","    # Try to do subsampling on S_T to get M query points\n","    # from the final point cloud frame. Also, print\n","    # that subsampling is being done.\n","    print(\"Subsampling {} points from S_T of shape {} x {}.\".format(M, S_T.shape[0], S_T.shape[1])) if verbose else print('', end = '')\n","    S_tilde_T = subsampler(S_T, M).to(this_device)\n","\n","    # Initialize a variable to hold the backward t-patches.\n","    backward_t_patches = torch.zeros((dim_1_size, M, K, dim_3_size)).to(this_device)\n","\n","    # Store the query points of the final frame in a variable.\n","    query_points_frame_t = S_tilde_T\n","\n","    # Iterate over the frames in the point cloud sequence starting\n","    # from the last frame.\n","    for t in range(dim_1_size - 1, -1, -1):\n","      # Update the M query points of the current frame.\n","      query_points_frame_t = extract_patches_in_frame(S[index], t, backward_t_patches, query_points_frame_t, gaussian_noise_mu, gaussian_noise_std, K)\n","\n","    # Store the backward t-patches of the current point cloud sequence in the tensor\n","    # that holds the backward t-patches of all input point cloud sequences.\n","    point_cloud_sequences_backward_t_patches[index] = backward_t_patches\n","\n","  return point_cloud_sequences_backward_t_patches.flatten(start_dim = 3)"]},{"cell_type":"markdown","metadata":{"id":"2fUx6CDfTuJN"},"source":["## Bidirectional T-Patch Extractor"]},{"cell_type":"code","execution_count":127,"metadata":{"id":"UG5gP9UPRgJA","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":56,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["def extract_bidirectional_t_patches(S, M, K, subsampler, gaussian_noise_mu, gaussian_noise_std, verbose):\n","  # Print that the bidirectional t-patches are being extracted.\n","  print(\"Extracting bidirectional t-patches.\") if verbose else print('', end = '')\n","\n","  # Print the arguments that were passed to this function.\n","  print(\"S.shape = {} x {} x {} x {}, Subsampler = {}, M = {}, K = {}, Gaussian Noise ~ ({}, {})\".format(\n","      S.shape[0],\n","      S.shape[1],\n","      S.shape[2],\n","      S.shape[3],\n","      subsampler,\n","      M,\n","      K,\n","      gaussian_noise_mu,\n","      gaussian_noise_std\n","  )) if verbose else print('', end = '')\n","\n","  # Extract the forward t-patches and store them in a variable.\n","  forward_t_patches = extract_forward_t_patches(S, M, K, subsampler, gaussian_noise_mu, gaussian_noise_std, verbose).to(this_device)\n","\n","  # Extract the backward t-patches and store them in a variable.\n","  backward_t_patches = extract_backward_t_patches(S, M, K, subsampler, gaussian_noise_mu, gaussian_noise_std, verbose).to(this_device)\n","\n","  # Concatenate the forward and backward t-patches to form the bidirectional t-patches.\n","  bidirectional_t_patches = torch.cat((forward_t_patches, backward_t_patches), dim = 1).to(this_device)\n","\n","  # Print that the bidirectional t-patches have been extracted.\n","  print(\"Extracted bidirectional t-patches with shape ({} x {} x {} x {}).\".format(*bidirectional_t_patches.shape)) if verbose else print('', end = '')\n","\n","  return bidirectional_t_patches"]},{"cell_type":"markdown","metadata":{"id":"JA4RVzfa5bjx"},"source":["# Hierarchical Point Cloud Sequence Classifier Architecture\n","* There are l consecutive t-patch modules and l = 3 in the paper.\n","* Each t-patch module consists of a t-patch extractor and a t-patch network. Before each t-patch module, there is a subsampler. The subsampling sizes in the paper were 512, 128, and 128 for the 1st, 2nd and 3rd t-patch modules. These subsampling sizes are the hyperparameters, M_1, M_2, ..., M_l.\n","* In the paper, each t-patch network consists of one P_1-Layer Perceptron, where P_1 was 3, followed by a 2D-Conv layer with kernel size (H, W), using ReLU activation and batch normalization.\n","* The hidden sizes of this MLP, h_1_1, h_1_2, ..., h_1_P_1, vary between modules in the paper. In the paper, the hidden sizes of the MLP in the first t-patch module were (64, 64, 128), and the kernel size was (8, 128). The hidden sizes of the MLP in the second t-patch module were (128, 128, 256), and the paper implicitly suggested that the kernel size was (4, 256). The hidden sizes of the MLP in the third t-patch module were (256, 512, 1024), and the paper implicitly suggested that the kernel size was (4, 1024).\n","* The final classifier is a P_2-Layer Perceptron, where P_2 = 3 in the paper. The hidden sizes of the FC layers are h_2_1, ..., h_2_P_2. In the paper, the hidden sizes were (512, 256, #classes).\n","* Before the first layer of the final classifier there is a max pooling operation over the t-patches. Also, there is the flattening of the 2D features of the global spatio-temporal embedding.\n","* The first and second layers of the final classifier are followed by dropout layers with dropout probability, dropout_prob = 0.4.\n","* The final layer of the classifier is preceded by a temporal smoothing convolutional kernel. Input size could be preserved in the output of the smoothing layer."]},{"cell_type":"markdown","metadata":{"id":"1-geJudLC4VL"},"source":["## Hyperparameters"]},{"cell_type":"markdown","source":["### Original Architecture"],"metadata":{"id":"_f1q7MxO3vhD"}},{"cell_type":"code","execution_count":128,"metadata":{"id":"iHSUm7TCKWLf","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":55,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["# Hyperparameters\n","num_classes = num_action_classes    # Number of action classes in the dataset.\n","l = 3                               # Number of consecutive t-patch modules.\n","M = [512, 128, 128]                 # Subsampling sizes for the different subsamplers.\n","P_1 = 3                             # Number of FC layers in t-patch network perceptron.\n","P_2 = 3                             # Number of FC layers in final classifier.\n","hidden_sizes_t_patch_nets = [\n","    (64, 64, 128),\n","     (128, 128, 256),\n","      (256, 512, 1024)\n","      ]                             # The hidden sizes of FC layers in consecutive t-patch modules.\n","hidden_sizes_final_classifier = [\n","    (512, 256, num_classes)\n","    ]                               # The hidden sizes of FC layers in final classifier.\n","kernel_sizes_t_patch_nets = [\n","    (8, 128),\n","     (4, 256),\n","      (4, 1024)\n","      ]                             # Kernel sizes of t-patch network Conv layers for consecutive t-patch modules.\n","kernel_size_smoothing_conv = 5      # Kernel size of the convolutional layer used for temporal smoothing in the final classifier.\n","dropout_probability = 0.4           # Dropout probability in dropout layers of final classifier.\n","\n","num_frames = clip_size              # Contains the number of time steps in a clip.\n","T = num_frames -  1                 # Contains the index of the last frame in a point cloud clip.\n","N = 2048                            # Contains the number of points per frame.\n","N_S = dataset_batch_size            # Contains the number of clips in a batch.\n","\n","K = 6                               # Number of nearest neighbors to use for KNN that approximates phi().\n","gaussian_noise_mu = 0               # Mean of small Gaussian noise that is added to query points to avoid t-patch collapses.\n","gaussian_noise_std = 1              # Standard deviation of small Gaussian noise that is added to query points to avoid t-patch collapses."]},{"cell_type":"markdown","source":["### Small Architecture"],"metadata":{"id":"naNUJx4x3zxB"}},{"cell_type":"code","source":["# Hyperparameters\n","num_classes = num_action_classes    # Number of action classes in the dataset.\n","l = 3                               # Number of consecutive t-patch modules.\n","M = [12, 10, 10]                    # Subsampling sizes for the different subsamplers.\n","P_1 = 3                             # Number of FC layers in t-patch network perceptron.\n","P_2 = 3                             # Number of FC layers in final classifier.\n","hidden_sizes_t_patch_nets = [\n","    (16, 16, 32),\n","     (32, 32, 64),\n","      (64, 72, 96)\n","      ]                             # The hidden sizes of FC layers in consecutive t-patch modules.\n","hidden_sizes_final_classifier = [\n","    (96, 16, num_classes)\n","    ]                               # The hidden sizes of FC layers in final classifier.\n","kernel_sizes_t_patch_nets = [\n","    (8, 8),\n","     (4, 16),\n","      (4, 64)\n","      ]                             # Kernel sizes of t-patch network Conv layers for consecutive t-patch modules.\n","kernel_size_smoothing_conv = 5      # Kernel size of the convolutional layer used for temporal smoothing in the final classifier.\n","dropout_probability = 0.4           # Dropout probability in dropout layers of final classifier.\n","\n","num_frames = clip_size              # Contains the number of time steps in a clip.\n","T = num_frames -  1                 # Contains the index of the last frame in a point cloud clip.\n","N = 2048                            # Contains the number of points per frame.\n","N_S = dataset_batch_size            # Contains the number of clips in a batch.\n","\n","K = 6                               # Number of nearest neighbors to use for KNN that approximates phi().\n","gaussian_noise_mu = 0               # Mean of small Gaussian noise that is added to query points to avoid t-patch collapses.\n","gaussian_noise_std = 1              # Standard deviation of small Gaussian noise that is added to query points to avoid t-patch collapses."],"metadata":{"id":"ydhEj-r33328","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":55,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":129,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vPruYjWuzqAR"},"source":["## T-Patch Module"]},{"cell_type":"code","execution_count":130,"metadata":{"id":"4tSTNHjQ0Zw6","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":55,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["class TPatchModule(tnn.Module):\n","  def __init__(\n","      self,\n","      input_dim,\n","      num_input_channels,\n","      hidden_sizes,\n","      kernel_size,\n","      subsampler,\n","      subsampling_size,\n","      K,\n","      gaussian_noise_mu,\n","      gaussian_noise_std,\n","      t_patch_extractor,\n","      verbose\n","      ):\n","    # Call the __init__ method of tnn.Module.\n","    super(TPatchModule, self).__init__()\n","\n","    # Store whether output should be done.\n","    self.verbose = verbose\n","\n","    # Store the hidden sizes of the MLP of this t-patch module in a variable.\n","    self.hidden_sizes = hidden_sizes\n","\n","    # Store the kernel size of the convolutional layer of this t-patch module in a variable.\n","    self.kernel_size = kernel_size\n","\n","    # Store the subsampler of the input to the t-patch module, the subsampling size and the number\n","    # of nearest neighbors to consider when calculating the output of a KNN in variables.\n","    self.subsampler = subsampler\n","    self.subsampling_size = subsampling_size\n","    self.K = K\n","\n","    # Store the parameters of the distribution of the Gaussian noise used by the t-patch extractor\n","    # in variables.\n","    self.gaussian_noise_mu = gaussian_noise_mu\n","    self.gaussian_noise_std = gaussian_noise_std\n","\n","    # Store the t-patch extractor of this t-patch module in a variable.\n","    self.t_patch_extractor = t_patch_extractor\n","\n","    # Store the t-patch network of this t-patch module as a Sequential object in a variable.\n","    self.t_patch_net = tnn.Sequential(\n","        tnn.Linear(K * input_dim, hidden_sizes[0]),\n","        tnn.ReLU(),\n","        tnn.BatchNorm2d(num_input_channels)\n","        ).to(this_device)\n","\n","    # Store the dimensions of the input in a variable.\n","    self.input_dim = input_dim\n","\n","    # Iterate over the hidden sizes of the MLP of this t-patch module.\n","    for index, hidden_size in enumerate(hidden_sizes):\n","      if index < len(hidden_sizes) - 1:\n","        # Append an FC layer to the t-patch network of this t-patch module that has\n","        # the specified hidden size.\n","        self.t_patch_net.append(tnn.Linear(hidden_size, hidden_sizes[index + 1]).to(this_device))\n","\n","        # Append a ReLU activation function to the t-patch network of this t-patch module.\n","        self.t_patch_net.append(tnn.ReLU().to(this_device))\n","\n","        # Append a BatchNorm2d layer to the t-patch network of this t-patch module.\n","        self.t_patch_net.append(tnn.BatchNorm2d(num_input_channels).to(this_device))\n","\n","    # Append a convolutional layer to the t-patch network of this t-patch module.\n","    self.t_patch_net.append(tnn.Conv2d(num_input_channels, num_input_channels, kernel_size, 1, padding = 'same').to(this_device))\n","\n","    # Append a ReLU activation function to the t-patch network of this t-patch module.\n","    self.t_patch_net.append(tnn.ReLU().to(this_device))\n","\n","    # Append a BatchNorm2d layer to the t-patch network of this t-patch module.\n","    self.t_patch_net.append(tnn.BatchNorm2d(num_input_channels).to(this_device))\n","\n","  def forward(self, S):\n","    # Print that a t-patch module has started execution.\n","    print(\"Executing a t-patch module.\") if self.verbose else print('', end = '')\n","\n","    # Store the t-patches that are extracted in a variable.\n","    t_patches = self.t_patch_extractor(\n","            S,\n","            self.subsampling_size,\n","            self.K,\n","            self.subsampler,\n","            self.gaussian_noise_mu,\n","            self.gaussian_noise_std,\n","            self.verbose\n","            ).transpose(1, 2).to(this_device)\n","\n","    # Print that the high-dimensional feature representation of each t-patch\n","    # is being computed.\n","    print(\"Creating high-dimensional feature representation for t-patches of shape ({} x {} x {} x {}).\".format(*t_patches.shape)) if self.verbose else print('', end = '')\n","\n","    # Store a high-dimensional representation of each t-patch in a variable.\n","    high_dim_representation_t_patches = self.t_patch_net(t_patches).transpose(1, 2).to(this_device)\n","\n","    # Print that the t-patch module finished execution.\n","    print(\"Finished t-patch module execution. \") if self.verbose else print('', end = '')\n","    print(\"Created high-dimensional feature representation of shape ({} x {} x {} x {}).\".format(*high_dim_representation_t_patches.shape)) if self.verbose else print('', end = '')\n","    print() if self.verbose else print('', end = '')\n","\n","    return high_dim_representation_t_patches\n"]},{"cell_type":"markdown","metadata":{"id":"lZTpBdBRDmGw"},"source":["## Connector Module Between T-Patches and Final Classifier"]},{"cell_type":"code","execution_count":131,"metadata":{"id":"fSZ_vvlwDlyW","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":55,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["class TransposeAndFlatten(tnn.Module):\n","  def __init__(self):\n","    # Call the __init__ method of tnn.Module.\n","    super(TransposeAndFlatten, self).__init__()\n","\n","    # Store the flattening layer of this module in a variable.\n","    self.flattenner = tnn.Flatten(1, 2).to(this_device)\n","\n","  def forward(self, input_tensor):\n","    # Squeeze out the last dimension from the input. Transpose the resulting tensor\n","    # twice before flattenning its last two dimensions.\n","    return self.flattenner(input_tensor.squeeze(3).transpose(0, 1).transpose(1, 2))\n","\n","class Squeezer(tnn.Module):\n","  def __init__(self) -> None:\n","    # Call the __init__ method of the tnn.Module class.\n","    super(Squeezer, self).__init__()\n","\n","  def forward(self, input_tensor):\n","    # Return the input tensor after squeezing dimension 1.\n","    return input_tensor.squeeze(3)\n","\n","class Transposer(tnn.Module):\n","  def __init__(self) -> None:\n","    # Call the __init__ method of the tnn.Module class.\n","    super(Transposer, self).__init__()\n","\n","  def forward(self, input_tensor):\n","    # Return the input tensor after transposing dimensions 3 and 2 first, then 1 and 2 later.\n","    return input_tensor.transpose(3, 2).transpose(1, 2)\n","\n","class Debugger(tnn.Module):\n","  def __init__(self) -> None:\n","    # Call the __init__ method of the tnn.Module class.\n","    super(Debugger, self).__init__()\n","\n","  def forward(self, input_tensor):\n","    # Print the shape of the input_tensor.\n","    print(\"Debugging module: input Tensor size = {}\".format(input_tensor.shape))\n","    return input_tensor"]},{"cell_type":"markdown","metadata":{"id":"DxNFn-UzGV2_"},"source":["## Module for Hierarchical Architecture"]},{"cell_type":"code","source":["class ThreeDInActionPipeline(tnn.Module):\n","  def __init__(\n","      self,\n","      subsampler,\n","      subsampling_sizes,\n","      T,\n","      num_classes,\n","      K,\n","      input_dim,\n","      kernel_sizes_t_patch_nets,\n","      gaussian_noise_mu,\n","      gaussian_noise_std,\n","      hidden_sizes_t_patch_nets,\n","      hidden_sizes_final_classifier,\n","      dropout_probability,\n","      kernel_size_smoothing_conv,\n","      smoothing_kernel,\n","      t_patch_extractors,\n","      using_msraction3d = True,\n","      verbose = True\n","      ):\n","    # Call the __init__ method of tnn.Module.\n","    super(ThreeDInActionPipeline, self).__init__()\n","\n","    # Store whether output should be done.\n","    self.verbose = verbose\n","\n","    # Store the subsampling function in a variable.\n","    self.subsampler = subsampler\n","\n","    # Store the K hyperparameter of the KNN used by the t-patch extractor in a variable.\n","    self.K = K\n","\n","    # Store the number of frames in an input point cloud sequence in a variable.\n","    self.num_frames_per_pt_cloud_sequence = T + 1\n","\n","    # Store the mean and standard deviation of the Gaussian noise used to prevent t-patch collapse in two separate variables.\n","    self.gaussian_noise_mu = gaussian_noise_mu\n","    self.gaussian_noise_std = gaussian_noise_std\n","\n","    # Store the sizes of subsamples created by subsamplers in a variable.\n","    self.M = subsampling_sizes\n","\n","    # Store the number of action classes in a variable.\n","    self.num_classes = num_classes\n","\n","    # Store the input dimension in a variable.\n","    self.input_dim = input_dim\n","\n","    # Store the hidden sizes of MLPs of t-patch networks, the kernel sizes of Conv layers of t-patch networks\n","    # and t-patch modules in variables.\n","    self.hidden_sizes_t_patch_nets = hidden_sizes_t_patch_nets\n","    self.kernel_sizes_t_patch_nets = kernel_sizes_t_patch_nets\n","    self.t_patch_modules = tnn.Sequential().to(this_device)\n","\n","    # Store the number of channels in the input to a t-patch module in a variable.\n","    t_patch_module_num_input_channels = subsampling_sizes[0]\n","    t_patch_module_input_dim = input_dim\n","\n","    # Iterate over the hidden sizes of MLPs of t-patch networks of t-patch modules.\n","    for index, hidden_sizes in enumerate(hidden_sizes_t_patch_nets):\n","      # Store the kernel size of the current t-patch module in a variable.\n","      kernel_size = kernel_sizes_t_patch_nets[index]\n","\n","      t_patch_module_num_input_channels = subsampling_sizes[index]\n","\n","      # Append a t-patch module to the Sequential object containing the t-patch modules.\n","      self.t_patch_modules.append(\n","          TPatchModule(\n","              t_patch_module_input_dim,\n","              t_patch_module_num_input_channels,\n","              hidden_sizes,\n","              kernel_size,\n","              subsampler,\n","              subsampling_sizes[index],\n","              K,\n","              gaussian_noise_mu,\n","              gaussian_noise_std,\n","              t_patch_extractors[index],\n","              verbose = verbose\n","              ).to(this_device)\n","          )\n","\n","      t_patch_module_input_dim = hidden_sizes[-1]\n","      # Update the number of channels in the input to the next t-patch module.\n","      #t_patch_module_num_input_channels = subsampling_sizes[index + 1]\n","\n","    # Store the hidden sizes of the final classifier in a variable.\n","    self.hidden_sizes_final_classifier = hidden_sizes_final_classifier\n","\n","    # Store the dropout probability of dropout layers of the final classifier in a variable.\n","    self.dropout_probability = dropout_probability\n","\n","    # Store the kernel size of the temporal smoothing convolutional layer of the final classifier in a variable.\n","    self.kernel_size_smoothing_conv = kernel_size_smoothing_conv\n","\n","    # Store the padding of the temporal smoothing convolutional layer of the final classifier in a variable.\n","    self.padding_smoothing_conv = kernel_size_smoothing_conv // 2\n","\n","    # Store the size of the dimension of the input of the max pooling layer on which pooling is done.\n","    self.max_pooling_dim_size = subsampling_sizes[-1]\n","\n","    # Store the temporal smoothing convolutional layer in a variable.\n","    self.temporal_smoothing_conv_layer = tnn.Conv2d(\n","        1,\n","        1,\n","        kernel_size = kernel_size_smoothing_conv,\n","        padding = self.padding_smoothing_conv\n","        ).to(this_device)\n","\n","    # Set the requires_grad attribute of the temporal smoothing convolutional layer to False because gradients\n","    # don't need to be calculated for that smoothing layer.\n","    self.temporal_smoothing_conv_layer.weight.requires_grad = False\n","\n","    # Assign the weights of the temporal smoothing convolutional layer with a smoothing kernel.\n","    self.temporal_smoothing_conv_layer.weight *= 0\n","    self.temporal_smoothing_conv_layer.weight += smoothing_kernel\n","\n","    # Store the final classifier as a tnn.Sequential object in a variable.\n","    if using_msraction3d:\n","      self.final_classifier = tnn.Sequential(\n","            tnn.MaxPool2d((1, self.max_pooling_dim_size)),\n","            Transposer(),\n","            tnn.Linear(hidden_sizes_t_patch_nets[-1][-1], hidden_sizes_final_classifier[0][2])\n","              ).to(this_device)\n","    else:\n","      self.final_classifier = tnn.Sequential(\n","            tnn.MaxPool2d((1, self.max_pooling_dim_size)),\n","            Transposer(),\n","            tnn.Linear(hidden_sizes_t_patch_nets[-1][-1], hidden_sizes_final_classifier[0][0]),\n","            tnn.Dropout(p = dropout_probability),\n","            tnn.Linear(hidden_sizes_final_classifier[0][0], hidden_sizes_final_classifier[0][1]),\n","            tnn.Dropout(p = dropout_probability),\n","            Debugger(),\n","            self.temporal_smoothing_conv_layer,\n","            tnn.Linear(hidden_sizes_final_classifier[0][1], hidden_sizes_final_classifier[0][2])\n","              ).to(this_device)\n","\n","  def forward(self, S):\n","    # Print that the t-patch modules started computation.\n","    print(\"T-patch modules are acting on the input point cloud sequence.\") if self.verbose else print('', end = '')\n","\n","    # Store the global spatio-temporal representation of an input point\n","    # cloud sequence that the t-patch modules produce in a variable.\n","    global_spatio_temporal_representation = self.t_patch_modules(S).transpose(2, 3).to(this_device)\n","\n","    # Print that the final classifier started computation.\n","    print(\"Final classifier is acting on the per-frame representation of the point cloud sequence.\") if self.verbose else print('', end = '')\n","\n","    # Store the output predictions of the final classifier on the forward t-patches and on the backward t-patches\n","    # in separate variables.\n","    predictions = self.final_classifier(global_spatio_temporal_representation).squeeze(1).to(this_device)\n","\n","    # Store the shape of the predictions Tensor in a variable.\n","    dim_1, dim_2, num_classes = predictions.shape\n","\n","    # Reshape the predictions Tensor to separate the backward t-patch predictions and the predictions for the forward t-patches\n","    # along dimension 1.\n","    predictions = predictions.reshape((dim_1, 2, dim_2 // 2, num_classes)).to(this_device)\n","\n","    # Compute and return the per-frame action predictions by averaging the action predictions of the forward and backward t-patches\n","    # of each frame.\n","    return torch.mean(predictions, dim = 1).transpose(1, 2)\n"],"metadata":{"id":"tI2IGGLskgzR","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":54,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":132,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zRuWJ6GgMf6D"},"source":["## Test the 3D in Action Pipeline on Input Data"]},{"cell_type":"code","execution_count":133,"metadata":{"id":"JQaxVUeoJRV_","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":54,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["# Initialize a 3D in Action model to train on the input data.\n","action_classification_model = ThreeDInActionPipeline(\n","    KMeansSampling,\n","    M,\n","    T,\n","    num_classes,\n","    K,\n","    3,\n","    kernel_sizes_t_patch_nets,\n","    gaussian_noise_mu,\n","    gaussian_noise_std,\n","    hidden_sizes_t_patch_nets,\n","    hidden_sizes_final_classifier,\n","    dropout_probability,\n","    kernel_size_smoothing_conv,\n","    torch.Tensor(\n","        [\n","            [ .25, .375, .25, .375, .25 ],\n","            [.375,   .5,  .5,   .5, .375],\n","            [ .25,   .5,   1,   .5, .25 ],\n","            [.375,   .5,  .5,   .5, .375],\n","            [ .25, .375, .25, .375, .25 ]\n","        ],\n","    ).to(this_device),\n","    [extract_bidirectional_t_patches, extract_forward_t_patches, extract_forward_t_patches],\n","    using_msraction3d= (True if dataset_used == \"MSR-Action3D\" else False),\n","    verbose = False\n",")\n","\n","# Initialize a 3D in Action model to store the state dictionary of the best model obtained so far.\n","best_3d_in_action_model = ThreeDInActionPipeline(\n","    KMeansSampling,\n","    M,\n","    T,\n","    num_classes,\n","    K,\n","    3,\n","    kernel_sizes_t_patch_nets,\n","    gaussian_noise_mu,\n","    gaussian_noise_std,\n","    hidden_sizes_t_patch_nets,\n","    hidden_sizes_final_classifier,\n","    dropout_probability,\n","    kernel_size_smoothing_conv,\n","    torch.Tensor(\n","        [\n","            [ .25, .375, .25, .375, .25 ],\n","            [.375,   .5,  .5,   .5, .375],\n","            [ .25,   .5,   1,   .5, .25 ],\n","            [.375,   .5,  .5,   .5, .375],\n","            [ .25, .375, .25, .375, .25 ]\n","        ],\n","    ).to(this_device),\n","    [extract_bidirectional_t_patches, extract_forward_t_patches, extract_forward_t_patches],\n","    using_msraction3d=(True if dataset_used == \"MSR-Action3D\" else False),\n","    verbose = True\n",")"]},{"cell_type":"markdown","metadata":{"id":"kv1exY4ntnSH"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"kfEg5ZgCtrWQ"},"source":["## Loss Function"]},{"cell_type":"code","execution_count":134,"metadata":{"id":"H-A0vmtTtqAO","executionInfo":{"status":"ok","timestamp":1715911505382,"user_tz":240,"elapsed":54,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["frame_loss = tnn.CrossEntropyLoss()\n","seq_loss = tnn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"zCrBUCdTTSlC"},"source":["## Optimizer"]},{"cell_type":"code","execution_count":135,"metadata":{"id":"8n_CTCr5TSRc","executionInfo":{"status":"ok","timestamp":1715911505383,"user_tz":240,"elapsed":54,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[],"source":["model_optimizer = torch.optim.Adam(action_classification_model.parameters(), lr = 1e-4)"]},{"cell_type":"markdown","metadata":{"id":"KqLZEX-wFXwG"},"source":["# Compute the Loss for the Loaded Point Cloud Clips\n"]},{"cell_type":"markdown","source":["### Create Function That Plots Losses and Accuracies"],"metadata":{"id":"BNlttl2nQ8oY"}},{"cell_type":"code","source":["import matplotlib.pyplot as colab_plot\n","# Display matplotlib plots inline in the notebook.\n","%matplotlib inline\n","\n","def draw_losses_and_accuracies():\n","  # Create subplots for accuracies and losses.\n","  colab_plot.subplots_adjust(wspace = 0.5, hspace = 0.5)\n","  axis_accuracies = colab_plot.subplot(2, 1, 1)\n","  axis_loss = colab_plot.subplot(2, 1, 2)\n","\n","  # Set the titles, x and y axis labels of both plots.\n","  axis_accuracies.set_title('Training Accuracy vs. Iteration')\n","  axis_accuracies.set_xlabel('Iteration')\n","  axis_accuracies.set_ylabel('Training Accuracy')\n","  axis_accuracies.set_xlim(left = 0)\n","  axis_loss.set_title('Training Loss vs. Iteration')\n","  axis_loss.set_xlabel('Iteration')\n","  axis_loss.set_ylabel('Training Loss')\n","  axis_loss.set_xlim(left = 0)\n","\n","  # Store the training losses and training accuracies in variables.\n","  training_losses = [pair[0] for pair in training_losses_and_accuracies]\n","  training_accuracies = [pair[1] for pair in training_losses_and_accuracies]\n","\n","  # Plot Training Accuracies vs. Iteration.\n","  axis_accuracies.plot(range(len(training_accuracies)), training_accuracies)\n","\n","  # Plot Training Losses vs. Iteration.\n","  axis_loss.plot(range(len(training_losses)), training_losses)\n","\n","  # Show the plots.\n","  colab_plot.show()"],"metadata":{"id":"hv9BpOksNVDQ","executionInfo":{"status":"ok","timestamp":1715911505383,"user_tz":240,"elapsed":54,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":136,"outputs":[]},{"cell_type":"markdown","source":["### Train for Epochs."],"metadata":{"id":"QYq7uSE_RIlC"}},{"cell_type":"code","source":["# If a file exists at '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/MSRAction3D.pt'\n","# then load the saved MSR-Action3D model from the file and the number of epochs it was trained for.\n","import os.path\n","\n","# Store the number of epochs a model has been trained yet in a variable.\n","num_trained_epochs = 0\n","\n","if dataset_used == \"MSR-Action3D\":\n","  if os.path.exists('/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/MSRAction3D.pt'):\n","    msr_action3d_state_dict, num_trained_epochs, best_training_accuracy = torch.load('/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/MSRAction3D.pt')\n","    best_3d_in_action_model.load_state_dict(msr_action3d_state_dict)\n","\n","    # Print the state dictionary of the MSR-Action3D model after loading its\n","    # state dictionary from a file.\n","    print(best_3d_in_action_model.state_dict())\n","else:\n","  best_3d_in_action_model = action_classification_model\n","  best_training_accuracy = 0"],"metadata":{"id":"MBAf63xkejpj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715911505383,"user_tz":240,"elapsed":54,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}},"outputId":"d9d1ab38-1f0f-4c73-d41b-0d7551bb19ba"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["OrderedDict([('t_patch_modules.0.t_patch_net.0.weight', tensor([[-0.2093, -0.0976, -0.0101,  0.1960, -0.0332, -0.0369, -0.0710,  0.1424,\n","          0.1490,  0.2245,  0.1685, -0.1701,  0.2260,  0.1171,  0.1160,  0.0714,\n","         -0.2076, -0.1126],\n","        [ 0.2013,  0.0027,  0.1047, -0.0615, -0.2250, -0.0104,  0.1848,  0.0323,\n","         -0.0158,  0.1871,  0.0447,  0.1418,  0.1549,  0.2164, -0.1070, -0.1452,\n","          0.0382,  0.2119],\n","        [-0.2001,  0.2262, -0.1320,  0.1429,  0.1089,  0.2315, -0.2149, -0.2028,\n","          0.0502,  0.2342, -0.1718,  0.0749, -0.2262,  0.2200,  0.1613,  0.1797,\n","         -0.0706, -0.1231],\n","        [ 0.1983, -0.1665, -0.0543, -0.0498, -0.1688,  0.0706,  0.2099,  0.1446,\n","         -0.1969,  0.0110, -0.0671,  0.0889, -0.0881,  0.2050,  0.0739, -0.0655,\n","         -0.0848, -0.0268],\n","        [ 0.2250,  0.2011,  0.1431, -0.0632,  0.0209,  0.2149,  0.0355,  0.0954,\n","          0.1751, -0.1026,  0.1468,  0.0175, -0.1484,  0.1910,  0.0613, -0.2202,\n","         -0.0284,  0.0580],\n","        [ 0.0301, -0.1062,  0.1159,  0.1185,  0.2096, -0.0496,  0.0754,  0.0230,\n","         -0.0473,  0.0464, -0.1652,  0.0085,  0.1728, -0.0869,  0.1344, -0.2316,\n","          0.2006, -0.2297],\n","        [-0.1506,  0.0649, -0.2092, -0.1538, -0.0424,  0.0078, -0.0516,  0.0977,\n","         -0.0377,  0.0647,  0.1013, -0.1558, -0.1523, -0.0911, -0.1299, -0.0706,\n","         -0.2184,  0.1271],\n","        [-0.0509, -0.1750, -0.1996, -0.0236,  0.1523,  0.1279, -0.1485,  0.0829,\n","         -0.1157,  0.1823, -0.0201, -0.0442,  0.0045,  0.0575, -0.0984, -0.1346,\n","          0.2073,  0.1345],\n","        [-0.1593,  0.2254, -0.0534,  0.0630, -0.1815,  0.1184, -0.1708,  0.0586,\n","         -0.2327,  0.2260,  0.1355,  0.0327,  0.1369, -0.1115, -0.1588,  0.0680,\n","          0.1764, -0.1547],\n","        [ 0.1024, -0.2072, -0.1213,  0.1002, -0.2213, -0.0349, -0.1615,  0.2241,\n","          0.2165,  0.0105, -0.0248,  0.1806, -0.0825,  0.0638,  0.2344,  0.0957,\n","          0.0019,  0.1817],\n","        [ 0.1745,  0.1567, -0.0532, -0.2231,  0.0009,  0.1321,  0.2256, -0.1688,\n","          0.1169,  0.0950,  0.1662,  0.2173, -0.1012, -0.0251, -0.1164,  0.0839,\n","          0.1846, -0.2322],\n","        [-0.0066, -0.0020, -0.0583,  0.1898,  0.0984, -0.1291, -0.0312,  0.0483,\n","         -0.1502, -0.0194,  0.0861, -0.0525,  0.0443,  0.2246, -0.2327,  0.2180,\n","         -0.1478,  0.1922],\n","        [-0.0473, -0.2062,  0.1484,  0.1705,  0.0132,  0.0795, -0.1779,  0.2260,\n","         -0.2199,  0.0579, -0.0191, -0.1540,  0.0702, -0.1090,  0.2100,  0.2036,\n","          0.0222,  0.0787],\n","        [-0.1951,  0.1754, -0.1403, -0.0831, -0.2048, -0.1219, -0.2280,  0.0396,\n","         -0.1205,  0.2279,  0.0141, -0.1252,  0.0558,  0.2191,  0.2010, -0.2216,\n","          0.0976, -0.2266],\n","        [ 0.1867,  0.0646, -0.0874,  0.1247, -0.0487, -0.0792,  0.2032,  0.2022,\n","         -0.0010, -0.1453, -0.1227,  0.0935, -0.1579,  0.0937, -0.0235,  0.1242,\n","          0.1768,  0.1193],\n","        [-0.1751, -0.1169, -0.2346, -0.2334, -0.1237, -0.1915, -0.1050, -0.1152,\n","         -0.2009,  0.1831,  0.1878,  0.0992,  0.0353,  0.2273, -0.0429, -0.2303,\n","          0.2029, -0.0167]], device='cuda:0')), ('t_patch_modules.0.t_patch_net.0.bias', tensor([ 0.0840,  0.0839, -0.0256,  0.0273, -0.1389,  0.1897, -0.2233,  0.0011,\n","        -0.2293, -0.1700,  0.0708,  0.0851,  0.2015,  0.1589, -0.2111,  0.0475],\n","       device='cuda:0')), ('t_patch_modules.0.t_patch_net.2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.2.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.0.t_patch_net.3.weight', tensor([[ 0.0955, -0.2152,  0.2155,  0.1131, -0.1991, -0.1638,  0.2272, -0.2325,\n","         -0.2402,  0.2348, -0.1569, -0.1135, -0.0483,  0.0674, -0.1089,  0.2095],\n","        [ 0.0555, -0.0228,  0.0015, -0.1063,  0.0003, -0.1732,  0.0428, -0.0517,\n","          0.0532, -0.0318,  0.1897, -0.1946, -0.0244,  0.1270, -0.0123, -0.1099],\n","        [-0.2256,  0.1195,  0.1239, -0.1969, -0.1670,  0.0372,  0.1579,  0.0370,\n","          0.1506,  0.2173,  0.0074, -0.1495,  0.1741, -0.0071,  0.0032, -0.2177],\n","        [-0.0543, -0.1100,  0.2194, -0.2321, -0.1831,  0.0976,  0.1696,  0.2265,\n","         -0.0323, -0.2051,  0.0201, -0.0963,  0.2074,  0.0833, -0.1416,  0.0522],\n","        [-0.0819,  0.0439,  0.2109,  0.1499,  0.2019,  0.2486, -0.0751, -0.1575,\n","         -0.0795,  0.2295,  0.1963, -0.1957, -0.1204,  0.1503,  0.0686, -0.0418],\n","        [ 0.0263,  0.2324,  0.1110,  0.2398, -0.0451,  0.1304,  0.1540, -0.0959,\n","          0.1925, -0.1661,  0.1949,  0.2103, -0.1991,  0.0493,  0.2483,  0.0657],\n","        [ 0.2457,  0.2397,  0.1433, -0.0866,  0.1919,  0.1924,  0.0456, -0.0253,\n","         -0.1301,  0.2192, -0.1954, -0.1960, -0.2368, -0.0313,  0.0510, -0.0973],\n","        [ 0.1336, -0.2370,  0.0457,  0.0193,  0.1218,  0.0934,  0.1422,  0.0200,\n","          0.2424,  0.1179,  0.0870,  0.1779, -0.1789, -0.2211,  0.0607, -0.1569],\n","        [ 0.0880,  0.1945,  0.1380, -0.2449,  0.1968,  0.0683,  0.2378, -0.2427,\n","          0.1987, -0.2347, -0.2340, -0.1515, -0.2466,  0.0668, -0.1186,  0.1225],\n","        [-0.2015,  0.0563,  0.1652,  0.0242, -0.1828, -0.1649, -0.0045,  0.0525,\n","         -0.1169, -0.0880, -0.0462,  0.0717,  0.1083, -0.0801,  0.0321, -0.0169],\n","        [-0.1533,  0.0536, -0.0846, -0.2338, -0.0823,  0.1460, -0.1391, -0.1493,\n","          0.1912,  0.1861, -0.1408,  0.1770,  0.0866,  0.0324, -0.0523, -0.0294],\n","        [-0.0963,  0.0823, -0.0197,  0.0611, -0.0257,  0.0964,  0.0336, -0.2182,\n","          0.1823, -0.2005,  0.1722, -0.0637, -0.1980, -0.1278, -0.1916,  0.2100],\n","        [-0.1394,  0.1061,  0.2055,  0.0389, -0.1550,  0.1211,  0.2434,  0.1900,\n","          0.0543, -0.1543,  0.1077,  0.1272,  0.2083,  0.0641, -0.2087, -0.1900],\n","        [ 0.2500, -0.1501, -0.0600,  0.1600, -0.1010, -0.2003,  0.0082, -0.0867,\n","         -0.0518, -0.0124, -0.0186, -0.1047, -0.0151, -0.1408, -0.1959, -0.1381],\n","        [-0.1002,  0.0281,  0.1520,  0.0142,  0.0628,  0.0700, -0.0709,  0.2099,\n","          0.1144, -0.0511, -0.0018,  0.0100,  0.2166,  0.0339, -0.1844, -0.1444],\n","        [-0.1131, -0.2390, -0.1192, -0.0376,  0.2052,  0.0661,  0.0112, -0.0771,\n","          0.1519, -0.2060,  0.2266, -0.0847, -0.1085, -0.1095, -0.1263,  0.0336]],\n","       device='cuda:0')), ('t_patch_modules.0.t_patch_net.3.bias', tensor([ 0.0332, -0.0371,  0.2231, -0.1523, -0.0900,  0.1432,  0.0018,  0.0937,\n","        -0.0459,  0.1007,  0.1160,  0.1744,  0.1471,  0.0044,  0.2468,  0.1163],\n","       device='cuda:0')), ('t_patch_modules.0.t_patch_net.5.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.5.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.5.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.5.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.5.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.0.t_patch_net.6.weight', tensor([[-0.1665, -0.1831, -0.0141,  0.2214, -0.1962,  0.0111, -0.0791, -0.0529,\n","         -0.0646, -0.2464,  0.1150, -0.2117, -0.1717,  0.1800, -0.0252, -0.1350],\n","        [-0.2326,  0.1750,  0.0957,  0.0377,  0.0091, -0.2169, -0.0962, -0.0098,\n","          0.1878,  0.0408, -0.0726,  0.0170,  0.0980,  0.1812,  0.0089, -0.2267],\n","        [ 0.2375,  0.1216,  0.0499,  0.0237,  0.0710,  0.0818, -0.1509, -0.0482,\n","         -0.1945, -0.1969,  0.0267, -0.1612,  0.1599,  0.1631, -0.1810,  0.1005],\n","        [-0.0343,  0.0986, -0.0539, -0.0854,  0.0117, -0.0630,  0.0876,  0.2074,\n","          0.1708, -0.1697, -0.0597,  0.0175,  0.0288,  0.1736,  0.2382, -0.0921],\n","        [-0.1023, -0.0860, -0.0507,  0.0779, -0.1151, -0.0356, -0.0847,  0.1139,\n","         -0.1982, -0.1262, -0.1104, -0.1294, -0.2061,  0.0016,  0.2300, -0.1292],\n","        [ 0.0208, -0.0457, -0.1324,  0.1780, -0.0558, -0.1968,  0.2323,  0.2050,\n","          0.0803, -0.0618, -0.2061,  0.2108, -0.1436,  0.2064, -0.0071, -0.1836],\n","        [ 0.2104, -0.0713, -0.1565,  0.0782,  0.1387, -0.1811,  0.1117,  0.1650,\n","          0.1485,  0.0768,  0.1933,  0.1929, -0.0156, -0.0040,  0.0590, -0.0113],\n","        [ 0.0426,  0.2470, -0.0916, -0.0128,  0.1370,  0.0038,  0.1349, -0.0722,\n","          0.1659,  0.2346,  0.2200, -0.2110,  0.1221,  0.2150,  0.1383, -0.2466],\n","        [-0.1854, -0.0071,  0.0513, -0.1097,  0.1374,  0.1342,  0.0794, -0.0242,\n","          0.2099,  0.1381, -0.1498, -0.0392, -0.0934, -0.0881, -0.1376,  0.1114],\n","        [-0.0438, -0.1799, -0.0165, -0.1493,  0.1695,  0.1574, -0.0580,  0.0348,\n","          0.1311, -0.1424, -0.2211,  0.0171,  0.1282,  0.2009,  0.1267,  0.1544],\n","        [ 0.0760, -0.0503,  0.1398,  0.0879, -0.1073, -0.0284, -0.0560,  0.1730,\n","          0.0946, -0.0725,  0.0383,  0.0352, -0.1433,  0.2438, -0.0486, -0.2288],\n","        [-0.0276, -0.1747, -0.1763,  0.2098, -0.1316,  0.2353,  0.1235,  0.0479,\n","          0.0851, -0.0468, -0.1679, -0.0743,  0.1598, -0.1297, -0.1071, -0.1286],\n","        [-0.0820,  0.1945,  0.2195, -0.1637,  0.1551, -0.0768,  0.1954, -0.0453,\n","          0.0221, -0.1539,  0.0060, -0.0438, -0.1436,  0.1724, -0.0858, -0.1358],\n","        [-0.2289, -0.1047, -0.1194,  0.0577,  0.0809, -0.1574,  0.0679, -0.1085,\n","          0.0673,  0.2447, -0.0877,  0.0804,  0.1741,  0.1542,  0.0613,  0.2031],\n","        [-0.1444,  0.1649,  0.2156, -0.2213,  0.0077, -0.1276,  0.1790, -0.0169,\n","          0.0105, -0.2114, -0.2047,  0.2476, -0.1955,  0.0444, -0.0661, -0.0525],\n","        [ 0.2158,  0.0977,  0.0164,  0.0599, -0.0299,  0.0790,  0.1708, -0.2190,\n","          0.1208,  0.2179,  0.2291,  0.1655, -0.1818, -0.0524, -0.0478,  0.1144],\n","        [-0.2159,  0.1719, -0.2369, -0.0712, -0.1365, -0.1899,  0.1867,  0.0347,\n","          0.0443,  0.1032, -0.1052, -0.2136,  0.0578, -0.0958, -0.1200, -0.2272],\n","        [ 0.0495,  0.0332,  0.1495,  0.1985,  0.1906, -0.0876,  0.2470,  0.0975,\n","         -0.1990, -0.1725, -0.1082,  0.0845,  0.0533, -0.0104, -0.1780,  0.0572],\n","        [-0.0537, -0.0137,  0.1437,  0.2301, -0.1620,  0.0824,  0.2028,  0.0450,\n","         -0.0885,  0.0461,  0.1113, -0.0737, -0.0477, -0.0040,  0.0581, -0.1632],\n","        [ 0.2083,  0.0787,  0.0187, -0.1325,  0.0247,  0.0747, -0.0187, -0.0249,\n","          0.0634, -0.0038, -0.1072,  0.1927,  0.2388,  0.1322, -0.2056,  0.1540],\n","        [ 0.1101,  0.2277, -0.0515, -0.2183,  0.2143, -0.0208,  0.1729,  0.0613,\n","          0.0012,  0.0609, -0.0244,  0.0932,  0.0024,  0.1775,  0.1830,  0.2037],\n","        [-0.0450, -0.0574, -0.0201, -0.1768,  0.1003,  0.1293,  0.1743, -0.2117,\n","          0.2044, -0.0884,  0.1625, -0.1779, -0.0321,  0.2345, -0.0696,  0.2155],\n","        [ 0.1116,  0.1542,  0.0323, -0.2171,  0.0197, -0.1913, -0.0326,  0.2244,\n","         -0.2230,  0.1708,  0.1358, -0.0548, -0.1851, -0.1573,  0.1220,  0.2213],\n","        [ 0.0964, -0.0351,  0.2121, -0.0374, -0.0498, -0.0874, -0.0133,  0.0858,\n","          0.1063, -0.1584,  0.0851, -0.0156, -0.1417, -0.2461, -0.2258, -0.0229],\n","        [-0.1925, -0.0864, -0.0174, -0.0138,  0.0225,  0.2131, -0.2228, -0.0179,\n","         -0.1668, -0.0706,  0.2289,  0.0674, -0.2108,  0.0403,  0.0424, -0.2275],\n","        [ 0.1822, -0.1631, -0.0863,  0.2203,  0.0899, -0.2480,  0.1229, -0.2314,\n","          0.1567, -0.2256, -0.2149, -0.1472, -0.0256, -0.1529,  0.1386, -0.1392],\n","        [ 0.0914,  0.1234, -0.0737, -0.1974,  0.1342, -0.1299,  0.0425, -0.0772,\n","         -0.0782,  0.1657,  0.1695, -0.0449, -0.2425, -0.1279,  0.0252, -0.2035],\n","        [ 0.2319, -0.1784, -0.1410,  0.2324, -0.0705,  0.1171,  0.1039,  0.0680,\n","         -0.1763, -0.0926,  0.0792,  0.1097,  0.1812,  0.0229,  0.1626,  0.0978],\n","        [ 0.0956,  0.0146,  0.1810,  0.2199, -0.0156, -0.2267, -0.1755, -0.0173,\n","         -0.0241,  0.2000, -0.1112,  0.0464, -0.1092, -0.2395,  0.0126, -0.2215],\n","        [ 0.0426, -0.1879,  0.1208,  0.0202, -0.2155,  0.0982, -0.2081, -0.0238,\n","         -0.0635, -0.1866,  0.1377, -0.1674,  0.1684, -0.0231, -0.1829, -0.1977],\n","        [-0.1896, -0.1393,  0.0716, -0.1350,  0.1094,  0.1280, -0.0271,  0.0505,\n","          0.1355,  0.1293, -0.2062, -0.0876,  0.1720,  0.1489,  0.2336, -0.0754],\n","        [-0.2397, -0.0096,  0.0585,  0.1721,  0.1728, -0.0883, -0.1588, -0.2037,\n","         -0.2196,  0.1632,  0.1536,  0.1136, -0.0801, -0.0032, -0.0945,  0.2437]],\n","       device='cuda:0')), ('t_patch_modules.0.t_patch_net.6.bias', tensor([-0.0806,  0.1165, -0.1589,  0.2058, -0.2252, -0.1733, -0.0497,  0.0533,\n","        -0.2432,  0.0358, -0.2306,  0.0029, -0.1032,  0.0433,  0.1521, -0.1923,\n","        -0.0180, -0.1187,  0.0253,  0.0991, -0.1380,  0.1107,  0.0614, -0.0434,\n","        -0.1031, -0.1003,  0.0185,  0.0229,  0.1785,  0.1788, -0.0881, -0.0077],\n","       device='cuda:0')), ('t_patch_modules.0.t_patch_net.8.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.8.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.8.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.8.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.8.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.0.t_patch_net.9.weight', tensor([[[[-2.5740e-02,  3.2437e-02, -1.2809e-03,  ...,  1.1270e-02,\n","           -1.5532e-02, -2.1338e-02],\n","          [ 4.5856e-03, -2.6633e-02,  2.5790e-03,  ...,  2.2965e-02,\n","            2.0103e-02, -2.0333e-02],\n","          [-1.8802e-02, -1.0397e-02, -3.2083e-02,  ...,  2.1654e-02,\n","            1.1212e-02,  2.1249e-02],\n","          ...,\n","          [ 1.9444e-02,  2.9753e-02, -2.0641e-02,  ...,  2.6962e-03,\n","           -3.5009e-02,  2.1325e-02],\n","          [ 1.2916e-02,  1.0940e-03, -1.4908e-02,  ..., -6.3422e-03,\n","            2.3496e-02,  1.6035e-02],\n","          [ 1.1832e-02, -1.3383e-02, -7.8506e-03,  ..., -2.9804e-02,\n","           -3.5326e-02,  1.3337e-02]],\n","\n","         [[ 9.9967e-03,  8.4512e-03, -9.9789e-03,  ...,  3.5343e-02,\n","            1.4816e-02,  2.9850e-02],\n","          [-1.2564e-02,  1.7136e-02,  1.7570e-02,  ...,  1.1881e-02,\n","           -6.3164e-03, -2.1531e-02],\n","          [-2.1051e-02,  1.5821e-03,  4.9572e-03,  ..., -2.2310e-02,\n","           -1.5466e-02,  1.2437e-02],\n","          ...,\n","          [-2.9379e-02,  1.6741e-02,  1.2262e-02,  ...,  3.0070e-02,\n","           -2.7788e-02,  1.3271e-02],\n","          [-2.8151e-02, -2.3992e-03, -7.1223e-03,  ...,  3.0150e-02,\n","           -5.5598e-03, -2.0328e-02],\n","          [ 3.2939e-02, -8.4499e-03,  1.5104e-02,  ...,  3.4526e-02,\n","           -1.0829e-02,  3.1477e-02]],\n","\n","         [[-1.5790e-02,  1.4134e-02, -1.3679e-02,  ...,  5.6833e-03,\n","            1.1320e-02,  8.6382e-03],\n","          [-2.3661e-02, -1.9206e-02, -2.9621e-02,  ..., -1.3125e-02,\n","            6.7016e-03, -1.5736e-02],\n","          [-2.4172e-02, -1.9443e-02, -3.2790e-02,  ...,  3.2807e-03,\n","            2.4063e-02, -4.2531e-03],\n","          ...,\n","          [ 1.9556e-02, -2.3318e-02,  4.4919e-03,  ..., -3.0604e-02,\n","           -3.7565e-03,  1.7610e-02],\n","          [-1.9153e-03, -1.1684e-02,  3.1715e-02,  ...,  9.0936e-03,\n","           -1.8518e-02,  3.1386e-02],\n","          [-7.7623e-04,  6.6986e-03,  8.9648e-03,  ...,  6.7564e-03,\n","            1.7781e-02,  1.5528e-02]],\n","\n","         ...,\n","\n","         [[ 1.6394e-02,  1.8143e-02,  2.2803e-02,  ...,  1.5281e-02,\n","           -3.0767e-02,  1.1669e-03],\n","          [ 3.5966e-02,  1.9947e-02,  4.0076e-03,  ..., -3.3400e-02,\n","            3.3371e-02,  1.2679e-02],\n","          [-2.7937e-02, -2.2829e-02, -3.3580e-02,  ...,  3.0511e-02,\n","            1.6275e-02, -3.1275e-02],\n","          ...,\n","          [ 2.0478e-02, -9.9070e-03, -5.7483e-03,  ...,  2.3699e-02,\n","            1.0403e-02, -1.3276e-02],\n","          [-3.4111e-02, -5.9452e-03,  3.5476e-02,  ...,  8.1781e-04,\n","           -2.4034e-02,  2.9851e-02],\n","          [-4.7892e-03, -1.5399e-03, -5.1704e-04,  ..., -6.2435e-04,\n","           -5.7146e-03, -4.6577e-03]],\n","\n","         [[-7.7897e-03, -1.6458e-03, -1.4366e-03,  ..., -2.5840e-02,\n","            1.3219e-02,  1.4036e-02],\n","          [ 2.9853e-03, -2.6775e-02, -1.1628e-02,  ...,  2.4970e-02,\n","           -5.4704e-03, -3.3451e-02],\n","          [-2.2518e-02, -6.5745e-03,  5.5821e-03,  ...,  1.2085e-02,\n","            1.1003e-02, -1.0122e-02],\n","          ...,\n","          [-1.5121e-02,  2.6557e-02,  1.4466e-02,  ...,  2.4202e-02,\n","            3.3692e-02, -4.0371e-03],\n","          [ 2.4860e-02, -1.4216e-03, -2.7779e-02,  ..., -6.7290e-03,\n","           -3.3132e-02, -2.6089e-02],\n","          [ 2.8910e-02,  7.4354e-03,  1.2680e-02,  ..., -1.3993e-02,\n","            2.4374e-02,  7.3432e-04]],\n","\n","         [[-1.0199e-02,  2.0279e-02,  1.4300e-02,  ...,  1.3406e-02,\n","            9.5583e-03,  3.3803e-02],\n","          [ 3.0476e-02,  3.0050e-04, -1.8269e-02,  ...,  5.5684e-03,\n","            2.4775e-02, -2.9967e-02],\n","          [-1.2864e-02,  9.1706e-03,  1.7133e-02,  ...,  2.2142e-02,\n","           -9.1388e-03, -2.4913e-02],\n","          ...,\n","          [-3.9488e-03, -1.9460e-02, -2.4052e-02,  ..., -1.9904e-02,\n","            1.6803e-02,  9.8758e-03],\n","          [ 2.9832e-03,  2.7314e-02, -2.6300e-02,  ..., -3.5991e-02,\n","            1.5055e-02, -3.2111e-02],\n","          [ 1.5653e-02, -3.4768e-02, -1.2593e-02,  ...,  3.4331e-02,\n","            1.1323e-02,  4.5988e-03]]],\n","\n","\n","        [[[-3.3099e-02, -1.3577e-02, -1.8701e-02,  ...,  9.2174e-03,\n","           -2.2597e-02, -2.3207e-03],\n","          [-2.6757e-02,  8.9932e-03,  3.5217e-02,  ...,  1.3408e-02,\n","           -2.6628e-02, -1.5015e-02],\n","          [ 3.5385e-02, -8.0069e-03, -1.5989e-02,  ..., -2.5262e-02,\n","           -3.4372e-02, -2.9791e-02],\n","          ...,\n","          [-2.0650e-02,  1.7470e-02,  2.9814e-02,  ..., -1.1790e-02,\n","           -2.5634e-02, -2.7713e-02],\n","          [ 5.1076e-03, -2.6914e-02, -1.2992e-02,  ..., -2.9562e-02,\n","            2.0906e-03,  1.9875e-02],\n","          [-3.5058e-03,  1.8977e-02, -2.7141e-02,  ..., -2.4930e-02,\n","           -2.5217e-02, -1.8178e-02]],\n","\n","         [[ 1.6029e-02, -1.2339e-02, -1.0943e-02,  ...,  2.4595e-02,\n","           -3.4676e-02,  2.8151e-02],\n","          [-3.4905e-02,  9.2793e-03, -1.8148e-02,  ..., -2.1501e-02,\n","            3.0233e-03, -1.5097e-02],\n","          [-2.0831e-02,  5.2000e-03,  2.0280e-02,  ...,  2.1696e-02,\n","           -2.8049e-03, -1.3617e-02],\n","          ...,\n","          [-1.8590e-02, -1.3383e-03,  8.6149e-03,  ...,  2.5559e-02,\n","           -3.1310e-02, -1.4119e-02],\n","          [ 2.3043e-02,  2.4724e-02, -4.6777e-04,  ...,  1.6941e-02,\n","            1.2915e-02, -1.7855e-02],\n","          [-2.8644e-02, -9.1373e-03, -2.3675e-02,  ...,  7.2815e-03,\n","           -3.5442e-02, -3.3524e-02]],\n","\n","         [[-2.7419e-02, -2.4248e-02,  2.6910e-02,  ..., -1.0102e-02,\n","            2.0174e-03, -2.2427e-02],\n","          [-4.6643e-03, -2.7470e-02, -2.0546e-02,  ..., -3.4447e-02,\n","           -4.7700e-03, -1.7119e-02],\n","          [ 4.4623e-03,  2.9246e-02,  1.5810e-02,  ...,  1.8889e-02,\n","           -3.1804e-02,  2.7172e-02],\n","          ...,\n","          [ 3.4344e-02, -3.3553e-02, -2.6491e-02,  ..., -1.9317e-02,\n","           -5.0403e-03,  8.2304e-03],\n","          [-3.4401e-02,  3.9308e-03,  2.3154e-03,  ...,  1.0213e-02,\n","            2.9735e-02,  3.3917e-02],\n","          [ 1.1794e-02, -3.0008e-02, -4.7044e-03,  ..., -3.4018e-02,\n","            6.9810e-03,  1.9374e-02]],\n","\n","         ...,\n","\n","         [[-3.6085e-03, -5.8268e-03,  3.5551e-02,  ...,  2.8168e-03,\n","           -1.9004e-02,  2.2306e-02],\n","          [ 2.9745e-02,  1.9868e-02, -2.4092e-02,  ..., -3.3709e-02,\n","           -2.2904e-02, -5.6959e-03],\n","          [ 3.4177e-03, -4.6777e-03, -1.6205e-02,  ...,  1.7872e-02,\n","            3.1416e-02,  3.0273e-02],\n","          ...,\n","          [ 2.9182e-02, -1.2159e-02,  3.4394e-02,  ...,  3.0896e-03,\n","            2.1058e-02, -2.4115e-02],\n","          [ 2.6358e-03,  2.9284e-02,  2.5957e-02,  ..., -1.7195e-02,\n","            6.5955e-03,  1.3207e-02],\n","          [-1.0194e-02, -3.1936e-02, -5.4739e-03,  ..., -1.4734e-02,\n","           -7.9575e-03, -1.2202e-02]],\n","\n","         [[ 2.2918e-02, -1.8250e-02, -2.1393e-03,  ..., -2.0669e-02,\n","            2.6021e-02,  3.3988e-02],\n","          [-3.0214e-02,  3.0359e-03,  2.0552e-02,  ..., -2.1229e-02,\n","            2.6229e-02,  4.1696e-03],\n","          [ 2.8256e-02,  1.5738e-02,  3.1768e-02,  ..., -2.0238e-02,\n","           -1.4841e-02, -6.3499e-03],\n","          ...,\n","          [-3.8803e-03,  2.6620e-02, -6.3558e-03,  ...,  3.3624e-02,\n","            8.7943e-03,  2.0583e-02],\n","          [-8.0429e-03, -9.5501e-03,  8.2435e-03,  ...,  3.0688e-02,\n","            3.4179e-02, -2.9920e-02],\n","          [-2.7372e-02, -2.8769e-03, -1.9087e-02,  ...,  5.6489e-03,\n","            2.7416e-02, -2.0492e-02]],\n","\n","         [[-1.0323e-02,  2.3932e-02,  2.9909e-02,  ...,  1.5734e-02,\n","            5.5434e-03,  1.4485e-02],\n","          [ 2.1668e-02, -2.1017e-03,  2.0141e-02,  ...,  3.2547e-04,\n","           -1.9401e-02, -1.1696e-02],\n","          [-2.3228e-02,  2.7133e-02,  2.1598e-02,  ..., -7.4384e-03,\n","           -1.6782e-02, -4.8640e-03],\n","          ...,\n","          [-2.8074e-02,  1.9348e-02,  2.6983e-02,  ..., -1.3993e-03,\n","            2.5346e-02,  2.4342e-02],\n","          [-2.6348e-02,  2.1694e-02,  3.2815e-02,  ..., -1.0682e-03,\n","           -2.7195e-02,  3.0486e-02],\n","          [ 2.9610e-02,  2.1186e-02,  2.3914e-02,  ..., -3.0612e-02,\n","           -4.5804e-03, -5.0863e-03]]],\n","\n","\n","        [[[-6.4206e-03,  2.2104e-02, -7.6202e-03,  ..., -2.0467e-02,\n","           -2.7558e-02, -2.5794e-02],\n","          [ 2.1213e-02, -3.3531e-02,  1.8621e-02,  ...,  2.4793e-02,\n","           -3.2430e-02, -2.0275e-02],\n","          [-1.4572e-03,  3.1612e-02, -1.7039e-02,  ..., -2.4231e-02,\n","           -3.2511e-02,  2.6541e-02],\n","          ...,\n","          [-3.4304e-02,  2.1251e-02, -1.7599e-02,  ...,  1.7720e-02,\n","           -3.1362e-02,  1.1497e-02],\n","          [ 4.0447e-03, -5.2283e-03, -2.1539e-02,  ..., -3.2307e-02,\n","            1.5385e-02,  4.9328e-03],\n","          [-5.2165e-03,  2.5390e-02, -1.6718e-02,  ...,  3.5295e-02,\n","            2.0831e-02, -1.9683e-02]],\n","\n","         [[-3.0966e-02, -3.4622e-03,  3.3162e-02,  ..., -1.8050e-03,\n","           -1.2474e-03, -3.0506e-02],\n","          [ 9.3150e-03, -3.5605e-02,  1.7820e-02,  ...,  2.0984e-02,\n","           -3.7311e-03, -2.4072e-02],\n","          [-1.3045e-02, -1.5045e-03,  2.3264e-02,  ..., -2.3859e-03,\n","            5.6563e-03,  1.3725e-02],\n","          ...,\n","          [ 6.1691e-04,  2.0939e-02, -3.1174e-02,  ..., -3.4734e-02,\n","           -2.0643e-02,  3.3496e-02],\n","          [ 2.7486e-02,  1.3471e-02,  1.9443e-02,  ..., -2.9761e-02,\n","           -3.2081e-02,  1.3641e-02],\n","          [ 3.1734e-02,  2.2610e-02,  1.5285e-02,  ...,  3.0341e-02,\n","           -1.9150e-02,  2.1439e-02]],\n","\n","         [[ 2.7156e-03, -2.7228e-02, -3.3059e-03,  ...,  1.7726e-02,\n","           -1.0777e-02,  3.4781e-02],\n","          [ 3.5503e-02, -3.5063e-02, -7.4920e-03,  ..., -2.1705e-02,\n","           -3.3541e-02, -2.0863e-02],\n","          [-2.1067e-04,  1.7434e-02, -1.6074e-02,  ..., -1.3849e-02,\n","            1.8349e-02,  1.8484e-02],\n","          ...,\n","          [-1.6886e-03,  5.1855e-03,  2.6891e-02,  ..., -2.7751e-02,\n","            1.7228e-02,  1.8058e-02],\n","          [ 3.2338e-02,  9.5627e-03, -7.4273e-03,  ..., -3.7551e-03,\n","            2.4341e-02, -3.3180e-02],\n","          [ 5.1493e-03,  1.7487e-02, -3.5093e-02,  ..., -2.4483e-02,\n","           -3.4068e-02, -3.2032e-02]],\n","\n","         ...,\n","\n","         [[-9.2717e-03,  2.1207e-02,  1.6559e-02,  ...,  3.2048e-02,\n","            2.7739e-02, -3.2354e-03],\n","          [ 3.5995e-02, -3.5079e-02,  2.2395e-02,  ...,  1.3632e-02,\n","            3.5033e-02, -2.6030e-02],\n","          [-2.1315e-02,  1.5323e-02,  2.9050e-02,  ...,  2.7945e-02,\n","            2.6798e-02,  3.1088e-02],\n","          ...,\n","          [-2.8109e-02,  1.2007e-02,  3.1975e-02,  ...,  1.1644e-02,\n","            7.4524e-03, -2.1168e-02],\n","          [-1.9884e-02, -3.5502e-02, -2.9031e-02,  ..., -1.5739e-02,\n","            4.1983e-03, -1.6771e-02],\n","          [-1.6985e-02, -1.7314e-02,  1.6061e-02,  ...,  7.2205e-03,\n","            1.1160e-02, -3.3476e-02]],\n","\n","         [[ 2.9607e-02,  7.4581e-03,  1.6723e-02,  ..., -2.2314e-02,\n","            8.8768e-03,  2.2664e-02],\n","          [ 7.3828e-03,  2.4377e-02,  8.2337e-05,  ..., -1.3707e-02,\n","           -3.5970e-03, -2.0186e-02],\n","          [ 5.0177e-03, -3.0418e-02,  2.2955e-02,  ...,  9.1158e-03,\n","           -9.0231e-03,  3.5260e-02],\n","          ...,\n","          [ 1.7042e-02,  9.0380e-03,  8.4974e-03,  ...,  2.9468e-02,\n","           -9.2085e-03,  2.4903e-03],\n","          [ 2.1386e-02, -2.6504e-02, -1.8670e-02,  ...,  1.9355e-02,\n","            1.8458e-02, -2.6470e-02],\n","          [ 5.5056e-04,  2.3592e-02,  1.0786e-02,  ..., -3.5704e-02,\n","            1.9987e-02,  6.0093e-03]],\n","\n","         [[-4.0875e-03,  8.2506e-04,  3.5084e-02,  ..., -5.7787e-03,\n","            3.5071e-02,  3.2599e-02],\n","          [-7.7442e-03, -2.9635e-02, -8.6322e-03,  ...,  2.3597e-02,\n","           -6.2404e-04, -2.6240e-02],\n","          [ 9.4907e-03,  2.9287e-02, -2.2711e-02,  ...,  3.5752e-02,\n","           -3.4187e-02,  2.8993e-02],\n","          ...,\n","          [-2.3863e-02,  2.9284e-03,  2.7350e-02,  ..., -1.8581e-02,\n","            2.3868e-02, -1.5546e-02],\n","          [-3.2362e-02,  6.8069e-03,  5.3259e-03,  ...,  2.8960e-02,\n","           -4.8495e-03,  1.3232e-02],\n","          [-2.1023e-02, -3.9319e-03, -1.9542e-02,  ...,  2.3639e-02,\n","           -1.4888e-02, -2.2699e-02]]],\n","\n","\n","        ...,\n","\n","\n","        [[[ 4.0559e-03,  4.1368e-04,  2.3208e-02,  ...,  3.1211e-02,\n","           -4.5271e-04, -3.2981e-02],\n","          [-3.1480e-02, -1.6156e-02,  3.4075e-02,  ..., -2.2176e-02,\n","           -3.2431e-02,  3.3444e-02],\n","          [-2.4544e-02,  1.5253e-02,  6.0395e-03,  ...,  3.0730e-02,\n","           -3.1058e-02,  2.2591e-02],\n","          ...,\n","          [-5.7222e-03,  2.8042e-02, -1.0552e-02,  ..., -3.1765e-03,\n","            1.4557e-02,  1.7228e-02],\n","          [-3.0250e-02,  3.4537e-02, -1.3486e-02,  ...,  3.0501e-02,\n","           -3.3646e-02,  2.8781e-02],\n","          [ 2.3249e-02,  3.1151e-02, -1.9469e-04,  ...,  1.6517e-02,\n","           -3.1441e-02,  1.9029e-02]],\n","\n","         [[ 2.3484e-02, -7.8543e-03, -9.5075e-03,  ...,  1.0996e-02,\n","           -1.3518e-02, -1.0878e-02],\n","          [ 2.9796e-02,  2.0727e-02, -6.1224e-03,  ..., -2.1252e-02,\n","            2.5166e-02, -1.2542e-02],\n","          [ 1.3054e-02, -1.3337e-02,  9.4827e-04,  ..., -1.1444e-02,\n","           -3.5809e-02,  9.5487e-03],\n","          ...,\n","          [ 1.2260e-02,  2.6519e-02,  7.3052e-03,  ...,  2.6929e-02,\n","           -1.6247e-02, -2.6824e-02],\n","          [ 1.7622e-03,  5.2844e-03,  2.8669e-02,  ..., -1.6327e-02,\n","           -2.4575e-02,  3.2007e-02],\n","          [ 2.5724e-02,  3.5730e-02, -3.3036e-02,  ..., -1.4580e-02,\n","           -1.8764e-02, -2.3546e-02]],\n","\n","         [[ 7.3064e-03, -2.6434e-02,  9.9842e-03,  ...,  2.0417e-02,\n","            1.8231e-02,  1.7913e-02],\n","          [-7.4488e-03,  2.7004e-02,  1.0462e-02,  ...,  2.7132e-02,\n","            1.9516e-02, -1.2664e-02],\n","          [ 1.4413e-02,  3.9214e-03,  2.5415e-02,  ...,  1.9521e-02,\n","           -3.2855e-02, -3.3218e-02],\n","          ...,\n","          [-5.8181e-03, -2.2396e-02,  2.2884e-02,  ...,  1.8526e-02,\n","           -3.0295e-02, -2.8270e-02],\n","          [-9.8634e-04,  1.3972e-02, -1.0692e-02,  ...,  1.7314e-02,\n","            5.8905e-03, -8.5970e-03],\n","          [ 6.8210e-03, -2.7164e-02,  2.1027e-04,  ..., -5.3029e-03,\n","           -4.7699e-03, -2.0802e-03]],\n","\n","         ...,\n","\n","         [[-1.2037e-02,  1.5452e-02,  1.0740e-02,  ..., -1.1504e-02,\n","           -2.8494e-02, -1.7065e-02],\n","          [ 1.0549e-02, -7.4604e-03,  2.3677e-02,  ..., -1.6482e-02,\n","            1.3829e-02,  5.0302e-03],\n","          [-8.5867e-03, -1.3907e-02,  3.6009e-02,  ..., -1.4104e-02,\n","           -2.1649e-02, -2.5722e-02],\n","          ...,\n","          [-3.3973e-02, -2.5039e-02, -3.6003e-02,  ...,  2.7533e-02,\n","           -2.9747e-02, -2.4537e-02],\n","          [-7.4334e-03,  3.1757e-02,  1.7894e-02,  ..., -1.9592e-02,\n","           -4.6295e-03,  3.9288e-03],\n","          [-2.9214e-02,  3.0178e-02, -2.6549e-02,  ...,  1.0397e-02,\n","           -2.8428e-02, -1.0291e-02]],\n","\n","         [[ 2.0485e-02,  8.5216e-03, -1.2702e-03,  ..., -1.1134e-02,\n","            3.5486e-03,  1.3928e-02],\n","          [ 1.0720e-02, -2.1556e-02,  3.0127e-02,  ...,  4.4657e-03,\n","           -3.4825e-02,  3.3351e-02],\n","          [ 1.7613e-02,  1.3991e-02,  7.0099e-03,  ..., -3.0300e-02,\n","           -3.2809e-02, -1.5669e-02],\n","          ...,\n","          [ 1.2403e-02, -2.4688e-02, -5.6798e-03,  ...,  3.3695e-02,\n","           -3.2369e-02,  2.0248e-02],\n","          [-1.9087e-02, -1.8696e-02,  1.8399e-02,  ..., -1.6054e-03,\n","            2.7225e-02, -1.3113e-02],\n","          [ 3.1064e-02,  6.3313e-03, -1.5019e-02,  ...,  1.2873e-02,\n","           -2.5419e-02,  1.1704e-02]],\n","\n","         [[-7.9041e-03,  1.1628e-02, -6.8846e-03,  ..., -3.2484e-02,\n","            1.2718e-02,  4.8037e-03],\n","          [ 2.9057e-02,  5.3671e-03, -2.9199e-02,  ...,  2.8212e-02,\n","            6.6640e-03,  3.1259e-02],\n","          [-2.1710e-02,  2.4940e-02,  9.6852e-03,  ..., -1.0362e-02,\n","           -1.9921e-02,  2.0719e-03],\n","          ...,\n","          [ 1.7128e-02, -2.5732e-02, -3.5882e-02,  ...,  2.1728e-02,\n","            3.5626e-02, -2.2836e-02],\n","          [ 2.4922e-02, -1.0627e-02, -3.0124e-02,  ..., -1.9582e-02,\n","            1.4701e-02, -1.2958e-02],\n","          [-1.6516e-02, -9.3945e-03,  4.7591e-03,  ..., -1.3592e-02,\n","            2.1763e-02, -3.3614e-02]]],\n","\n","\n","        [[[ 1.7462e-02, -1.0368e-02,  8.6545e-04,  ..., -6.0964e-03,\n","            3.3653e-02,  3.4844e-02],\n","          [-1.1389e-02, -1.1766e-02,  5.2122e-03,  ...,  4.7924e-03,\n","            2.8245e-02,  2.1653e-02],\n","          [-3.3343e-02, -7.7991e-03, -2.3199e-02,  ...,  6.2282e-03,\n","            2.6106e-02, -1.3005e-02],\n","          ...,\n","          [ 1.0169e-02, -1.4902e-02,  2.7263e-02,  ..., -5.8428e-03,\n","            2.5168e-02,  2.7811e-02],\n","          [-9.7354e-03,  2.6615e-03,  2.3168e-02,  ..., -1.8189e-02,\n","            1.5022e-02, -3.0501e-02],\n","          [-2.4878e-02,  2.8375e-02, -1.5668e-02,  ...,  2.9421e-03,\n","           -1.9547e-02, -3.3080e-02]],\n","\n","         [[ 3.5192e-02,  3.0251e-02,  1.2161e-02,  ..., -2.4703e-02,\n","           -1.8859e-02, -1.8161e-02],\n","          [ 6.5905e-03, -6.9024e-03, -1.2710e-04,  ...,  3.9846e-03,\n","           -3.1411e-03,  1.9760e-03],\n","          [-3.0035e-02, -2.5746e-02,  6.2452e-03,  ...,  1.1547e-02,\n","            4.9203e-03, -2.3391e-02],\n","          ...,\n","          [-1.4988e-02, -3.3998e-02, -2.3283e-02,  ..., -3.4275e-02,\n","           -1.0290e-02,  3.2393e-02],\n","          [ 1.4868e-02, -3.4908e-02,  1.8790e-03,  ..., -3.1180e-02,\n","            1.1600e-02, -5.4492e-03],\n","          [-6.6109e-03,  7.6626e-04,  3.3409e-04,  ...,  1.2469e-02,\n","            8.3476e-03, -2.7225e-02]],\n","\n","         [[ 3.7639e-03, -2.2997e-02,  3.2655e-02,  ...,  8.6484e-03,\n","            3.3907e-03, -1.6854e-02],\n","          [ 3.5971e-02,  3.5218e-02, -1.4933e-02,  ...,  1.1851e-02,\n","            2.7653e-02,  2.7560e-02],\n","          [ 9.6014e-03,  3.4808e-02,  1.1006e-02,  ...,  2.4631e-02,\n","           -1.8771e-02,  2.0840e-02],\n","          ...,\n","          [ 3.2206e-02,  1.9298e-02,  9.0818e-03,  ...,  2.8941e-02,\n","           -3.3660e-04, -1.7754e-02],\n","          [ 2.7010e-02, -1.3262e-02, -3.2843e-03,  ...,  2.6226e-02,\n","            1.0082e-02,  2.4273e-02],\n","          [-3.9335e-03, -1.5516e-02, -3.1908e-02,  ...,  2.7638e-02,\n","            1.0355e-02, -3.0885e-02]],\n","\n","         ...,\n","\n","         [[ 3.2555e-02,  2.9894e-02, -1.7796e-02,  ..., -8.8151e-03,\n","            2.4421e-02, -3.2292e-02],\n","          [-3.1466e-02, -2.6875e-02, -6.8632e-03,  ...,  2.6873e-02,\n","           -1.7338e-02, -1.9225e-02],\n","          [ 1.5091e-02, -9.5230e-03, -1.8525e-03,  ...,  1.0680e-02,\n","           -2.2264e-02,  2.7075e-02],\n","          ...,\n","          [-2.7011e-03, -3.1088e-02, -1.9693e-02,  ...,  2.6771e-02,\n","            1.1142e-02, -2.7895e-02],\n","          [-2.1285e-02,  2.3941e-02,  3.2400e-02,  ..., -2.7609e-02,\n","           -2.8314e-02, -1.2890e-02],\n","          [-3.2918e-03,  1.4423e-02,  1.3236e-03,  ...,  1.9743e-02,\n","            8.5074e-03, -4.1044e-03]],\n","\n","         [[-1.7709e-02,  1.5511e-02,  9.8050e-03,  ..., -8.7196e-03,\n","           -1.9809e-02,  2.2956e-02],\n","          [ 9.8259e-03,  3.5725e-02, -2.5685e-02,  ...,  2.4853e-02,\n","           -3.5525e-02,  1.7672e-02],\n","          [ 2.7154e-02,  2.1441e-02,  1.1223e-02,  ..., -1.0744e-02,\n","            3.5930e-02,  3.3773e-02],\n","          ...,\n","          [-2.5741e-02, -1.7159e-03,  2.2601e-02,  ...,  2.7861e-02,\n","            1.9362e-02, -2.8537e-02],\n","          [-1.4753e-02,  1.8881e-02, -9.4862e-03,  ..., -3.4742e-02,\n","           -4.3675e-03, -2.3638e-02],\n","          [ 3.5551e-02,  3.2861e-02,  2.0594e-02,  ...,  1.9723e-02,\n","            6.3673e-03, -2.8631e-02]],\n","\n","         [[-1.5172e-02, -1.6811e-02, -5.9141e-03,  ...,  2.8042e-02,\n","           -2.1004e-02, -3.2913e-02],\n","          [ 2.7703e-02,  1.9476e-02,  8.7599e-03,  ..., -3.0192e-02,\n","           -2.9951e-03,  2.2423e-02],\n","          [-1.7998e-02, -2.7556e-02, -1.7566e-02,  ..., -1.3977e-02,\n","           -1.3426e-02,  3.2389e-02],\n","          ...,\n","          [-7.7683e-03, -1.0790e-03,  5.9844e-03,  ..., -3.2596e-02,\n","           -1.9057e-02,  7.1591e-03],\n","          [ 2.0728e-02,  2.7103e-02,  3.4786e-02,  ..., -2.5040e-02,\n","            3.5884e-02, -2.1340e-02],\n","          [ 1.3160e-02, -1.6367e-02, -1.6956e-02,  ...,  9.7912e-04,\n","            2.3138e-02,  2.4218e-02]]],\n","\n","\n","        [[[ 3.2719e-02, -2.7424e-02,  1.3424e-02,  ...,  1.0778e-02,\n","           -2.2863e-02,  3.4506e-02],\n","          [-1.7470e-02, -2.7207e-02,  2.4800e-03,  ...,  3.5181e-02,\n","           -1.1484e-02,  2.6284e-02],\n","          [-2.8461e-02, -4.2498e-03, -3.3176e-02,  ..., -1.5331e-02,\n","           -1.9488e-02,  1.8127e-02],\n","          ...,\n","          [ 9.4929e-03,  3.8841e-03, -3.3648e-02,  ..., -1.4546e-02,\n","           -1.6817e-02,  3.5410e-02],\n","          [ 7.0135e-03, -9.8384e-03,  1.9553e-02,  ..., -2.0519e-02,\n","            1.2256e-02,  2.2974e-02],\n","          [-2.8673e-02, -2.8176e-02, -2.4615e-02,  ...,  2.8864e-02,\n","           -2.8330e-02, -1.8489e-02]],\n","\n","         [[-2.4685e-02, -2.3771e-02,  2.4189e-02,  ..., -8.0364e-03,\n","            1.9259e-02, -1.7400e-02],\n","          [-1.9190e-04, -9.6799e-03,  2.7822e-02,  ..., -3.4231e-02,\n","            2.4793e-02,  6.7765e-03],\n","          [ 2.4984e-02, -4.4621e-03, -1.2813e-02,  ..., -2.0682e-02,\n","            1.1096e-02,  5.8955e-03],\n","          ...,\n","          [-3.4459e-02, -2.9637e-02,  7.5973e-03,  ..., -2.7528e-02,\n","            5.5909e-03,  3.1918e-02],\n","          [-3.5181e-02, -1.8039e-02,  3.2869e-02,  ..., -1.8851e-02,\n","            3.4657e-02, -2.9190e-02],\n","          [-3.4237e-02,  2.3894e-02,  6.4129e-03,  ..., -1.2991e-02,\n","            1.4424e-02, -7.4990e-05]],\n","\n","         [[-1.5967e-02,  7.2245e-03, -1.9494e-02,  ..., -9.2053e-03,\n","            2.3767e-02,  1.5679e-02],\n","          [ 1.7337e-02, -2.0707e-02, -2.5764e-02,  ..., -1.2151e-02,\n","            1.4198e-02,  5.9887e-03],\n","          [ 2.8452e-02,  1.1699e-02,  2.6318e-02,  ...,  3.1303e-02,\n","           -1.1469e-02, -2.7851e-03],\n","          ...,\n","          [ 9.4638e-03,  4.7166e-03, -3.4534e-02,  ..., -1.3815e-02,\n","            2.2092e-02, -2.8036e-02],\n","          [ 1.6609e-02,  3.1172e-02,  1.6117e-02,  ...,  7.9443e-03,\n","           -2.0516e-02,  2.1455e-02],\n","          [ 1.5410e-02,  3.1491e-02, -2.4924e-02,  ...,  2.0891e-02,\n","            3.4903e-02, -2.4446e-02]],\n","\n","         ...,\n","\n","         [[ 3.4505e-02,  1.9115e-02,  1.2567e-02,  ..., -3.1391e-02,\n","            2.9582e-02, -7.0607e-03],\n","          [ 3.5131e-02,  7.8766e-03,  5.5526e-03,  ...,  1.1937e-02,\n","           -3.7788e-03,  3.8655e-03],\n","          [-3.1369e-02,  2.4765e-02, -5.9802e-03,  ...,  1.6362e-02,\n","           -3.1473e-03, -2.1814e-02],\n","          ...,\n","          [-1.7733e-02, -1.3111e-02, -1.2360e-02,  ..., -3.4947e-02,\n","            1.1466e-02,  1.9396e-02],\n","          [ 2.4157e-02, -5.1191e-03, -1.1943e-02,  ...,  1.7829e-03,\n","           -3.0504e-02,  2.6688e-03],\n","          [ 5.9310e-03,  6.9338e-03,  1.6973e-02,  ...,  2.3988e-02,\n","           -1.8634e-02, -1.4084e-02]],\n","\n","         [[ 1.6547e-02,  1.5652e-02, -1.2245e-02,  ...,  1.7810e-02,\n","           -3.1358e-02, -3.5358e-03],\n","          [-1.9412e-02, -1.8114e-02,  2.9894e-02,  ...,  3.2912e-02,\n","            7.1858e-03, -3.4097e-02],\n","          [-2.0296e-02,  3.5342e-02,  7.9366e-03,  ..., -1.2707e-02,\n","            3.5138e-02,  2.2536e-02],\n","          ...,\n","          [-3.1101e-03,  3.1334e-02,  1.4470e-02,  ...,  1.6842e-02,\n","            1.4873e-02, -2.8172e-03],\n","          [-6.0485e-03, -1.5406e-02, -3.3261e-02,  ...,  2.7130e-03,\n","            3.0462e-02, -3.5171e-02],\n","          [ 3.4619e-02,  8.0666e-03,  2.6845e-02,  ..., -1.8192e-03,\n","           -2.5357e-02, -1.8013e-02]],\n","\n","         [[ 2.9714e-02, -2.1357e-02, -2.2204e-02,  ..., -2.7117e-02,\n","            2.5048e-02,  8.6475e-04],\n","          [ 1.8270e-02,  3.4696e-02,  4.1793e-03,  ...,  3.4876e-02,\n","            2.7833e-02, -9.5607e-03],\n","          [-2.7417e-02,  1.2054e-02,  6.0184e-03,  ..., -1.0904e-02,\n","           -1.4258e-02,  2.5905e-03],\n","          ...,\n","          [ 5.2909e-03,  1.2784e-02,  3.2054e-03,  ..., -2.3312e-02,\n","           -1.5734e-02, -2.7869e-04],\n","          [-3.4464e-04, -2.0533e-02, -1.3244e-02,  ..., -1.3012e-02,\n","            1.9855e-02,  1.0745e-02],\n","          [ 2.8981e-02, -2.9661e-03,  2.0591e-02,  ...,  3.6238e-03,\n","           -2.5783e-02, -3.1837e-02]]]], device='cuda:0')), ('t_patch_modules.0.t_patch_net.9.bias', tensor([-0.0313, -0.0282,  0.0239, -0.0195, -0.0130, -0.0123, -0.0223, -0.0248,\n","         0.0315,  0.0141, -0.0175,  0.0139], device='cuda:0')), ('t_patch_modules.0.t_patch_net.11.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.11.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.11.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.11.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.0.t_patch_net.11.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.1.t_patch_net.0.weight', tensor([[-0.0583,  0.0021, -0.0634,  ..., -0.0525, -0.0220,  0.0319],\n","        [ 0.0334, -0.0598, -0.0456,  ..., -0.0242,  0.0324,  0.0324],\n","        [-0.0107, -0.0413,  0.0083,  ...,  0.0153,  0.0492, -0.0541],\n","        ...,\n","        [ 0.0073,  0.0261, -0.0179,  ...,  0.0019,  0.0622,  0.0675],\n","        [ 0.0057,  0.0111, -0.0393,  ..., -0.0016, -0.0047,  0.0148],\n","        [ 0.0241, -0.0389,  0.0420,  ..., -0.0411,  0.0258,  0.0076]],\n","       device='cuda:0')), ('t_patch_modules.1.t_patch_net.0.bias', tensor([ 0.0061, -0.0441, -0.0145,  0.0181, -0.0320,  0.0219,  0.0637, -0.0002,\n","        -0.0362, -0.0700, -0.0669,  0.0560, -0.0052,  0.0596,  0.0165,  0.0016,\n","         0.0586,  0.0312, -0.0112,  0.0056,  0.0558,  0.0300, -0.0008,  0.0341,\n","         0.0685,  0.0541,  0.0202,  0.0055,  0.0188,  0.0251, -0.0198, -0.0511],\n","       device='cuda:0')), ('t_patch_modules.1.t_patch_net.2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.2.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.1.t_patch_net.3.weight', tensor([[ 0.1697,  0.0424,  0.1718,  ...,  0.0141,  0.1712, -0.1093],\n","        [ 0.1153, -0.0649, -0.1222,  ..., -0.1008,  0.1496, -0.1295],\n","        [-0.0783, -0.0808,  0.0958,  ...,  0.1740, -0.0724, -0.1284],\n","        ...,\n","        [-0.1226,  0.0369,  0.0062,  ..., -0.0805,  0.0606, -0.0957],\n","        [-0.0778, -0.1270, -0.0918,  ...,  0.0502, -0.0686, -0.0615],\n","        [ 0.1629, -0.0072, -0.1466,  ...,  0.1248,  0.0421, -0.1233]],\n","       device='cuda:0')), ('t_patch_modules.1.t_patch_net.3.bias', tensor([-0.1087, -0.0799,  0.0947,  0.0444,  0.1005, -0.0068, -0.0609,  0.0207,\n","        -0.1484,  0.0464,  0.1586,  0.1637, -0.0762, -0.1217, -0.0005,  0.1005,\n","        -0.0440, -0.1646,  0.0462, -0.0024,  0.1000,  0.0353,  0.0719, -0.1518,\n","         0.0284,  0.1732,  0.0424, -0.1025,  0.1322,  0.0799, -0.0513, -0.1026],\n","       device='cuda:0')), ('t_patch_modules.1.t_patch_net.5.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.5.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.5.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.5.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.5.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.1.t_patch_net.6.weight', tensor([[ 0.1229, -0.0210, -0.0231,  ..., -0.1205,  0.0896, -0.0199],\n","        [-0.0986,  0.1259,  0.0476,  ..., -0.1079,  0.1651,  0.0905],\n","        [-0.1080,  0.0751, -0.0219,  ..., -0.1425, -0.0466,  0.1300],\n","        ...,\n","        [-0.0862,  0.1523,  0.0570,  ..., -0.1254,  0.0424, -0.0682],\n","        [-0.0614,  0.1098, -0.0340,  ...,  0.0088,  0.0190, -0.1260],\n","        [ 0.1567,  0.0936,  0.1762,  ...,  0.1029, -0.0884, -0.1758]],\n","       device='cuda:0')), ('t_patch_modules.1.t_patch_net.6.bias', tensor([ 0.0880, -0.1309,  0.0758, -0.1662, -0.0655, -0.1057, -0.0129,  0.0505,\n","        -0.1577, -0.0546,  0.0139,  0.0176,  0.0015,  0.0309, -0.1151,  0.0528,\n","        -0.0576,  0.1483, -0.0933,  0.0514,  0.1380,  0.1606, -0.0032,  0.0685,\n","         0.1054, -0.1752, -0.0900,  0.0443,  0.1275,  0.1325, -0.1602,  0.0152,\n","         0.1446, -0.1515,  0.0144, -0.0933,  0.0666, -0.1456,  0.0581,  0.0974,\n","         0.1544, -0.1267,  0.1316,  0.0224, -0.1115, -0.0858, -0.0700,  0.0746,\n","         0.0601,  0.0618, -0.1602, -0.1549, -0.0827,  0.1138, -0.0324,  0.0071,\n","        -0.1661,  0.0761, -0.1187,  0.1501,  0.1732, -0.0656, -0.0120, -0.0961],\n","       device='cuda:0')), ('t_patch_modules.1.t_patch_net.8.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.8.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.8.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.8.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.8.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.1.t_patch_net.9.weight', tensor([[[[ 3.8403e-03,  3.1742e-02, -1.8117e-02,  ...,  7.9818e-03,\n","            8.4892e-03,  2.6913e-03],\n","          [-3.7969e-02,  3.7306e-02,  3.3488e-02,  ..., -7.9776e-03,\n","           -3.2856e-02, -6.0408e-03],\n","          [-1.8402e-02, -1.6681e-02,  1.7828e-02,  ...,  1.1320e-03,\n","            3.1390e-02, -1.9515e-02],\n","          [-4.2881e-03,  9.6303e-03,  1.8141e-02,  ..., -9.2382e-03,\n","           -5.3800e-03, -2.7540e-02]],\n","\n","         [[ 9.0842e-03, -6.1033e-03,  8.7400e-03,  ..., -2.3058e-02,\n","            9.2205e-03, -7.2817e-03],\n","          [-1.9840e-02, -7.1026e-03, -3.6446e-02,  ..., -6.0398e-03,\n","            1.1423e-02, -3.5074e-02],\n","          [ 7.6619e-03,  1.5949e-02, -1.0255e-02,  ..., -2.8372e-02,\n","            3.2652e-02,  3.5739e-02],\n","          [-7.2156e-03, -5.8409e-03,  8.7784e-03,  ..., -2.5578e-02,\n","           -3.1433e-02,  3.4634e-02]],\n","\n","         [[-1.3720e-03,  1.1155e-02,  2.1540e-03,  ...,  8.4826e-03,\n","            2.2003e-02, -1.7195e-02],\n","          [-6.2850e-03, -1.8753e-02, -9.7884e-04,  ..., -1.3665e-02,\n","            4.4938e-03,  4.6333e-03],\n","          [ 7.3216e-03,  3.2002e-02,  1.1316e-02,  ..., -6.9899e-03,\n","           -2.1574e-02,  1.9153e-02],\n","          [ 3.9828e-03, -8.1897e-03, -8.5782e-03,  ...,  2.2039e-02,\n","            3.7555e-03, -2.7731e-02]],\n","\n","         ...,\n","\n","         [[ 1.3222e-02,  3.7207e-02, -3.8311e-02,  ..., -1.6599e-02,\n","            3.0675e-03,  1.7576e-02],\n","          [ 1.7718e-02,  1.2602e-02, -6.8032e-03,  ..., -1.8313e-02,\n","           -2.4304e-02,  2.3377e-02],\n","          [ 6.8372e-03,  1.8555e-03, -1.7141e-02,  ..., -7.8400e-03,\n","            2.8430e-02, -2.9570e-02],\n","          [-9.3898e-03, -3.6172e-02, -3.6680e-02,  ...,  1.2699e-02,\n","            3.5234e-04,  6.1683e-03]],\n","\n","         [[ 1.0147e-02, -2.6674e-03, -2.8207e-02,  ...,  5.6783e-03,\n","           -1.8624e-02, -3.2110e-02],\n","          [-3.0857e-02, -3.0008e-02,  3.5209e-02,  ..., -5.8149e-03,\n","           -2.8608e-02,  6.5153e-03],\n","          [-3.0146e-02, -1.2641e-02, -3.6938e-02,  ..., -1.6785e-02,\n","           -1.1787e-02,  2.1560e-02],\n","          [ 3.4670e-02, -3.0456e-02, -3.1549e-03,  ..., -1.2407e-03,\n","           -3.2236e-02, -3.2353e-02]],\n","\n","         [[-1.2905e-02, -5.7580e-03,  2.8836e-02,  ...,  3.2126e-03,\n","            4.9011e-03, -3.3159e-02],\n","          [-2.1467e-03,  3.1677e-02,  1.3033e-02,  ..., -1.8477e-02,\n","           -2.3475e-02, -2.3528e-03],\n","          [-3.0374e-02, -3.2470e-02, -9.5826e-03,  ...,  2.6302e-02,\n","           -2.0120e-02,  3.3958e-02],\n","          [-2.8633e-02, -3.8487e-03, -1.9340e-02,  ..., -1.1254e-03,\n","            6.6414e-03, -3.0738e-02]]],\n","\n","\n","        [[[ 9.3488e-03,  3.1942e-02, -1.4688e-02,  ..., -3.1051e-02,\n","           -2.7190e-02,  2.3360e-02],\n","          [ 1.4590e-02, -3.4244e-02, -1.4424e-02,  ...,  8.8972e-03,\n","            6.9195e-03,  3.1140e-02],\n","          [-9.1699e-03, -1.1915e-02, -1.6355e-02,  ..., -6.7151e-03,\n","           -5.7037e-03,  3.5974e-02],\n","          [ 4.8738e-03, -3.0483e-02, -3.1221e-02,  ...,  2.0969e-02,\n","            3.3625e-02, -3.6059e-02]],\n","\n","         [[ 1.3756e-03, -2.7663e-02,  3.6701e-02,  ..., -1.1523e-02,\n","           -3.1928e-02, -3.8828e-04],\n","          [ 8.1100e-03, -3.3148e-02,  8.0404e-03,  ..., -3.1208e-02,\n","           -1.5820e-02, -1.9729e-02],\n","          [-1.1732e-02,  2.8991e-03, -2.3089e-02,  ...,  5.8113e-03,\n","           -2.3449e-02, -1.1190e-02],\n","          [ 1.9128e-02,  1.7509e-02, -2.9270e-02,  ...,  8.1748e-03,\n","           -1.2698e-02,  8.4859e-03]],\n","\n","         [[ 1.4059e-02, -1.3440e-02, -8.7600e-04,  ..., -3.1632e-02,\n","            9.9701e-03,  8.8885e-03],\n","          [-3.8513e-02,  1.9213e-02, -2.0187e-02,  ..., -8.3233e-03,\n","           -2.5327e-02, -3.0243e-02],\n","          [-6.0259e-03, -1.9548e-03, -2.9778e-02,  ..., -3.3806e-02,\n","           -3.6640e-02, -2.3485e-02],\n","          [-9.7176e-03,  7.9228e-03,  2.7806e-02,  ..., -8.5592e-03,\n","           -1.7773e-03,  3.3262e-02]],\n","\n","         ...,\n","\n","         [[ 2.4440e-03,  1.0044e-02,  2.2622e-03,  ..., -5.7076e-03,\n","            3.9259e-02,  5.2229e-03],\n","          [-9.6181e-03,  2.4499e-02,  3.7139e-02,  ..., -9.0288e-03,\n","            1.5012e-02, -2.3774e-03],\n","          [-3.8574e-02, -2.0428e-02,  3.9755e-03,  ..., -7.1143e-03,\n","            1.7085e-02, -1.5555e-02],\n","          [ 3.7994e-02, -5.4484e-03, -1.9721e-02,  ..., -5.8491e-03,\n","            3.6059e-02, -3.2184e-03]],\n","\n","         [[ 3.0225e-02, -9.6693e-03,  3.6914e-02,  ...,  3.9312e-02,\n","            2.6990e-02, -3.0103e-03],\n","          [ 3.8530e-02,  3.2846e-02,  1.7353e-02,  ...,  5.5420e-03,\n","           -2.9881e-02,  2.7504e-02],\n","          [-2.9118e-02, -1.4824e-02,  6.2104e-03,  ..., -3.4493e-02,\n","            2.7640e-02, -1.5576e-02],\n","          [ 2.2831e-02,  2.5894e-02,  6.0494e-03,  ..., -1.4370e-02,\n","            4.4293e-03, -3.4337e-02]],\n","\n","         [[-2.4889e-02,  1.3645e-02,  3.8708e-02,  ..., -2.8346e-02,\n","           -2.0567e-02, -2.2556e-02],\n","          [-3.8459e-02,  1.0622e-02,  1.3055e-02,  ...,  2.9398e-02,\n","            1.9654e-02, -1.8216e-02],\n","          [-1.4782e-02,  2.1183e-02,  1.7813e-02,  ...,  2.8101e-02,\n","           -5.6353e-03,  2.4404e-02],\n","          [ 3.7387e-02,  7.7104e-04,  3.9193e-02,  ..., -2.4130e-02,\n","           -1.8978e-02,  1.9263e-02]]],\n","\n","\n","        [[[ 3.7602e-02, -1.6471e-02, -8.1792e-03,  ...,  3.5886e-02,\n","            2.2327e-02,  1.9717e-02],\n","          [-1.1233e-02,  5.7746e-03, -7.7682e-03,  ..., -1.9825e-03,\n","            7.5525e-03,  2.1925e-02],\n","          [-3.5466e-02,  3.1934e-02,  2.4113e-02,  ...,  8.8675e-03,\n","           -3.9190e-02,  3.0229e-02],\n","          [ 3.7538e-03, -1.0888e-02,  2.8014e-02,  ..., -3.5623e-02,\n","           -5.6303e-03,  3.2054e-02]],\n","\n","         [[ 1.0417e-02,  3.2468e-02, -1.1754e-02,  ..., -2.1773e-02,\n","           -3.0728e-02, -2.8125e-02],\n","          [ 2.6532e-03,  1.4553e-02,  3.4075e-02,  ..., -2.8699e-02,\n","            2.9653e-02, -2.3178e-02],\n","          [-1.3584e-02,  2.2347e-02,  3.7901e-02,  ..., -2.2706e-02,\n","            2.5073e-02,  2.7838e-02],\n","          [-4.1333e-03,  5.1093e-03,  3.2687e-02,  ..., -9.1457e-03,\n","            6.0908e-03, -2.8509e-02]],\n","\n","         [[-1.8529e-02,  2.3129e-02, -2.5511e-03,  ..., -3.3276e-02,\n","            3.1753e-02,  7.4714e-03],\n","          [ 2.5305e-02,  3.6417e-02, -1.0207e-02,  ...,  6.2792e-03,\n","           -3.1421e-02, -3.5548e-02],\n","          [-1.9431e-02, -2.4421e-02, -3.3401e-02,  ..., -4.5683e-03,\n","            1.0872e-02, -9.3275e-03],\n","          [-2.4229e-02,  3.0476e-02, -3.8171e-02,  ...,  3.7154e-02,\n","           -3.1208e-02, -8.1151e-03]],\n","\n","         ...,\n","\n","         [[-1.1335e-02, -2.5998e-02,  2.7469e-03,  ...,  1.8240e-02,\n","           -3.7136e-03,  1.1266e-03],\n","          [ 2.9813e-03, -3.2817e-02, -3.3435e-02,  ..., -1.0442e-02,\n","           -1.7828e-02, -2.4681e-02],\n","          [-3.3451e-02,  1.2627e-02, -3.1056e-02,  ..., -2.7135e-03,\n","            3.7641e-02,  1.5984e-02],\n","          [ 1.9541e-02, -3.8359e-03,  3.8428e-02,  ..., -2.3756e-02,\n","           -3.2731e-02, -1.0447e-02]],\n","\n","         [[ 2.3508e-02, -3.5277e-02,  1.8266e-03,  ...,  1.7502e-03,\n","           -3.3701e-02, -3.6575e-02],\n","          [ 1.9527e-02, -2.7452e-02, -1.8623e-02,  ..., -2.9964e-02,\n","           -3.4802e-03,  1.2020e-02],\n","          [ 1.2247e-02, -3.7938e-02,  1.5490e-02,  ...,  2.4798e-02,\n","            1.7314e-03,  7.0914e-03],\n","          [ 9.6569e-04,  3.6221e-02, -1.3659e-02,  ...,  4.0620e-03,\n","            3.6687e-02, -8.0547e-03]],\n","\n","         [[ 6.4387e-03,  2.3217e-02, -3.8921e-02,  ...,  1.3992e-02,\n","           -1.1459e-03, -3.5553e-02],\n","          [ 2.2532e-02, -1.5368e-02, -3.8026e-02,  ..., -3.1233e-02,\n","            3.8321e-02,  1.0595e-02],\n","          [-9.3796e-03,  2.7477e-02,  3.1209e-02,  ...,  2.5636e-02,\n","           -4.9057e-04, -2.9135e-02],\n","          [ 3.0004e-02,  2.4682e-03,  1.3059e-02,  ..., -1.6079e-02,\n","            1.3842e-02, -2.1754e-02]]],\n","\n","\n","        ...,\n","\n","\n","        [[[-9.0469e-03, -1.3824e-02, -6.0358e-03,  ...,  3.6575e-02,\n","           -4.7597e-03, -2.0915e-02],\n","          [-3.5707e-03, -1.0679e-02,  2.3163e-02,  ..., -2.9583e-02,\n","            2.2536e-02, -3.2831e-02],\n","          [ 3.2648e-02, -7.5609e-03, -2.4687e-02,  ...,  3.4779e-02,\n","           -3.6142e-02,  2.6086e-02],\n","          [-1.5552e-02,  2.7588e-02,  1.9899e-02,  ...,  3.8482e-02,\n","            3.0252e-02, -3.8705e-02]],\n","\n","         [[-1.1321e-02, -3.3614e-02,  6.8103e-03,  ...,  5.2829e-03,\n","            3.3923e-02, -2.4822e-02],\n","          [-3.8427e-02, -1.4418e-02,  2.8457e-02,  ..., -3.4790e-02,\n","            3.6129e-02, -2.2241e-02],\n","          [-3.9902e-03,  1.9299e-02,  2.4830e-02,  ..., -2.9636e-02,\n","            2.5115e-02,  1.6674e-02],\n","          [-1.8421e-02,  5.4334e-03,  3.5089e-02,  ...,  1.3191e-03,\n","           -2.2814e-02, -2.3682e-02]],\n","\n","         [[ 1.9070e-03,  3.7768e-02, -2.4506e-02,  ...,  2.9791e-02,\n","            1.5839e-02, -1.4228e-02],\n","          [ 1.2847e-02, -6.0225e-04, -3.2367e-02,  ...,  3.4768e-03,\n","            3.3569e-04,  1.6361e-02],\n","          [ 3.6927e-02, -2.8378e-02,  1.2246e-02,  ..., -3.6175e-02,\n","           -1.1209e-02, -1.1451e-02],\n","          [-3.0533e-02, -3.0762e-02,  1.2412e-02,  ...,  3.6550e-02,\n","            1.9780e-02, -4.8646e-03]],\n","\n","         ...,\n","\n","         [[-3.2764e-04,  3.9173e-02, -1.6848e-02,  ..., -4.8040e-03,\n","           -1.4626e-02,  9.5568e-03],\n","          [ 2.4644e-02,  3.5481e-02, -3.4814e-02,  ..., -1.8711e-02,\n","           -3.8194e-02,  3.4189e-03],\n","          [ 2.4693e-02,  2.0916e-02,  1.7623e-02,  ...,  7.2842e-03,\n","           -2.6750e-02, -1.7744e-02],\n","          [-3.4139e-02,  1.8779e-02, -2.9578e-02,  ...,  9.8687e-03,\n","            1.6045e-02,  1.9455e-02]],\n","\n","         [[-5.5811e-03,  9.9875e-03, -1.8732e-02,  ...,  1.1623e-02,\n","           -8.8525e-03,  3.8017e-02],\n","          [ 4.3583e-03, -1.5508e-02,  3.4971e-02,  ..., -3.4579e-02,\n","           -2.4266e-02,  2.8191e-02],\n","          [-1.1920e-02,  1.2516e-02,  3.6238e-03,  ...,  3.7831e-02,\n","           -3.6376e-02, -2.7083e-02],\n","          [ 1.2189e-02, -4.6218e-03,  3.8846e-03,  ...,  2.7008e-02,\n","            1.7997e-02, -3.2497e-02]],\n","\n","         [[-1.0616e-02, -3.0603e-02, -3.1156e-02,  ..., -2.9944e-02,\n","            2.2960e-02,  3.4324e-02],\n","          [-2.6082e-05, -3.0870e-02, -3.9850e-03,  ...,  3.5690e-02,\n","           -1.3936e-02, -3.9345e-02],\n","          [-4.4895e-03,  7.1162e-04,  3.1663e-02,  ..., -6.9792e-03,\n","            3.7629e-02, -2.9710e-02],\n","          [ 2.5727e-02, -9.7377e-03,  3.0530e-02,  ..., -5.0811e-05,\n","            2.3409e-02,  1.3404e-02]]],\n","\n","\n","        [[[-3.9309e-02, -2.7345e-02,  2.1627e-03,  ...,  4.2559e-03,\n","           -3.1506e-02,  2.3765e-02],\n","          [ 3.6400e-03, -2.0609e-02, -3.0669e-02,  ..., -6.4575e-03,\n","           -2.9530e-02, -1.1079e-02],\n","          [-3.3165e-02,  3.9023e-02,  2.6022e-02,  ..., -1.0640e-02,\n","           -3.8789e-03,  2.6692e-02],\n","          [ 1.9254e-02, -2.0174e-02, -5.7738e-03,  ..., -2.9038e-02,\n","            2.5694e-02, -1.0326e-02]],\n","\n","         [[-9.8300e-03,  2.0989e-02,  2.2203e-02,  ...,  3.6935e-02,\n","            3.4522e-02,  7.6636e-03],\n","          [-1.9935e-02, -8.7045e-03, -2.8507e-03,  ..., -5.5690e-03,\n","           -1.9728e-02, -9.3117e-03],\n","          [-1.6445e-02,  3.9338e-02,  1.1576e-02,  ...,  1.2252e-02,\n","            2.4534e-02,  3.4968e-02],\n","          [-2.6382e-02,  1.6994e-02,  3.7899e-03,  ...,  2.5049e-02,\n","           -3.1297e-02, -4.8256e-03]],\n","\n","         [[ 3.8844e-02,  1.7154e-03,  1.9497e-02,  ..., -9.1344e-03,\n","           -1.0483e-02,  2.4151e-02],\n","          [-1.0769e-02,  2.6996e-02, -3.8661e-02,  ..., -2.2254e-02,\n","           -1.6248e-02, -2.1974e-02],\n","          [-3.3573e-02, -3.0550e-02, -2.1768e-02,  ...,  7.7453e-03,\n","            2.6752e-02,  2.7846e-02],\n","          [-2.1733e-02,  3.5732e-02,  5.0565e-03,  ..., -3.5202e-02,\n","           -1.4806e-02,  3.4914e-02]],\n","\n","         ...,\n","\n","         [[ 2.9905e-02,  3.8468e-02,  1.3906e-02,  ..., -2.4728e-02,\n","           -3.0355e-03, -6.0698e-03],\n","          [-1.7115e-02,  1.4737e-02,  5.5443e-03,  ..., -5.8466e-03,\n","           -3.4490e-02,  2.6541e-02],\n","          [-2.3556e-02,  2.4733e-04, -3.2498e-02,  ...,  9.7613e-03,\n","           -1.7042e-02, -1.2648e-02],\n","          [-5.3700e-03,  3.2073e-03, -3.6851e-02,  ...,  9.7767e-03,\n","           -2.2378e-02, -3.7271e-02]],\n","\n","         [[-2.9948e-02, -6.9298e-04, -2.3638e-02,  ..., -9.3815e-03,\n","           -3.3588e-03,  2.2969e-02],\n","          [ 1.8782e-02, -8.5191e-03, -3.8756e-02,  ...,  3.0251e-02,\n","            2.3935e-02, -1.2945e-03],\n","          [-2.0693e-02, -3.3179e-02, -2.1236e-02,  ...,  8.0997e-03,\n","            2.1751e-02, -1.7419e-02],\n","          [ 1.7286e-02, -3.4279e-02, -1.4969e-02,  ...,  1.8602e-02,\n","           -1.0930e-02, -2.4869e-02]],\n","\n","         [[-1.8949e-02, -3.7955e-02, -2.9358e-02,  ..., -1.3741e-02,\n","           -1.4013e-02, -2.6356e-03],\n","          [-4.8489e-04, -2.4842e-02, -1.7555e-02,  ...,  2.6642e-02,\n","           -4.0949e-03, -3.0814e-02],\n","          [ 1.1891e-02, -2.4858e-03, -2.3746e-03,  ..., -3.2884e-02,\n","           -1.7937e-02,  3.0058e-02],\n","          [ 3.1235e-02,  4.3736e-03, -2.8312e-02,  ...,  9.5718e-03,\n","            2.5917e-03, -1.6468e-02]]],\n","\n","\n","        [[[ 2.1299e-02, -3.2225e-02,  1.2303e-02,  ..., -2.6019e-02,\n","           -3.3364e-02, -1.5941e-05],\n","          [ 1.2443e-02,  1.6246e-02, -6.0002e-03,  ...,  2.1443e-03,\n","           -1.9034e-02, -1.7693e-02],\n","          [ 1.6898e-02, -3.9068e-02,  3.6667e-02,  ..., -1.3393e-02,\n","           -6.6795e-03,  1.6526e-02],\n","          [ 8.1960e-03,  1.4049e-02, -1.1275e-02,  ..., -2.7936e-02,\n","            2.5715e-02,  3.4754e-02]],\n","\n","         [[-3.0316e-02,  2.4854e-02, -3.3533e-02,  ..., -2.0906e-02,\n","            2.2816e-05,  2.9755e-02],\n","          [ 3.3716e-02, -3.9350e-02,  1.0944e-02,  ...,  1.8777e-02,\n","            3.0834e-02,  3.9153e-02],\n","          [ 6.3589e-03, -1.2249e-02, -1.2769e-02,  ..., -3.1384e-02,\n","            1.5876e-02, -3.1562e-02],\n","          [-2.4275e-02, -1.9312e-02, -5.9995e-03,  ..., -2.5864e-02,\n","           -1.3321e-02, -1.0083e-02]],\n","\n","         [[ 3.1865e-03,  2.0157e-02,  1.5306e-03,  ...,  3.0952e-02,\n","            1.4564e-02, -1.8945e-02],\n","          [-1.4641e-02, -3.5585e-02, -1.6997e-03,  ...,  2.4108e-02,\n","            2.9588e-02,  2.0203e-02],\n","          [ 2.9049e-02,  2.5036e-02, -3.7732e-02,  ..., -3.1525e-02,\n","           -1.2514e-02, -1.9953e-02],\n","          [-3.4033e-02, -3.2967e-02, -7.4108e-04,  ..., -2.4010e-02,\n","            1.6420e-02,  2.3700e-02]],\n","\n","         ...,\n","\n","         [[-4.4639e-03, -1.4583e-02, -2.9035e-02,  ...,  1.7914e-03,\n","            2.3374e-02, -2.7033e-02],\n","          [-2.0147e-03, -9.6813e-03,  5.4259e-03,  ...,  6.5498e-03,\n","            1.2464e-02,  1.2905e-02],\n","          [-1.2244e-03, -5.1522e-03,  8.5831e-03,  ...,  3.2670e-02,\n","            1.5128e-02, -3.6938e-02],\n","          [ 6.6535e-03, -3.4118e-02,  1.2570e-02,  ...,  3.4059e-02,\n","            1.5639e-02, -2.4613e-02]],\n","\n","         [[-1.5383e-02,  3.0358e-02, -3.7324e-03,  ..., -1.1066e-03,\n","            2.8987e-03,  7.9854e-03],\n","          [-2.2391e-02,  5.9381e-03, -1.5450e-02,  ...,  3.9554e-03,\n","            1.5436e-02,  1.5702e-02],\n","          [-7.1894e-03, -1.5284e-02, -3.2841e-02,  ..., -4.6477e-03,\n","            5.9542e-03, -3.0648e-02],\n","          [ 1.9627e-02,  3.5974e-02,  2.5215e-02,  ...,  8.2324e-03,\n","           -3.0483e-02, -3.0216e-03]],\n","\n","         [[ 2.0706e-02, -3.3723e-02, -1.9254e-02,  ..., -7.2335e-03,\n","            9.5076e-03,  1.2631e-02],\n","          [ 2.9109e-02,  1.9267e-02, -2.3756e-02,  ...,  3.2299e-02,\n","            3.7313e-02, -2.9028e-02],\n","          [ 2.6636e-02,  2.4095e-02, -3.6934e-02,  ..., -2.4451e-02,\n","           -1.9045e-02,  9.2693e-03],\n","          [-6.0685e-03,  1.1623e-02,  1.1171e-02,  ..., -1.1089e-02,\n","            2.1655e-02, -3.9149e-02]]]], device='cuda:0')), ('t_patch_modules.1.t_patch_net.9.bias', tensor([-0.0349, -0.0345,  0.0076,  0.0323,  0.0193,  0.0332, -0.0036,  0.0146,\n","        -0.0268, -0.0343], device='cuda:0')), ('t_patch_modules.1.t_patch_net.11.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.11.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.11.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.11.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.1.t_patch_net.11.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.2.t_patch_net.0.weight', tensor([[-0.0015,  0.0351,  0.0135,  ..., -0.0471, -0.0137, -0.0422],\n","        [ 0.0269,  0.0289, -0.0057,  ...,  0.0318, -0.0179, -0.0124],\n","        [-0.0188, -0.0280, -0.0260,  ...,  0.0268, -0.0424, -0.0366],\n","        ...,\n","        [-0.0094, -0.0356,  0.0181,  ...,  0.0492,  0.0025,  0.0198],\n","        [ 0.0150, -0.0343,  0.0277,  ...,  0.0121, -0.0353,  0.0025],\n","        [ 0.0124,  0.0470,  0.0476,  ..., -0.0263,  0.0213,  0.0386]],\n","       device='cuda:0')), ('t_patch_modules.2.t_patch_net.0.bias', tensor([-0.0372, -0.0042,  0.0245, -0.0021,  0.0100, -0.0266,  0.0130, -0.0037,\n","         0.0233,  0.0332, -0.0217,  0.0218,  0.0279, -0.0479,  0.0161,  0.0472,\n","         0.0196,  0.0289, -0.0224, -0.0117,  0.0246, -0.0116,  0.0401,  0.0304,\n","        -0.0220, -0.0408, -0.0302, -0.0385,  0.0322, -0.0396, -0.0224,  0.0370,\n","         0.0306, -0.0424, -0.0485,  0.0041, -0.0466, -0.0307,  0.0111, -0.0340,\n","        -0.0073,  0.0452,  0.0277, -0.0199, -0.0038, -0.0321, -0.0111, -0.0135,\n","        -0.0458, -0.0480, -0.0178,  0.0351, -0.0256,  0.0056, -0.0308, -0.0417,\n","         0.0343,  0.0157, -0.0273,  0.0023,  0.0387,  0.0200, -0.0466,  0.0020],\n","       device='cuda:0')), ('t_patch_modules.2.t_patch_net.2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.2.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.2.t_patch_net.3.weight', tensor([[-0.0767, -0.0928, -0.0847,  ...,  0.1047, -0.0359,  0.1207],\n","        [-0.0961, -0.1106,  0.1106,  ..., -0.0837, -0.0563, -0.0071],\n","        [ 0.0476,  0.0521, -0.0471,  ...,  0.0311, -0.0271,  0.0311],\n","        ...,\n","        [-0.0574, -0.0405, -0.0377,  ...,  0.0558,  0.1166,  0.0519],\n","        [ 0.0128,  0.1151, -0.0784,  ...,  0.0780, -0.0995, -0.0145],\n","        [ 0.0648,  0.0459,  0.0279,  ..., -0.0846,  0.1011, -0.0825]],\n","       device='cuda:0')), ('t_patch_modules.2.t_patch_net.3.bias', tensor([-1.1945e-01, -9.5897e-02,  7.8229e-03,  4.5242e-02, -1.0757e-01,\n","         3.5619e-02, -7.1135e-03, -6.9520e-03, -7.8116e-02,  6.3991e-02,\n","        -4.6144e-02,  2.9480e-02,  7.9758e-02,  1.0880e-01,  5.5530e-02,\n","        -9.4272e-02, -7.1318e-02, -2.7899e-02,  4.5621e-03,  7.3850e-05,\n","         1.0584e-01, -9.7899e-02, -6.7578e-02,  1.0607e-01,  1.2298e-02,\n","         8.5502e-02,  6.8814e-02, -3.2407e-02, -1.0545e-01, -3.8122e-02,\n","        -1.0609e-01, -5.6849e-02,  5.9137e-02,  4.7372e-02, -2.4002e-02,\n","        -1.2137e-01,  1.0403e-01,  4.8414e-02,  7.4094e-03,  5.3656e-02,\n","        -1.7804e-02, -3.5675e-02, -1.0401e-01,  9.7594e-02, -1.2444e-01,\n","        -9.4324e-02,  1.2143e-01, -9.5914e-02, -2.7169e-02,  5.1207e-02,\n","        -9.6449e-02, -2.7738e-02, -8.2045e-02,  7.6285e-02, -5.1034e-02,\n","         1.5384e-03, -2.2680e-02,  4.8087e-02,  7.6087e-03, -1.0326e-01,\n","        -6.4667e-02,  6.1901e-02, -5.4994e-02, -2.1961e-02, -6.5525e-02,\n","         1.2472e-01, -3.5318e-02, -1.1928e-01,  1.0787e-01,  3.8897e-02,\n","         8.1476e-02, -4.6166e-02], device='cuda:0')), ('t_patch_modules.2.t_patch_net.5.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.5.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.5.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.5.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.5.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.2.t_patch_net.6.weight', tensor([[ 0.0421,  0.0386,  0.0294,  ..., -0.1020, -0.0868, -0.0209],\n","        [-0.0826, -0.0742, -0.0282,  ...,  0.0767, -0.0331, -0.0797],\n","        [ 0.0356,  0.0430,  0.0331,  ..., -0.0795,  0.0514, -0.0453],\n","        ...,\n","        [-0.1054,  0.0235, -0.0661,  ..., -0.0088,  0.0171, -0.0850],\n","        [-0.0558,  0.0033,  0.0173,  ...,  0.0109, -0.0410, -0.0613],\n","        [ 0.0386, -0.0763, -0.0183,  ..., -0.1056,  0.0765, -0.0680]],\n","       device='cuda:0')), ('t_patch_modules.2.t_patch_net.6.bias', tensor([ 0.1098, -0.0484, -0.0744,  0.0132, -0.0558, -0.1040, -0.1026, -0.1105,\n","         0.0472,  0.1064, -0.0573,  0.0144,  0.0231, -0.1096,  0.1100,  0.0577,\n","        -0.0996,  0.0851, -0.0519, -0.0867, -0.0527, -0.0724, -0.1057, -0.0943,\n","        -0.0992, -0.0594,  0.0199,  0.0923,  0.0949, -0.0500, -0.0123, -0.0022,\n","         0.0911,  0.1055,  0.0361,  0.0052, -0.0613, -0.0721, -0.0262, -0.0591,\n","         0.1052,  0.0693,  0.0612, -0.0959,  0.0852,  0.0983, -0.0642,  0.0813,\n","        -0.0049,  0.0335,  0.0405,  0.0850, -0.0965,  0.0764, -0.0598,  0.0381,\n","         0.1089, -0.1118,  0.0951, -0.0881, -0.0534,  0.0089,  0.0680, -0.0799,\n","         0.0823, -0.0900,  0.0781,  0.0502,  0.0938, -0.0475, -0.0272,  0.0446,\n","        -0.0302,  0.1025,  0.0854,  0.0288, -0.0157, -0.1106, -0.0997,  0.0637,\n","        -0.0716, -0.0902, -0.0652,  0.0302, -0.1115,  0.0048,  0.0057,  0.0942,\n","        -0.1111,  0.0577,  0.0823, -0.1104,  0.0528,  0.0136, -0.0474,  0.0215],\n","       device='cuda:0')), ('t_patch_modules.2.t_patch_net.8.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.8.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.8.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.8.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.8.num_batches_tracked', tensor(0, device='cuda:0')), ('t_patch_modules.2.t_patch_net.9.weight', tensor([[[[-6.8473e-03, -2.6834e-04, -1.6378e-02,  ...,  1.4681e-02,\n","           -1.3601e-02, -4.9508e-03],\n","          [-2.7496e-03, -1.7903e-02, -4.9407e-03,  ...,  1.0895e-02,\n","            3.9620e-03,  1.8218e-02],\n","          [ 3.5057e-03,  1.3605e-02, -1.8221e-02,  ...,  2.6811e-03,\n","           -1.9188e-03,  3.6012e-03],\n","          [ 3.2201e-03,  8.9169e-03,  3.5919e-03,  ..., -1.8799e-02,\n","           -1.7914e-02,  3.3822e-03]],\n","\n","         [[-1.7729e-02,  1.8182e-02, -1.9575e-02,  ...,  1.6615e-02,\n","           -1.8112e-03, -1.0187e-02],\n","          [ 8.2288e-03,  8.7014e-03, -5.5976e-04,  ..., -6.7562e-04,\n","           -7.4236e-03,  1.0317e-02],\n","          [-1.1382e-02,  1.9703e-02,  1.8373e-03,  ..., -5.0079e-03,\n","           -7.8548e-03, -1.9233e-02],\n","          [-1.8611e-02,  1.9212e-02, -1.1412e-02,  ...,  9.8982e-03,\n","            1.1616e-02, -1.7608e-02]],\n","\n","         [[ 1.7491e-02,  1.3147e-02, -7.6214e-04,  ..., -1.9249e-02,\n","            1.1510e-02, -3.3723e-03],\n","          [-7.3353e-03,  3.1610e-03, -9.0168e-04,  ...,  1.2540e-02,\n","            1.1181e-03, -1.2747e-02],\n","          [-1.7368e-03,  2.3577e-03,  1.6215e-02,  ..., -1.1587e-02,\n","           -2.9878e-03, -6.3793e-03],\n","          [-4.0554e-03,  1.3638e-02, -1.5954e-03,  ...,  1.2255e-02,\n","           -7.3611e-03, -6.7155e-03]],\n","\n","         ...,\n","\n","         [[-1.4914e-02,  1.7702e-02, -6.2287e-03,  ...,  6.6412e-03,\n","            1.8456e-02,  1.6814e-03],\n","          [-9.6742e-04,  1.1182e-02, -1.6301e-02,  ...,  4.1949e-03,\n","            4.4122e-03, -2.6973e-03],\n","          [ 7.0100e-03,  6.8896e-03, -1.2977e-02,  ...,  1.7886e-02,\n","            9.7165e-03, -1.9178e-02],\n","          [-7.6631e-03, -1.1703e-02, -1.4965e-02,  ..., -4.5638e-03,\n","            1.0385e-02, -1.9189e-02]],\n","\n","         [[-1.7859e-02,  9.0643e-04, -4.3833e-03,  ..., -2.6405e-03,\n","            1.6679e-02, -1.6868e-02],\n","          [ 1.0553e-02,  1.0064e-02, -1.2673e-02,  ...,  4.4770e-03,\n","            6.3700e-03, -1.9194e-02],\n","          [ 1.6932e-02, -6.2870e-03, -6.3252e-03,  ...,  3.6011e-03,\n","           -1.0769e-02,  3.2374e-03],\n","          [-2.8440e-03,  4.7221e-03, -8.3150e-03,  ...,  1.0594e-02,\n","           -1.5819e-02, -1.3432e-02]],\n","\n","         [[ 8.7539e-03,  9.2473e-03,  1.1922e-02,  ...,  2.5933e-03,\n","            4.1514e-03, -4.1040e-03],\n","          [-1.5154e-02, -1.2400e-02,  1.4511e-02,  ..., -1.7997e-02,\n","            1.6043e-02,  1.0718e-02],\n","          [ 1.8271e-02, -1.6086e-02, -1.5220e-02,  ...,  2.0336e-03,\n","           -1.9726e-02,  1.4987e-02],\n","          [ 7.0692e-03,  1.4217e-02, -1.1156e-02,  ..., -1.5261e-02,\n","            6.9386e-03,  1.9680e-02]]],\n","\n","\n","        [[[-1.4789e-02,  2.8464e-03, -1.1563e-02,  ..., -4.1134e-03,\n","            1.4691e-02,  1.2398e-02],\n","          [ 1.1796e-02, -7.7320e-03, -7.1010e-03,  ..., -1.6842e-02,\n","            1.9458e-02, -7.9496e-03],\n","          [-1.7979e-03,  1.5925e-02,  1.8375e-03,  ..., -5.6052e-03,\n","           -1.6335e-03,  1.4784e-02],\n","          [ 1.6613e-03, -1.6435e-02, -1.7930e-02,  ...,  1.9639e-02,\n","           -1.8870e-02,  3.5581e-04]],\n","\n","         [[-1.4402e-02, -8.3012e-03,  8.7300e-03,  ..., -8.8860e-03,\n","            9.4213e-05, -1.4904e-02],\n","          [ 8.6048e-03,  7.5565e-03, -1.1325e-02,  ..., -1.8039e-02,\n","            1.1974e-02,  1.5230e-02],\n","          [ 1.5220e-05,  1.7670e-02,  5.8941e-03,  ...,  1.3954e-02,\n","           -4.7874e-03,  1.6322e-02],\n","          [-1.5444e-02,  1.0192e-02, -7.5509e-04,  ...,  1.7144e-02,\n","            1.0087e-03,  1.0686e-02]],\n","\n","         [[ 6.2740e-04,  1.5931e-02, -7.5879e-03,  ...,  7.2673e-03,\n","            1.8741e-02,  4.3266e-04],\n","          [-9.8985e-03,  1.0066e-02, -1.6233e-02,  ...,  1.4017e-02,\n","           -1.7589e-02, -9.3023e-03],\n","          [-1.5864e-02, -1.2634e-02, -2.7627e-03,  ...,  3.7594e-03,\n","           -1.8435e-02,  1.8757e-03],\n","          [ 1.3719e-03, -4.5425e-03, -9.4071e-03,  ..., -1.3007e-02,\n","            1.3469e-02,  1.0765e-03]],\n","\n","         ...,\n","\n","         [[-1.3116e-02, -1.4271e-02,  9.5646e-03,  ..., -4.4858e-03,\n","           -8.0830e-03,  1.2633e-02],\n","          [ 1.8748e-02, -1.8228e-03,  7.8211e-03,  ..., -4.9904e-03,\n","           -5.0039e-03, -1.9024e-02],\n","          [-7.4253e-03, -1.2371e-02,  3.6155e-04,  ...,  7.0739e-03,\n","           -6.5407e-04, -8.9339e-03],\n","          [-1.3402e-02, -1.8609e-02, -1.1934e-02,  ..., -1.3651e-02,\n","            4.0800e-03, -1.1965e-02]],\n","\n","         [[-1.3213e-02,  5.8178e-03,  1.7666e-02,  ..., -3.5017e-03,\n","            5.3519e-03, -7.1435e-03],\n","          [-4.6750e-03, -5.4102e-03,  7.3115e-03,  ...,  5.7409e-03,\n","            1.1483e-02, -7.6798e-03],\n","          [ 1.6618e-02, -1.8133e-02,  1.8990e-02,  ..., -1.0339e-02,\n","           -9.3810e-03, -6.4365e-03],\n","          [ 1.4845e-02,  1.2183e-02,  9.0774e-03,  ..., -2.7531e-03,\n","           -1.3874e-02,  1.2500e-02]],\n","\n","         [[ 1.8205e-02,  1.9119e-03,  5.3388e-03,  ..., -1.1536e-03,\n","           -1.3408e-02,  1.7162e-02],\n","          [ 6.3820e-03, -1.2001e-03, -7.8562e-03,  ...,  5.5500e-03,\n","            8.2987e-03, -7.0462e-03],\n","          [ 1.7570e-02, -3.1858e-03,  1.7997e-02,  ..., -5.2892e-03,\n","           -4.8877e-03, -7.2621e-03],\n","          [-7.1607e-03,  4.0670e-03,  2.2942e-04,  ...,  9.7235e-04,\n","            1.3719e-02, -1.6719e-02]]],\n","\n","\n","        [[[ 8.4788e-03,  1.9509e-02, -1.6383e-02,  ...,  1.5109e-02,\n","           -2.1541e-03, -1.8317e-02],\n","          [ 1.2898e-02,  1.9265e-02,  7.2972e-03,  ...,  1.2569e-02,\n","            9.1532e-03, -8.6831e-03],\n","          [-9.4534e-03,  1.9350e-02, -1.6493e-02,  ..., -1.8779e-02,\n","           -1.7478e-02, -1.1085e-02],\n","          [-2.7237e-03, -1.1278e-02, -1.5586e-02,  ..., -1.0842e-02,\n","           -5.0159e-03, -9.4926e-03]],\n","\n","         [[ 2.4249e-03, -1.2968e-02, -1.5343e-02,  ..., -1.8337e-02,\n","           -1.6471e-02,  1.7080e-02],\n","          [ 1.4950e-03,  1.3130e-02, -1.1555e-02,  ..., -4.7213e-03,\n","            1.4646e-02,  1.8884e-02],\n","          [ 1.8048e-02,  1.4644e-02, -1.8118e-02,  ...,  4.4361e-03,\n","            1.0253e-03,  4.2617e-03],\n","          [ 8.7654e-03, -1.3936e-02, -4.2542e-03,  ..., -1.1917e-03,\n","            1.0329e-02,  1.3752e-02]],\n","\n","         [[ 8.2985e-04, -1.6454e-02,  9.0971e-03,  ...,  1.2980e-02,\n","           -1.1200e-02, -1.1226e-03],\n","          [-2.8702e-03,  1.8695e-03, -1.6337e-02,  ..., -1.2245e-02,\n","           -1.0744e-02, -4.7054e-03],\n","          [ 9.7233e-04,  7.1615e-03,  1.1984e-03,  ...,  2.1371e-03,\n","           -3.6337e-03,  1.4610e-02],\n","          [-5.3328e-04, -5.3682e-03, -1.0252e-02,  ...,  1.1545e-02,\n","            8.4464e-03, -9.3782e-03]],\n","\n","         ...,\n","\n","         [[ 1.3336e-02, -1.9083e-03,  8.2773e-03,  ...,  3.9182e-03,\n","           -1.5933e-02, -1.5596e-03],\n","          [ 9.0058e-03, -9.9258e-03,  1.3126e-02,  ...,  1.3210e-02,\n","            1.2486e-02,  5.6635e-03],\n","          [ 1.9027e-02, -1.6510e-02,  1.6497e-02,  ...,  1.5923e-02,\n","           -1.5682e-02, -1.6144e-03],\n","          [ 6.4631e-03,  1.2988e-02, -2.4175e-03,  ...,  1.6474e-02,\n","            1.3368e-02,  6.1343e-03]],\n","\n","         [[-1.7000e-03, -7.4332e-03,  1.6070e-02,  ...,  5.8608e-03,\n","            4.9205e-03,  1.9715e-02],\n","          [ 4.1875e-03,  6.3467e-03, -3.4389e-03,  ...,  7.9558e-03,\n","           -1.4012e-02, -1.2888e-03],\n","          [ 1.3014e-02, -1.7639e-02, -3.2224e-03,  ..., -8.0747e-03,\n","            1.9209e-02, -6.2484e-03],\n","          [ 1.2373e-02, -9.3083e-03,  1.8169e-02,  ..., -1.2000e-02,\n","           -5.1204e-04, -1.4396e-02]],\n","\n","         [[-1.0164e-02, -1.6680e-04,  8.7869e-03,  ..., -1.0963e-02,\n","           -1.2714e-02,  6.3941e-03],\n","          [-6.4136e-03, -1.6913e-02,  7.4107e-04,  ...,  5.5433e-03,\n","           -6.4504e-03, -1.4077e-02],\n","          [-1.2115e-02, -9.9860e-03, -1.2285e-03,  ...,  2.5645e-03,\n","            1.6242e-03,  5.3072e-03],\n","          [ 2.8292e-03, -1.6033e-02, -1.7170e-02,  ...,  1.7827e-03,\n","            1.0254e-02, -1.8058e-02]]],\n","\n","\n","        ...,\n","\n","\n","        [[[ 1.1734e-02,  3.1107e-03, -1.5604e-02,  ...,  7.0901e-03,\n","            1.0676e-02,  8.1782e-03],\n","          [ 9.8473e-03,  6.7831e-03, -1.7120e-02,  ...,  1.8687e-02,\n","           -7.6663e-03,  3.1604e-04],\n","          [ 5.9109e-03,  1.0824e-02,  3.8597e-03,  ..., -5.5463e-03,\n","            1.7566e-02, -7.7509e-03],\n","          [-3.5068e-03,  1.6547e-02,  1.4098e-02,  ...,  1.1569e-02,\n","            1.5808e-02,  1.4118e-02]],\n","\n","         [[ 1.2736e-02,  2.0508e-03, -1.5610e-02,  ..., -1.4385e-02,\n","           -1.5656e-02,  1.6627e-02],\n","          [-1.3392e-02, -1.3924e-02,  1.5333e-02,  ..., -1.3001e-02,\n","           -6.9682e-03, -1.5536e-02],\n","          [ 1.5891e-02, -1.4743e-02,  6.0374e-03,  ..., -1.6036e-02,\n","           -9.7019e-03, -1.4197e-02],\n","          [-1.8647e-02,  8.9991e-03,  3.2503e-04,  ...,  9.4876e-04,\n","           -3.4913e-03,  7.1308e-03]],\n","\n","         [[ 2.5138e-03, -8.2510e-03,  2.3492e-03,  ..., -1.6409e-02,\n","           -1.9295e-03, -4.4077e-03],\n","          [-4.4787e-03, -8.6170e-03,  1.2571e-02,  ..., -2.3830e-04,\n","            1.1524e-02, -1.0718e-02],\n","          [-9.1201e-03,  1.7221e-02,  8.6366e-03,  ...,  1.9348e-02,\n","            1.2615e-02,  1.8746e-02],\n","          [ 5.0921e-04, -5.2460e-03, -6.8399e-03,  ...,  3.0886e-03,\n","            1.1520e-02, -3.4151e-03]],\n","\n","         ...,\n","\n","         [[ 3.5129e-03,  4.6565e-03, -1.8294e-02,  ..., -8.1554e-03,\n","           -1.0384e-02,  7.0437e-03],\n","          [ 1.1225e-02,  7.0698e-03, -3.1358e-03,  ...,  3.4880e-03,\n","           -6.5893e-03, -8.0926e-03],\n","          [ 7.4878e-03,  9.2289e-03, -1.1092e-02,  ...,  9.7771e-03,\n","            9.9919e-03, -4.0120e-03],\n","          [-5.8294e-03,  9.9710e-03, -1.3973e-02,  ...,  1.3867e-03,\n","           -1.4512e-03,  8.1202e-03]],\n","\n","         [[ 1.0719e-02,  1.1578e-02,  7.6598e-03,  ...,  1.7045e-02,\n","            6.6841e-03,  2.5843e-03],\n","          [ 1.5465e-02,  1.2733e-03,  1.8235e-02,  ...,  3.1960e-03,\n","            1.3310e-02,  1.2641e-02],\n","          [ 1.1476e-02, -7.2926e-03,  1.5178e-02,  ..., -8.4495e-03,\n","           -7.7257e-03,  1.1583e-02],\n","          [-8.2664e-03,  3.7986e-03, -1.7813e-02,  ...,  7.2748e-03,\n","            4.1985e-04,  1.1686e-02]],\n","\n","         [[ 1.5766e-02,  1.9466e-02,  1.3890e-02,  ..., -3.0172e-03,\n","           -1.5425e-02,  7.5854e-03],\n","          [-3.3275e-03, -6.3594e-03, -5.3800e-03,  ...,  1.5754e-02,\n","           -1.3390e-02,  1.0933e-02],\n","          [-1.3018e-02, -1.0770e-02, -4.7989e-03,  ...,  5.5618e-03,\n","           -2.5605e-03,  7.3618e-03],\n","          [ 6.4773e-03,  1.8347e-02,  1.6418e-02,  ...,  1.8973e-02,\n","           -6.8501e-03,  1.2549e-02]]],\n","\n","\n","        [[[-1.2818e-02, -9.2298e-03,  1.4024e-02,  ..., -1.9505e-02,\n","            1.1598e-02,  1.8114e-02],\n","          [ 2.8667e-03, -5.3086e-03,  5.2330e-03,  ...,  1.8654e-02,\n","           -1.7978e-02, -6.2021e-03],\n","          [ 1.5991e-02,  1.9403e-02,  8.5716e-03,  ...,  1.5265e-02,\n","            1.6875e-02, -1.8542e-02],\n","          [ 8.1463e-03, -4.0321e-03, -1.9134e-02,  ...,  1.0267e-02,\n","            4.6297e-03,  3.0878e-03]],\n","\n","         [[-1.7143e-02, -1.9023e-02, -1.2470e-02,  ...,  1.7914e-03,\n","           -1.7540e-02,  1.6448e-02],\n","          [ 9.6610e-03,  6.2996e-03, -1.8847e-02,  ...,  8.1845e-03,\n","            1.9085e-02, -9.3074e-03],\n","          [ 1.2679e-02,  2.4467e-03,  1.9013e-02,  ..., -9.5096e-03,\n","            8.5885e-04, -1.3470e-02],\n","          [ 3.2808e-03,  8.7666e-03, -1.3632e-02,  ...,  1.6466e-02,\n","            9.4208e-04,  7.3529e-03]],\n","\n","         [[ 1.6914e-02, -8.0315e-04,  4.7469e-04,  ...,  1.8156e-03,\n","           -1.1533e-02, -8.5233e-03],\n","          [-2.0942e-03, -1.2289e-02, -6.0517e-03,  ...,  1.4203e-02,\n","            1.8366e-02, -9.7303e-03],\n","          [ 7.7235e-03,  9.4563e-03, -1.0433e-02,  ...,  1.1795e-02,\n","            1.5936e-02,  3.1390e-05],\n","          [ 1.0546e-02, -1.5696e-02,  1.3981e-02,  ...,  1.1470e-02,\n","           -1.7789e-02, -9.1659e-03]],\n","\n","         ...,\n","\n","         [[ 6.1942e-03,  1.2717e-02, -5.8388e-03,  ..., -6.0281e-04,\n","           -7.7020e-03, -1.6189e-02],\n","          [ 4.1296e-03, -7.9136e-03, -8.3277e-03,  ...,  1.3977e-02,\n","            1.7918e-03,  1.3117e-02],\n","          [ 1.2442e-02,  1.0278e-02,  1.2586e-02,  ..., -1.4506e-02,\n","            1.4710e-03, -7.2040e-03],\n","          [-1.3281e-02, -3.5658e-03,  9.6713e-03,  ..., -1.8263e-02,\n","            2.2453e-03, -1.3716e-02]],\n","\n","         [[-1.4111e-02,  6.1301e-03,  1.7073e-02,  ..., -1.2066e-02,\n","            1.8471e-02,  7.4365e-03],\n","          [ 6.2307e-03, -1.9374e-02,  1.3268e-02,  ...,  5.3312e-03,\n","           -3.2741e-03, -4.2799e-03],\n","          [ 1.9503e-02,  1.5864e-02, -1.0388e-02,  ...,  1.2856e-02,\n","            1.7886e-02,  7.9189e-03],\n","          [ 1.2410e-02, -1.7212e-02,  1.6178e-02,  ...,  4.5770e-03,\n","            7.4526e-03,  7.1666e-03]],\n","\n","         [[-1.4524e-02, -1.2225e-02,  1.1083e-02,  ..., -8.8527e-03,\n","           -1.3930e-02, -1.0733e-02],\n","          [ 3.0322e-04, -4.7408e-03, -1.6999e-02,  ...,  9.9078e-03,\n","            1.4974e-02,  1.9328e-02],\n","          [ 1.1712e-02,  4.7354e-03,  6.7045e-03,  ..., -7.0484e-03,\n","            8.1112e-03,  6.1682e-03],\n","          [-1.4092e-02,  1.1499e-02,  1.2519e-03,  ..., -7.0099e-03,\n","            1.3059e-02, -1.1890e-02]]],\n","\n","\n","        [[[ 9.5880e-03, -1.4731e-02,  1.3530e-02,  ..., -1.8975e-02,\n","            1.0372e-02,  1.8305e-03],\n","          [-8.4340e-03,  1.9297e-02,  2.3017e-03,  ..., -1.0035e-03,\n","            7.1840e-03,  6.6154e-03],\n","          [ 1.2449e-02,  6.5314e-03, -1.7447e-02,  ..., -1.4936e-02,\n","           -1.7499e-02,  1.4185e-02],\n","          [ 8.0148e-03, -1.1119e-02, -1.9564e-02,  ...,  5.2037e-03,\n","           -1.5320e-02,  1.3814e-02]],\n","\n","         [[ 1.8983e-03, -1.0221e-02, -1.2123e-02,  ...,  6.7266e-03,\n","            9.6111e-03,  5.6732e-03],\n","          [-5.4966e-03, -1.7455e-02, -1.8300e-02,  ..., -1.9154e-02,\n","            1.9752e-02,  1.1012e-02],\n","          [-5.3128e-03, -1.8685e-02,  5.1159e-03,  ..., -3.3904e-03,\n","            1.2373e-02, -6.1068e-04],\n","          [ 1.5034e-02, -4.8408e-03, -2.9268e-03,  ..., -1.3839e-03,\n","           -1.0228e-02, -8.7724e-03]],\n","\n","         [[ 1.5142e-02, -2.3606e-03, -1.3273e-02,  ..., -4.2438e-03,\n","           -1.0150e-02,  1.9163e-02],\n","          [ 1.1842e-02,  9.7989e-03, -1.9334e-03,  ...,  1.0813e-03,\n","           -4.3014e-03,  2.9318e-03],\n","          [-5.9761e-03, -1.6839e-02,  1.4899e-02,  ..., -1.2338e-02,\n","           -1.4689e-02,  1.2771e-02],\n","          [-1.6181e-02,  1.4143e-02,  4.9389e-03,  ...,  1.4983e-03,\n","            1.3954e-02,  1.9187e-02]],\n","\n","         ...,\n","\n","         [[ 1.8467e-02, -2.4052e-03,  9.4541e-03,  ...,  2.6942e-03,\n","            1.0627e-02, -9.8241e-03],\n","          [ 5.2642e-03, -1.6699e-02, -5.6742e-03,  ...,  3.1394e-03,\n","           -3.7959e-03, -1.3270e-02],\n","          [ 1.0422e-02,  4.7986e-03, -4.5347e-03,  ...,  1.2148e-03,\n","           -8.4799e-03, -1.6841e-02],\n","          [ 1.5876e-02,  3.3018e-04,  1.4451e-02,  ...,  1.1622e-02,\n","            4.2789e-03, -9.6858e-03]],\n","\n","         [[-5.2616e-03, -1.4744e-02,  9.6275e-03,  ..., -3.4247e-03,\n","           -2.4508e-03, -7.4959e-03],\n","          [ 1.4984e-02,  1.4808e-02,  1.0616e-02,  ...,  8.5146e-03,\n","            1.7612e-03,  1.8572e-02],\n","          [-5.2714e-03, -1.5170e-02,  8.7717e-03,  ...,  5.5640e-03,\n","           -8.8542e-03, -1.9264e-02],\n","          [-1.6183e-03,  2.1829e-03, -1.3313e-02,  ...,  1.0271e-02,\n","           -1.6444e-03,  1.6791e-02]],\n","\n","         [[-5.3420e-03,  2.0916e-03, -1.4217e-02,  ...,  1.2393e-03,\n","           -1.9446e-02, -5.9132e-03],\n","          [-4.7372e-03,  1.2052e-02,  5.6767e-03,  ...,  1.9781e-03,\n","            1.1346e-02,  5.6853e-03],\n","          [-9.9338e-03,  4.6451e-03,  8.8144e-03,  ...,  1.3124e-02,\n","           -3.6575e-03, -1.5240e-02],\n","          [ 5.3697e-03,  1.3456e-02, -4.9871e-03,  ..., -5.7978e-04,\n","            6.7873e-03,  8.2852e-03]]]], device='cuda:0')), ('t_patch_modules.2.t_patch_net.9.bias', tensor([-0.0137, -0.0050, -0.0149,  0.0096,  0.0122,  0.0145, -0.0084, -0.0090,\n","         0.0053,  0.0125], device='cuda:0')), ('t_patch_modules.2.t_patch_net.11.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.11.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.11.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.11.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')), ('t_patch_modules.2.t_patch_net.11.num_batches_tracked', tensor(0, device='cuda:0')), ('temporal_smoothing_conv_layer.weight', tensor([[[[0.2500, 0.3750, 0.2500, 0.3750, 0.2500],\n","          [0.3750, 0.5000, 0.5000, 0.5000, 0.3750],\n","          [0.2500, 0.5000, 1.0000, 0.5000, 0.2500],\n","          [0.3750, 0.5000, 0.5000, 0.5000, 0.3750],\n","          [0.2500, 0.3750, 0.2500, 0.3750, 0.2500]]]], device='cuda:0')), ('temporal_smoothing_conv_layer.bias', tensor([-0.1708], device='cuda:0')), ('final_classifier.2.weight', tensor([[-0.0103, -0.0379,  0.0273,  ..., -0.0205, -0.0308, -0.0018],\n","        [ 0.0308,  0.0558, -0.0445,  ...,  0.0646, -0.0655, -0.0166],\n","        [ 0.0563,  0.0386, -0.0128,  ...,  0.1017, -0.0223, -0.0583],\n","        ...,\n","        [-0.0177, -0.0601,  0.0345,  ..., -0.0004,  0.0386,  0.0087],\n","        [ 0.0957,  0.0919,  0.0311,  ...,  0.0728,  0.0828,  0.0775],\n","        [ 0.0063,  0.0382, -0.0556,  ..., -0.0321, -0.1000,  0.0338]],\n","       device='cuda:0')), ('final_classifier.2.bias', tensor([ 0.0240, -0.0917,  0.0223, -0.0548, -0.0730,  0.1008, -0.0644, -0.0681,\n","         0.1020,  0.0733,  0.0377,  0.0079, -0.0776, -0.0068,  0.0503, -0.0285,\n","         0.0107, -0.0328,  0.0818,  0.1009], device='cuda:0'))])\n"]}]},{"cell_type":"code","source":["from torch.nn import DataParallel as run_in_parallel\n","\n","help(run_in_parallel)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhiF91ha8evE","executionInfo":{"status":"ok","timestamp":1715911505383,"user_tz":240,"elapsed":49,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}},"outputId":"7c49f2f3-c60b-4bbf-ba30-8ff47813f1e5"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on class DataParallel in module torch.nn.parallel.data_parallel:\n","\n","class DataParallel(torch.nn.modules.module.Module, typing.Generic)\n"," |  DataParallel(module: ~T, device_ids: Optional[Sequence[Union[int, torch.device]]] = None, output_device: Union[int, torch.device, NoneType] = None, dim: int = 0) -> None\n"," |  \n"," |  Implements data parallelism at the module level.\n"," |  \n"," |  This container parallelizes the application of the given :attr:`module` by\n"," |  splitting the input across the specified devices by chunking in the batch\n"," |  dimension (other objects will be copied once per device). In the forward\n"," |  pass, the module is replicated on each device, and each replica handles a\n"," |  portion of the input. During the backwards pass, gradients from each replica\n"," |  are summed into the original module.\n"," |  \n"," |  The batch size should be larger than the number of GPUs used.\n"," |  \n"," |  .. warning::\n"," |      It is recommended to use :class:`~torch.nn.parallel.DistributedDataParallel`,\n"," |      instead of this class, to do multi-GPU training, even if there is only a single\n"," |      node. See: :ref:`cuda-nn-ddp-instead` and :ref:`ddp`.\n"," |  \n"," |  Arbitrary positional and keyword inputs are allowed to be passed into\n"," |  DataParallel but some types are specially handled. tensors will be\n"," |  **scattered** on dim specified (default 0). tuple, list and dict types will\n"," |  be shallow copied. The other types will be shared among different threads\n"," |  and can be corrupted if written to in the model's forward pass.\n"," |  \n"," |  The parallelized :attr:`module` must have its parameters and buffers on\n"," |  ``device_ids[0]`` before running this :class:`~torch.nn.DataParallel`\n"," |  module.\n"," |  \n"," |  .. warning::\n"," |      In each forward, :attr:`module` is **replicated** on each device, so any\n"," |      updates to the running module in ``forward`` will be lost. For example,\n"," |      if :attr:`module` has a counter attribute that is incremented in each\n"," |      ``forward``, it will always stay at the initial value because the update\n"," |      is done on the replicas which are destroyed after ``forward``. However,\n"," |      :class:`~torch.nn.DataParallel` guarantees that the replica on\n"," |      ``device[0]`` will have its parameters and buffers sharing storage with\n"," |      the base parallelized :attr:`module`. So **in-place** updates to the\n"," |      parameters or buffers on ``device[0]`` will be recorded. E.g.,\n"," |      :class:`~torch.nn.BatchNorm2d` and :func:`~torch.nn.utils.spectral_norm`\n"," |      rely on this behavior to update the buffers.\n"," |  \n"," |  .. warning::\n"," |      Forward and backward hooks defined on :attr:`module` and its submodules\n"," |      will be invoked ``len(device_ids)`` times, each with inputs located on\n"," |      a particular device. Particularly, the hooks are only guaranteed to be\n"," |      executed in correct order with respect to operations on corresponding\n"," |      devices. For example, it is not guaranteed that hooks set via\n"," |      :meth:`~torch.nn.Module.register_forward_pre_hook` be executed before\n"," |      `all` ``len(device_ids)`` :meth:`~torch.nn.Module.forward` calls, but\n"," |      that each such hook be executed before the corresponding\n"," |      :meth:`~torch.nn.Module.forward` call of that device.\n"," |  \n"," |  .. warning::\n"," |      When :attr:`module` returns a scalar (i.e., 0-dimensional tensor) in\n"," |      :func:`forward`, this wrapper will return a vector of length equal to\n"," |      number of devices used in data parallelism, containing the result from\n"," |      each device.\n"," |  \n"," |  .. note::\n"," |      There is a subtlety in using the\n"," |      ``pack sequence -> recurrent network -> unpack sequence`` pattern in a\n"," |      :class:`~torch.nn.Module` wrapped in :class:`~torch.nn.DataParallel`.\n"," |      See :ref:`pack-rnn-unpack-with-data-parallelism` section in FAQ for\n"," |      details.\n"," |  \n"," |  \n"," |  Args:\n"," |      module (Module): module to be parallelized\n"," |      device_ids (list of int or torch.device): CUDA devices (default: all devices)\n"," |      output_device (int or torch.device): device location of output (default: device_ids[0])\n"," |  \n"," |  Attributes:\n"," |      module (Module): the module to be parallelized\n"," |  \n"," |  Example::\n"," |  \n"," |      >>> # xdoctest: +SKIP\n"," |      >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2])\n"," |      >>> output = net(input_var)  # input_var can be on any device, including CPU\n"," |  \n"," |  Method resolution order:\n"," |      DataParallel\n"," |      torch.nn.modules.module.Module\n"," |      typing.Generic\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, module: ~T, device_ids: Optional[Sequence[Union[int, torch.device]]] = None, output_device: Union[int, torch.device, NoneType] = None, dim: int = 0) -> None\n"," |      Initialize internal Module state, shared by both nn.Module and ScriptModule.\n"," |  \n"," |  forward(self, *inputs: Any, **kwargs: Any) -> Any\n"," |      Define the computation performed at every call.\n"," |      \n"," |      Should be overridden by all subclasses.\n"," |      \n"," |      .. note::\n"," |          Although the recipe for forward pass needs to be defined within\n"," |          this function, one should call the :class:`Module` instance afterwards\n"," |          instead of this since the former takes care of running the\n"," |          registered hooks while the latter silently ignores them.\n"," |  \n"," |  gather(self, outputs: Any, output_device: Union[int, torch.device]) -> Any\n"," |  \n"," |  parallel_apply(self, replicas: Sequence[~T], inputs: Sequence[Any], kwargs: Any) -> List[Any]\n"," |  \n"," |  replicate(self, module: ~T, device_ids: Sequence[Union[int, torch.device]]) -> List[~T]\n"," |  \n"," |  scatter(self, inputs: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]], device_ids: Sequence[Union[int, torch.device]]) -> Any\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __annotations__ = {}\n"," |  \n"," |  __orig_bases__ = (<class 'torch.nn.modules.module.Module'>, typing.Gen...\n"," |  \n"," |  __parameters__ = (~T,)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from torch.nn.modules.module.Module:\n"," |  \n"," |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n"," |  \n"," |  __delattr__(self, name)\n"," |      Implement delattr(self, name).\n"," |  \n"," |  __dir__(self)\n"," |      Default dir() implementation.\n"," |  \n"," |  __getattr__(self, name: str) -> Any\n"," |      # On the return type:\n"," |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n"," |      # This is done for better interop with various type checkers for the end users.\n"," |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n"," |      # people to excessively use type-ignores, asserts, casts, etc.\n"," |      # See full discussion on the problems with returning `Union` here\n"," |      # https://github.com/microsoft/pyright/issues/4213\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __repr__(self)\n"," |      Return repr(self).\n"," |  \n"," |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n"," |      Implement setattr(self, name, value).\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n"," |      Add a child module to the current module.\n"," |      \n"," |      The module can be accessed as an attribute using the given name.\n"," |      \n"," |      Args:\n"," |          name (str): name of the child module. The child module can be\n"," |              accessed from this module using the given name\n"," |          module (Module): child module to be added to the module.\n"," |  \n"," |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n"," |      Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\n"," |      \n"," |      Typical use includes initializing the parameters of a model\n"," |      (see also :ref:`nn-init-doc`).\n"," |      \n"," |      Args:\n"," |          fn (:class:`Module` -> None): function to be applied to each submodule\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> @torch.no_grad()\n"," |          >>> def init_weights(m):\n"," |          >>>     print(m)\n"," |          >>>     if type(m) == nn.Linear:\n"," |          >>>         m.weight.fill_(1.0)\n"," |          >>>         print(m.weight)\n"," |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n"," |          >>> net.apply(init_weights)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          Parameter containing:\n"," |          tensor([[1., 1.],\n"," |                  [1., 1.]], requires_grad=True)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          Parameter containing:\n"," |          tensor([[1., 1.],\n"," |                  [1., 1.]], requires_grad=True)\n"," |          Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          )\n"," |  \n"," |  bfloat16(self: ~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n"," |      Return an iterator over module buffers.\n"," |      \n"," |      Args:\n"," |          recurse (bool): if True, then yields buffers of this module\n"," |              and all submodules. Otherwise, yields only buffers that\n"," |              are direct members of this module.\n"," |      \n"," |      Yields:\n"," |          torch.Tensor: module buffer\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> for buf in model.buffers():\n"," |          >>>     print(type(buf), buf.size())\n"," |          <class 'torch.Tensor'> (20L,)\n"," |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n"," |  \n"," |  children(self) -> Iterator[ForwardRef('Module')]\n"," |      Return an iterator over immediate children modules.\n"," |      \n"," |      Yields:\n"," |          Module: a child module\n"," |  \n"," |  compile(self, *args, **kwargs)\n"," |      Compile this Module's forward using :func:`torch.compile`.\n"," |      \n"," |      This Module's `__call__` method is compiled and all arguments are passed as-is\n"," |      to :func:`torch.compile`.\n"," |      \n"," |      See :func:`torch.compile` for details on the arguments for this function.\n"," |  \n"," |  cpu(self: ~T) -> ~T\n"," |      Move all model parameters and buffers to the CPU.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n"," |      Move all model parameters and buffers to the GPU.\n"," |      \n"," |      This also makes associated parameters and buffers different objects. So\n"," |      it should be called before constructing optimizer if the module will\n"," |      live on GPU while being optimized.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Args:\n"," |          device (int, optional): if specified, all parameters will be\n"," |              copied to that device\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  double(self: ~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``double`` datatype.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  eval(self: ~T) -> ~T\n"," |      Set the module in evaluation mode.\n"," |      \n"," |      This has any effect only on certain modules. See documentations of\n"," |      particular modules for details of their behaviors in training/evaluation\n"," |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n"," |      etc.\n"," |      \n"," |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n"," |      \n"," |      See :ref:`locally-disable-grad-doc` for a comparison between\n"," |      `.eval()` and several similar mechanisms that may be confused with it.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  extra_repr(self) -> str\n"," |      Set the extra representation of the module.\n"," |      \n"," |      To print customized extra information, you should re-implement\n"," |      this method in your own modules. Both single-line and multi-line\n"," |      strings are acceptable.\n"," |  \n"," |  float(self: ~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``float`` datatype.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  get_buffer(self, target: str) -> 'Tensor'\n"," |      Return the buffer given by ``target`` if it exists, otherwise throw an error.\n"," |      \n"," |      See the docstring for ``get_submodule`` for a more detailed\n"," |      explanation of this method's functionality as well as how to\n"," |      correctly specify ``target``.\n"," |      \n"," |      Args:\n"," |          target: The fully-qualified string name of the buffer\n"," |              to look for. (See ``get_submodule`` for how to specify a\n"," |              fully-qualified string.)\n"," |      \n"," |      Returns:\n"," |          torch.Tensor: The buffer referenced by ``target``\n"," |      \n"," |      Raises:\n"," |          AttributeError: If the target string references an invalid\n"," |              path or resolves to something that is not a\n"," |              buffer\n"," |  \n"," |  get_extra_state(self) -> Any\n"," |      Return any extra state to include in the module's state_dict.\n"," |      \n"," |      Implement this and a corresponding :func:`set_extra_state` for your module\n"," |      if you need to store extra state. This function is called when building the\n"," |      module's `state_dict()`.\n"," |      \n"," |      Note that extra state should be picklable to ensure working serialization\n"," |      of the state_dict. We only provide provide backwards compatibility guarantees\n"," |      for serializing Tensors; other objects may break backwards compatibility if\n"," |      their serialized pickled form changes.\n"," |      \n"," |      Returns:\n"," |          object: Any extra state to store in the module's state_dict\n"," |  \n"," |  get_parameter(self, target: str) -> 'Parameter'\n"," |      Return the parameter given by ``target`` if it exists, otherwise throw an error.\n"," |      \n"," |      See the docstring for ``get_submodule`` for a more detailed\n"," |      explanation of this method's functionality as well as how to\n"," |      correctly specify ``target``.\n"," |      \n"," |      Args:\n"," |          target: The fully-qualified string name of the Parameter\n"," |              to look for. (See ``get_submodule`` for how to specify a\n"," |              fully-qualified string.)\n"," |      \n"," |      Returns:\n"," |          torch.nn.Parameter: The Parameter referenced by ``target``\n"," |      \n"," |      Raises:\n"," |          AttributeError: If the target string references an invalid\n"," |              path or resolves to something that is not an\n"," |              ``nn.Parameter``\n"," |  \n"," |  get_submodule(self, target: str) -> 'Module'\n"," |      Return the submodule given by ``target`` if it exists, otherwise throw an error.\n"," |      \n"," |      For example, let's say you have an ``nn.Module`` ``A`` that\n"," |      looks like this:\n"," |      \n"," |      .. code-block:: text\n"," |      \n"," |          A(\n"," |              (net_b): Module(\n"," |                  (net_c): Module(\n"," |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n"," |                  )\n"," |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n"," |              )\n"," |          )\n"," |      \n"," |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n"," |      submodule ``net_b``, which itself has two submodules ``net_c``\n"," |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n"," |      \n"," |      To check whether or not we have the ``linear`` submodule, we\n"," |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n"," |      we have the ``conv`` submodule, we would call\n"," |      ``get_submodule(\"net_b.net_c.conv\")``.\n"," |      \n"," |      The runtime of ``get_submodule`` is bounded by the degree\n"," |      of module nesting in ``target``. A query against\n"," |      ``named_modules`` achieves the same result, but it is O(N) in\n"," |      the number of transitive modules. So, for a simple check to see\n"," |      if some submodule exists, ``get_submodule`` should always be\n"," |      used.\n"," |      \n"," |      Args:\n"," |          target: The fully-qualified string name of the submodule\n"," |              to look for. (See above example for how to specify a\n"," |              fully-qualified string.)\n"," |      \n"," |      Returns:\n"," |          torch.nn.Module: The submodule referenced by ``target``\n"," |      \n"," |      Raises:\n"," |          AttributeError: If the target string references an invalid\n"," |              path or resolves to something that is not an\n"," |              ``nn.Module``\n"," |  \n"," |  half(self: ~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``half`` datatype.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n"," |      Move all model parameters and buffers to the IPU.\n"," |      \n"," |      This also makes associated parameters and buffers different objects. So\n"," |      it should be called before constructing optimizer if the module will\n"," |      live on IPU while being optimized.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Arguments:\n"," |          device (int, optional): if specified, all parameters will be\n"," |              copied to that device\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n"," |      Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\n"," |      \n"," |      If :attr:`strict` is ``True``, then\n"," |      the keys of :attr:`state_dict` must exactly match the keys returned\n"," |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n"," |      \n"," |      .. warning::\n"," |          If :attr:`assign` is ``True`` the optimizer must be created after\n"," |          the call to :attr:`load_state_dict`.\n"," |      \n"," |      Args:\n"," |          state_dict (dict): a dict containing parameters and\n"," |              persistent buffers.\n"," |          strict (bool, optional): whether to strictly enforce that the keys\n"," |              in :attr:`state_dict` match the keys returned by this module's\n"," |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n"," |          assign (bool, optional): whether to assign items in the state\n"," |              dictionary to their corresponding keys in the module instead\n"," |              of copying them inplace into the module's current parameters and buffers.\n"," |              When ``False``, the properties of the tensors in the current\n"," |              module are preserved while when ``True``, the properties of the\n"," |              Tensors in the state dict are preserved.\n"," |              Default: ``False``\n"," |      \n"," |      Returns:\n"," |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n"," |              * **missing_keys** is a list of str containing the missing keys\n"," |              * **unexpected_keys** is a list of str containing the unexpected keys\n"," |      \n"," |      Note:\n"," |          If a parameter or buffer is registered as ``None`` and its corresponding key\n"," |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n"," |          ``RuntimeError``.\n"," |  \n"," |  modules(self) -> Iterator[ForwardRef('Module')]\n"," |      Return an iterator over all modules in the network.\n"," |      \n"," |      Yields:\n"," |          Module: a module in the network\n"," |      \n"," |      Note:\n"," |          Duplicate modules are returned only once. In the following\n"," |          example, ``l`` will be returned only once.\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> l = nn.Linear(2, 2)\n"," |          >>> net = nn.Sequential(l, l)\n"," |          >>> for idx, m in enumerate(net.modules()):\n"," |          ...     print(idx, '->', m)\n"," |      \n"," |          0 -> Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          )\n"," |          1 -> Linear(in_features=2, out_features=2, bias=True)\n"," |  \n"," |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n"," |      Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\n"," |      \n"," |      Args:\n"," |          prefix (str): prefix to prepend to all buffer names.\n"," |          recurse (bool, optional): if True, then yields buffers of this module\n"," |              and all submodules. Otherwise, yields only buffers that\n"," |              are direct members of this module. Defaults to True.\n"," |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n"," |      \n"," |      Yields:\n"," |          (str, torch.Tensor): Tuple containing the name and buffer\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> for name, buf in self.named_buffers():\n"," |          >>>     if name in ['running_var']:\n"," |          >>>         print(buf.size())\n"," |  \n"," |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n"," |      Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\n"," |      \n"," |      Yields:\n"," |          (str, Module): Tuple containing a name and child module\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> for name, module in model.named_children():\n"," |          >>>     if name in ['conv4', 'conv5']:\n"," |          >>>         print(module)\n"," |  \n"," |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n"," |      Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\n"," |      \n"," |      Args:\n"," |          memo: a memo to store the set of modules already added to the result\n"," |          prefix: a prefix that will be added to the name of the module\n"," |          remove_duplicate: whether to remove the duplicated module instances in the result\n"," |              or not\n"," |      \n"," |      Yields:\n"," |          (str, Module): Tuple of name and module\n"," |      \n"," |      Note:\n"," |          Duplicate modules are returned only once. In the following\n"," |          example, ``l`` will be returned only once.\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> l = nn.Linear(2, 2)\n"," |          >>> net = nn.Sequential(l, l)\n"," |          >>> for idx, m in enumerate(net.named_modules()):\n"," |          ...     print(idx, '->', m)\n"," |      \n"," |          0 -> ('', Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          ))\n"," |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n"," |  \n"," |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n"," |      Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n"," |      \n"," |      Args:\n"," |          prefix (str): prefix to prepend to all parameter names.\n"," |          recurse (bool): if True, then yields parameters of this module\n"," |              and all submodules. Otherwise, yields only parameters that\n"," |              are direct members of this module.\n"," |          remove_duplicate (bool, optional): whether to remove the duplicated\n"," |              parameters in the result. Defaults to True.\n"," |      \n"," |      Yields:\n"," |          (str, Parameter): Tuple containing the name and parameter\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> for name, param in self.named_parameters():\n"," |          >>>     if name in ['bias']:\n"," |          >>>         print(param.size())\n"," |  \n"," |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n"," |      Return an iterator over module parameters.\n"," |      \n"," |      This is typically passed to an optimizer.\n"," |      \n"," |      Args:\n"," |          recurse (bool): if True, then yields parameters of this module\n"," |              and all submodules. Otherwise, yields only parameters that\n"," |              are direct members of this module.\n"," |      \n"," |      Yields:\n"," |          Parameter: module parameter\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> for param in model.parameters():\n"," |          >>>     print(type(param), param.size())\n"," |          <class 'torch.Tensor'> (20L,)\n"," |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n"," |  \n"," |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n"," |      Register a backward hook on the module.\n"," |      \n"," |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n"," |      the behavior of this function will change in future versions.\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n"," |      Add a buffer to the module.\n"," |      \n"," |      This is typically used to register a buffer that should not to be\n"," |      considered a model parameter. For example, BatchNorm's ``running_mean``\n"," |      is not a parameter, but is part of the module's state. Buffers, by\n"," |      default, are persistent and will be saved alongside parameters. This\n"," |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n"," |      only difference between a persistent buffer and a non-persistent buffer\n"," |      is that the latter will not be a part of this module's\n"," |      :attr:`state_dict`.\n"," |      \n"," |      Buffers can be accessed as attributes using given names.\n"," |      \n"," |      Args:\n"," |          name (str): name of the buffer. The buffer can be accessed\n"," |              from this module using the given name\n"," |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n"," |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n"," |              the buffer is **not** included in the module's :attr:`state_dict`.\n"," |          persistent (bool): whether the buffer is part of this module's\n"," |              :attr:`state_dict`.\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n"," |  \n"," |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n"," |      Register a forward hook on the module.\n"," |      \n"," |      The hook will be called every time after :func:`forward` has computed an output.\n"," |      \n"," |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n"," |      the positional arguments given to the module. Keyword arguments won't be\n"," |      passed to the hooks and only to the ``forward``. The hook can modify the\n"," |      output. It can modify the input inplace but it will not have effect on\n"," |      forward since this is called after :func:`forward` is called. The hook\n"," |      should have the following signature::\n"," |      \n"," |          hook(module, args, output) -> None or modified output\n"," |      \n"," |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n"," |      ``kwargs`` given to the forward function and be expected to return the\n"," |      output possibly modified. The hook should have the following signature::\n"," |      \n"," |          hook(module, args, kwargs, output) -> None or modified output\n"," |      \n"," |      Args:\n"," |          hook (Callable): The user defined hook to be registered.\n"," |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n"," |              before all existing ``forward`` hooks on this\n"," |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n"," |              ``hook`` will be fired after all existing ``forward`` hooks on\n"," |              this :class:`torch.nn.modules.Module`. Note that global\n"," |              ``forward`` hooks registered with\n"," |              :func:`register_module_forward_hook` will fire before all hooks\n"," |              registered by this method.\n"," |              Default: ``False``\n"," |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n"," |              kwargs given to the forward function.\n"," |              Default: ``False``\n"," |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n"," |              whether an exception is raised while calling the Module.\n"," |              Default: ``False``\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n"," |      Register a forward pre-hook on the module.\n"," |      \n"," |      The hook will be called every time before :func:`forward` is invoked.\n"," |      \n"," |      \n"," |      If ``with_kwargs`` is false or not specified, the input contains only\n"," |      the positional arguments given to the module. Keyword arguments won't be\n"," |      passed to the hooks and only to the ``forward``. The hook can modify the\n"," |      input. User can either return a tuple or a single modified value in the\n"," |      hook. We will wrap the value into a tuple if a single value is returned\n"," |      (unless that value is already a tuple). The hook should have the\n"," |      following signature::\n"," |      \n"," |          hook(module, args) -> None or modified input\n"," |      \n"," |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n"," |      kwargs given to the forward function. And if the hook modifies the\n"," |      input, both the args and kwargs should be returned. The hook should have\n"," |      the following signature::\n"," |      \n"," |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n"," |      \n"," |      Args:\n"," |          hook (Callable): The user defined hook to be registered.\n"," |          prepend (bool): If true, the provided ``hook`` will be fired before\n"," |              all existing ``forward_pre`` hooks on this\n"," |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n"," |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n"," |              on this :class:`torch.nn.modules.Module`. Note that global\n"," |              ``forward_pre`` hooks registered with\n"," |              :func:`register_module_forward_pre_hook` will fire before all\n"," |              hooks registered by this method.\n"," |              Default: ``False``\n"," |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n"," |              given to the forward function.\n"," |              Default: ``False``\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n"," |      Register a backward hook on the module.\n"," |      \n"," |      The hook will be called every time the gradients with respect to a module\n"," |      are computed, i.e. the hook will execute if and only if the gradients with\n"," |      respect to module outputs are computed. The hook should have the following\n"," |      signature::\n"," |      \n"," |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n"," |      \n"," |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n"," |      with respect to the inputs and outputs respectively. The hook should\n"," |      not modify its arguments, but it can optionally return a new gradient with\n"," |      respect to the input that will be used in place of :attr:`grad_input` in\n"," |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n"," |      as positional arguments and all kwarg arguments are ignored. Entries\n"," |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n"," |      arguments.\n"," |      \n"," |      For technical reasons, when this hook is applied to a Module, its forward function will\n"," |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n"," |      of each Tensor returned by the Module's forward function.\n"," |      \n"," |      .. warning ::\n"," |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n"," |          will raise an error.\n"," |      \n"," |      Args:\n"," |          hook (Callable): The user-defined hook to be registered.\n"," |          prepend (bool): If true, the provided ``hook`` will be fired before\n"," |              all existing ``backward`` hooks on this\n"," |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n"," |              ``hook`` will be fired after all existing ``backward`` hooks on\n"," |              this :class:`torch.nn.modules.Module`. Note that global\n"," |              ``backward`` hooks registered with\n"," |              :func:`register_module_full_backward_hook` will fire before\n"," |              all hooks registered by this method.\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n"," |      Register a backward pre-hook on the module.\n"," |      \n"," |      The hook will be called every time the gradients for the module are computed.\n"," |      The hook should have the following signature::\n"," |      \n"," |          hook(module, grad_output) -> tuple[Tensor] or None\n"," |      \n"," |      The :attr:`grad_output` is a tuple. The hook should\n"," |      not modify its arguments, but it can optionally return a new gradient with\n"," |      respect to the output that will be used in place of :attr:`grad_output` in\n"," |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n"," |      all non-Tensor arguments.\n"," |      \n"," |      For technical reasons, when this hook is applied to a Module, its forward function will\n"," |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n"," |      of each Tensor returned by the Module's forward function.\n"," |      \n"," |      .. warning ::\n"," |          Modifying inputs inplace is not allowed when using backward hooks and\n"," |          will raise an error.\n"," |      \n"," |      Args:\n"," |          hook (Callable): The user-defined hook to be registered.\n"," |          prepend (bool): If true, the provided ``hook`` will be fired before\n"," |              all existing ``backward_pre`` hooks on this\n"," |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n"," |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n"," |              on this :class:`torch.nn.modules.Module`. Note that global\n"," |              ``backward_pre`` hooks registered with\n"," |              :func:`register_module_full_backward_pre_hook` will fire before\n"," |              all hooks registered by this method.\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_load_state_dict_post_hook(self, hook)\n"," |      Register a post hook to be run after module's ``load_state_dict`` is called.\n"," |      \n"," |      It should have the following signature::\n"," |          hook(module, incompatible_keys) -> None\n"," |      \n"," |      The ``module`` argument is the current module that this hook is registered\n"," |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n"," |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n"," |      is a ``list`` of ``str`` containing the missing keys and\n"," |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n"," |      \n"," |      The given incompatible_keys can be modified inplace if needed.\n"," |      \n"," |      Note that the checks performed when calling :func:`load_state_dict` with\n"," |      ``strict=True`` are affected by modifications the hook makes to\n"," |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n"," |      set of keys will result in an error being thrown when ``strict=True``, and\n"," |      clearing out both missing and unexpected keys will avoid an error.\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n"," |      Alias for :func:`add_module`.\n"," |  \n"," |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n"," |      Add a parameter to the module.\n"," |      \n"," |      The parameter can be accessed as an attribute using given name.\n"," |      \n"," |      Args:\n"," |          name (str): name of the parameter. The parameter can be accessed\n"," |              from this module using the given name\n"," |          param (Parameter or None): parameter to be added to the module. If\n"," |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n"," |              are ignored. If ``None``, the parameter is **not** included in the\n"," |              module's :attr:`state_dict`.\n"," |  \n"," |  register_state_dict_pre_hook(self, hook)\n"," |      Register a pre-hook for the :meth:`~torch.nn.Module.load_state_dict` method.\n"," |      \n"," |      These hooks will be called with arguments: ``self``, ``prefix``,\n"," |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n"," |      hooks can be used to perform pre-processing before the ``state_dict``\n"," |      call is made.\n"," |  \n"," |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n"," |      Change if autograd should record operations on parameters in this module.\n"," |      \n"," |      This method sets the parameters' :attr:`requires_grad` attributes\n"," |      in-place.\n"," |      \n"," |      This method is helpful for freezing part of the module for finetuning\n"," |      or training parts of a model individually (e.g., GAN training).\n"," |      \n"," |      See :ref:`locally-disable-grad-doc` for a comparison between\n"," |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n"," |      \n"," |      Args:\n"," |          requires_grad (bool): whether autograd should record operations on\n"," |                                parameters in this module. Default: ``True``.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  set_extra_state(self, state: Any)\n"," |      Set extra state contained in the loaded `state_dict`.\n"," |      \n"," |      This function is called from :func:`load_state_dict` to handle any extra state\n"," |      found within the `state_dict`. Implement this function and a corresponding\n"," |      :func:`get_extra_state` for your module if you need to store extra state within its\n"," |      `state_dict`.\n"," |      \n"," |      Args:\n"," |          state (dict): Extra state from the `state_dict`\n"," |  \n"," |  share_memory(self: ~T) -> ~T\n"," |      See :meth:`torch.Tensor.share_memory_`.\n"," |  \n"," |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n"," |      Return a dictionary containing references to the whole state of the module.\n"," |      \n"," |      Both parameters and persistent buffers (e.g. running averages) are\n"," |      included. Keys are corresponding parameter and buffer names.\n"," |      Parameters and buffers set to ``None`` are not included.\n"," |      \n"," |      .. note::\n"," |          The returned object is a shallow copy. It contains references\n"," |          to the module's parameters and buffers.\n"," |      \n"," |      .. warning::\n"," |          Currently ``state_dict()`` also accepts positional arguments for\n"," |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n"," |          this is being deprecated and keyword arguments will be enforced in\n"," |          future releases.\n"," |      \n"," |      .. warning::\n"," |          Please avoid the use of argument ``destination`` as it is not\n"," |          designed for end-users.\n"," |      \n"," |      Args:\n"," |          destination (dict, optional): If provided, the state of module will\n"," |              be updated into the dict and the same object is returned.\n"," |              Otherwise, an ``OrderedDict`` will be created and returned.\n"," |              Default: ``None``.\n"," |          prefix (str, optional): a prefix added to parameter and buffer\n"," |              names to compose the keys in state_dict. Default: ``''``.\n"," |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n"," |              returned in the state dict are detached from autograd. If it's\n"," |              set to ``True``, detaching will not be performed.\n"," |              Default: ``False``.\n"," |      \n"," |      Returns:\n"," |          dict:\n"," |              a dictionary containing a whole state of the module\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> # xdoctest: +SKIP(\"undefined vars\")\n"," |          >>> module.state_dict().keys()\n"," |          ['bias', 'weight']\n"," |  \n"," |  to(self, *args, **kwargs)\n"," |      Move and/or cast the parameters and buffers.\n"," |      \n"," |      This can be called as\n"," |      \n"," |      .. function:: to(device=None, dtype=None, non_blocking=False)\n"," |         :noindex:\n"," |      \n"," |      .. function:: to(dtype, non_blocking=False)\n"," |         :noindex:\n"," |      \n"," |      .. function:: to(tensor, non_blocking=False)\n"," |         :noindex:\n"," |      \n"," |      .. function:: to(memory_format=torch.channels_last)\n"," |         :noindex:\n"," |      \n"," |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n"," |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n"," |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n"," |      (if given). The integral parameters and buffers will be moved\n"," |      :attr:`device`, if that is given, but with dtypes unchanged. When\n"," |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n"," |      with respect to the host if possible, e.g., moving CPU Tensors with\n"," |      pinned memory to CUDA devices.\n"," |      \n"," |      See below for examples.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Args:\n"," |          device (:class:`torch.device`): the desired device of the parameters\n"," |              and buffers in this module\n"," |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n"," |              the parameters and buffers in this module\n"," |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n"," |              dtype and device for all parameters and buffers in this module\n"," |          memory_format (:class:`torch.memory_format`): the desired memory\n"," |              format for 4D parameters and buffers in this module (keyword\n"," |              only argument)\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |      \n"," |      Examples::\n"," |      \n"," |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n"," |          >>> linear = nn.Linear(2, 2)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1913, -0.3420],\n"," |                  [-0.5113, -0.2325]])\n"," |          >>> linear.to(torch.double)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1913, -0.3420],\n"," |                  [-0.5113, -0.2325]], dtype=torch.float64)\n"," |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n"," |          >>> gpu1 = torch.device(\"cuda:1\")\n"," |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1914, -0.3420],\n"," |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n"," |          >>> cpu = torch.device(\"cpu\")\n"," |          >>> linear.to(cpu)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1914, -0.3420],\n"," |                  [-0.5112, -0.2324]], dtype=torch.float16)\n"," |      \n"," |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n"," |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n"," |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n"," |          tensor([[0.6122+0.j, 0.1150+0.j],\n"," |                  [0.6122+0.j, 0.1150+0.j],\n"," |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n"," |  \n"," |  to_empty(self: ~T, *, device: Union[int, str, torch.device, NoneType], recurse: bool = True) -> ~T\n"," |      Move the parameters and buffers to the specified device without copying storage.\n"," |      \n"," |      Args:\n"," |          device (:class:`torch.device`): The desired device of the parameters\n"," |              and buffers in this module.\n"," |          recurse (bool): Whether parameters and buffers of submodules should\n"," |              be recursively moved to the specified device.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  train(self: ~T, mode: bool = True) -> ~T\n"," |      Set the module in training mode.\n"," |      \n"," |      This has any effect only on certain modules. See documentations of\n"," |      particular modules for details of their behaviors in training/evaluation\n"," |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n"," |      etc.\n"," |      \n"," |      Args:\n"," |          mode (bool): whether to set training mode (``True``) or evaluation\n"," |                       mode (``False``). Default: ``True``.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n"," |      Casts all parameters and buffers to :attr:`dst_type`.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Args:\n"," |          dst_type (type or string): the desired type\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n"," |      Move all model parameters and buffers to the XPU.\n"," |      \n"," |      This also makes associated parameters and buffers different objects. So\n"," |      it should be called before constructing optimizer if the module will\n"," |      live on XPU while being optimized.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Arguments:\n"," |          device (int, optional): if specified, all parameters will be\n"," |              copied to that device\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  zero_grad(self, set_to_none: bool = True) -> None\n"," |      Reset gradients of all model parameters.\n"," |      \n"," |      See similar function under :class:`torch.optim.Optimizer` for more context.\n"," |      \n"," |      Args:\n"," |          set_to_none (bool): instead of setting to zero, set the grads to None.\n"," |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from torch.nn.modules.module.Module:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from torch.nn.modules.module.Module:\n"," |  \n"," |  T_destination = ~T_destination\n"," |  \n"," |  call_super_init = False\n"," |  \n"," |  dump_patches = False\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods inherited from typing.Generic:\n"," |  \n"," |  __class_getitem__(params) from builtins.type\n"," |  \n"," |  __init_subclass__(*args, **kwargs) from builtins.type\n"," |      This method is called when a class is subclassed.\n"," |      \n"," |      The default implementation does nothing. It may be\n"," |      overridden to extend subclasses.\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_score as calculate_avg_precision\n","from torch.nn import Softmax as softmax_function\n","\n","# Store a softmax function in a variable to calculate the average precision.\n","average_precision_softmax = softmax_function(dim = 1)"],"metadata":{"id":"1f2XVeeqDhqs","executionInfo":{"status":"ok","timestamp":1715911505383,"user_tz":240,"elapsed":10,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","execution_count":140,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6JQ-DMJsZ9RA","outputId":"a24b1f78-e4c5-434c-ad3f-a29cc100d5b7","executionInfo":{"status":"error","timestamp":1715913260717,"user_tz":240,"elapsed":1755343,"user":{"displayName":"Mathew John","userId":"02352606196281189679"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Batch 1, Training Loss: 3.2651829719543457\n","Epoch 1, Batch 1, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 2, Training Loss: 3.3814516067504883\n","Epoch 1, Batch 2, Training accuracy: 6.250000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 3, Training Loss: 3.4688737392425537\n","Epoch 1, Batch 3, Training accuracy: 0.000000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 4, Training Loss: 3.22158145904541\n","Epoch 1, Batch 4, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 5, Training Loss: 3.389482259750366\n","Epoch 1, Batch 5, Training accuracy: 0.000000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 6, Training Loss: 3.406094551086426\n","Epoch 1, Batch 6, Training accuracy: 3.125000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 7, Training Loss: 3.383458137512207\n","Epoch 1, Batch 7, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 8, Training Loss: 3.1702659130096436\n","Epoch 1, Batch 8, Training accuracy: 0.000000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 9, Training Loss: 3.501380443572998\n","Epoch 1, Batch 9, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 10, Training Loss: 3.2564003467559814\n","Epoch 1, Batch 10, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 11, Training Loss: 3.4410173892974854\n","Epoch 1, Batch 11, Training accuracy: 0.000000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 12, Training Loss: 3.121290445327759\n","Epoch 1, Batch 12, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 13, Training Loss: 3.2488696575164795\n","Epoch 1, Batch 13, Training accuracy: 0.000000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 14, Training Loss: 3.2907330989837646\n","Epoch 1, Batch 14, Training accuracy: 3.125000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 15, Training Loss: 3.187382936477661\n","Epoch 1, Batch 15, Training accuracy: 0.000000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 16, Training Loss: 3.5368611812591553\n","Epoch 1, Batch 16, Training accuracy: 3.125000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 17, Training Loss: 3.165083646774292\n","Epoch 1, Batch 17, Training accuracy: 3.125000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 18, Training Loss: 3.2244350910186768\n","Epoch 1, Batch 18, Training accuracy: 6.250000%, Average Precision: 0.09375\n","\n","\n","===============================================\n","Epoch 1, Batch 19, Training Loss: 3.2982685565948486\n","Epoch 1, Batch 19, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 20, Training Loss: 3.323667049407959\n","Epoch 1, Batch 20, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 21, Training Loss: 3.3276546001434326\n","Epoch 1, Batch 21, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 22, Training Loss: 3.1309659481048584\n","Epoch 1, Batch 22, Training accuracy: 3.125000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 23, Training Loss: 3.4798195362091064\n","Epoch 1, Batch 23, Training accuracy: 6.250000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 24, Training Loss: 3.1350417137145996\n","Epoch 1, Batch 24, Training accuracy: 3.125000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 25, Training Loss: 3.3823390007019043\n","Epoch 1, Batch 25, Training accuracy: 0.000000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 26, Training Loss: 3.1034200191497803\n","Epoch 1, Batch 26, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 27, Training Loss: 3.1497421264648438\n","Epoch 1, Batch 27, Training accuracy: 9.375000%, Average Precision: 0.125\n","\n","\n","===============================================\n","Epoch 1, Batch 28, Training Loss: 3.0696966648101807\n","Epoch 1, Batch 28, Training accuracy: 0.000000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 29, Training Loss: 3.0391597747802734\n","Epoch 1, Batch 29, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 30, Training Loss: 3.1085269451141357\n","Epoch 1, Batch 30, Training accuracy: 6.250000%, Average Precision: 0.09375\n","\n","\n","===============================================\n","Epoch 1, Batch 31, Training Loss: 3.1700804233551025\n","Epoch 1, Batch 31, Training accuracy: 0.000000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 32, Training Loss: 3.1878724098205566\n","Epoch 1, Batch 32, Training accuracy: 9.375000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 33, Training Loss: 3.3040525913238525\n","Epoch 1, Batch 33, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 34, Training Loss: 3.1388890743255615\n","Epoch 1, Batch 34, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 35, Training Loss: 3.235668420791626\n","Epoch 1, Batch 35, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 36, Training Loss: 3.1811764240264893\n","Epoch 1, Batch 36, Training accuracy: 0.000000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 37, Training Loss: 3.200840711593628\n","A better 3D in action model has been made.\n","Epoch 1, Batch 37, Training accuracy: 15.625000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 38, Training Loss: 3.2502846717834473\n","Epoch 1, Batch 38, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 39, Training Loss: 3.192331075668335\n","Epoch 1, Batch 39, Training accuracy: 6.250000%, Average Precision: 0.09375\n","\n","\n","===============================================\n","Epoch 1, Batch 40, Training Loss: 3.2246463298797607\n","Epoch 1, Batch 40, Training accuracy: 6.250000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 41, Training Loss: 3.2585268020629883\n","Epoch 1, Batch 41, Training accuracy: 3.125000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 42, Training Loss: 3.1527600288391113\n","Epoch 1, Batch 42, Training accuracy: 0.000000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 43, Training Loss: 3.1534268856048584\n","Epoch 1, Batch 43, Training accuracy: 3.125000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 1, Batch 44, Training Loss: 2.998581886291504\n","Epoch 1, Batch 44, Training accuracy: 0.000000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 45, Training Loss: 3.2434780597686768\n","Epoch 1, Batch 45, Training accuracy: 6.250000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 1, Batch 46, Training Loss: 3.1248066425323486\n","Epoch 1, Batch 46, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 47, Training Loss: 3.0426712036132812\n","Epoch 1, Batch 47, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 1, Batch 48, Training Loss: 3.054786205291748\n","Epoch 1, Batch 48, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["mAP: 0.034505208333333336\n","Epoch 2, Batch 1, Training Loss: 3.033649444580078\n","Epoch 2, Batch 1, Training accuracy: 6.250000%, Average Precision: 0.03125\n","\n","\n","===============================================\n","Epoch 2, Batch 2, Training Loss: 3.0243258476257324\n","Epoch 2, Batch 2, Training accuracy: 3.125000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 2, Batch 3, Training Loss: 3.0631306171417236\n","Epoch 2, Batch 3, Training accuracy: 9.375000%, Average Precision: 0.15625\n","\n","\n","===============================================\n","Epoch 2, Batch 4, Training Loss: 3.075596809387207\n","Epoch 2, Batch 4, Training accuracy: 9.375000%, Average Precision: 0.0\n","\n","\n","===============================================\n","Epoch 2, Batch 5, Training Loss: 3.0895533561706543\n","Epoch 2, Batch 5, Training accuracy: 3.125000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 2, Batch 6, Training Loss: 3.0239179134368896\n","Epoch 2, Batch 6, Training accuracy: 3.125000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 2, Batch 7, Training Loss: 3.0042643547058105\n","Epoch 2, Batch 7, Training accuracy: 6.250000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 2, Batch 8, Training Loss: 3.089099645614624\n","Epoch 2, Batch 8, Training accuracy: 9.375000%, Average Precision: 0.0625\n","\n","\n","===============================================\n","Epoch 2, Batch 9, Training Loss: 3.1045877933502197\n","Epoch 2, Batch 9, Training accuracy: 3.125000%, Average Precision: 0.0\n","\n","\n","===============================================\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-140-c810dd89a70f>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Make predictions using the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0maction_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_classification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Store the per frame losses for the model predictions of action classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-132-c08a5f408e2b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, S)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# Store the global spatio-temporal representation of an input point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# cloud sequence that the t-patch modules produce in a variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mglobal_spatio_temporal_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_patch_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Print that the final classifier started computation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-130-cb86b739c156>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, S)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Store the t-patches that are extracted in a variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     t_patches = self.t_patch_extractor(\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubsampling_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-126-89925afafb0f>\u001b[0m in \u001b[0;36mextract_forward_t_patches\u001b[0;34m(S, M, K, subsampler, gaussian_noise_mu, gaussian_noise_std, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_1_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;31m# Update the M query points of the current frame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mquery_points_frame_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_patches_in_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_t_patches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_points_frame_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_noise_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_noise_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Store the forward t-patches of the current point cloud sequence in the tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-125-1d8a9b82522b>\u001b[0m in \u001b[0;36mextract_patches_in_frame\u001b[0;34m(S, t, t_patches, query_points_frame_t, gaussian_noise_mu, gaussian_noise_std, K)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Store the patch of the current query point of the current frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# in a variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpsi_t_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_q_previous_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgaussian_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Store the query point x_q^t of the next frame in a variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-123-6c1f79feb314>\u001b[0m in \u001b[0;36mKNN\u001b[0;34m(data, query, K)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Compute the L2 distances of the query point from the data points.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mL2_distances_from_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Initialize a variable to hold the K nearest neighbors of the query point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Parallelize the model.\n","action_classification_model = run_in_parallel(action_classification_model)\n","\n","# Store the training losses and accuracies in a variable.\n","training_losses_and_accuracies = []\n","\n","# Store the average precisions in a variable.\n","avg_precisions = []\n","\n","# Store the number of training epochs in a variable.\n","# Currently, 3 epochs and ~20% training accuracy.\n","number_epochs = 20\n","\n","for epoch in range(number_epochs):\n","  for batch_index, batch in enumerate(training_data_loader):\n","    # Get the clips in the current batch and its labels.\n","    labels, clips = batch\n","\n","    # Put the model in training mode.\n","    action_classification_model.train()\n","\n","    # Make predictions using the model.\n","    action_predictions = action_classification_model(clips).to(this_device)\n","\n","    # Store the per frame losses for the model predictions of action classes.\n","    per_frame_losses = frame_loss(\n","      action_predictions,\n","       (\n","           labels.to(dtype = torch.long).unsqueeze(1) + torch.zeros((clips.shape[0], clip_size), dtype = torch.long, device = this_device)\n","       ).to(device = this_device)\n","      ).to(device = this_device)\n","\n","    # Nullify the gradients of the loss by the model parameters.\n","    model_optimizer.zero_grad()\n","\n","    # Do backpropagation.\n","    per_frame_losses.backward()\n","\n","    # Update the model parameters.\n","    model_optimizer.step()\n","\n","    # Print out the losses.\n","    print(\"Epoch {}, Batch {}, Training Loss: {}\".format(epoch + 1, batch_index + 1, per_frame_losses.item()))\n","\n","    # Store the predicted targets in a variable.\n","    prediction_targets = torch.argmax(torch.max(action_predictions, dim = 2)[0], dim = 1).cpu()\n","\n","    # Calculate the average precision and store it in a variable.\n","    average_precision = calculate_avg_precision(labels.cpu(), prediction_targets, average = 'micro')\n","\n","    # Calculate the training accuracy and store it in a variable.\n","    action_predictions = torch.mode(torch.max(action_predictions, dim = 1)[1], dim = 1)[0]\n","    training_accuracy = torch.sum(action_predictions == labels) / action_predictions.shape[0]\n","\n","    # Append the average precision to the list of average precision values.\n","    avg_precisions.append(average_precision)\n","\n","    # If the current training accuracy is better than all times before,\n","    # update the best 3D In Action model.\n","    if best_training_accuracy <= training_accuracy:\n","      # Print out that a better 3D in action model was made.\n","      print(\"A better 3D in action model has been made.\")\n","      best_training_accuracy = training_accuracy\n","      best_3d_in_action_model = action_classification_model\n","\n","    # Print out the training accuracy.\n","    print(\"Epoch {}, Batch {}, Training accuracy: {:%}, Average Precision: {}\\n\\n\".format(epoch + 1, batch_index + 1, training_accuracy, average_precision))\n","    print(\"===============================================\")\n","\n","    # Store the training loss and the training accuracy of the current batch in the list of losses and accuracies.\n","    training_losses_and_accuracies.append((per_frame_losses.item(), training_accuracy.item()))\n","\n","    if dataset_used == \"MSR-Action3D\":\n","      # Save the best 3D in Action model to a file and how many epochs it was trained to a file. Also, save the best training accuracy to a file.\n","      torch.save((best_3d_in_action_model.state_dict(), num_trained_epochs, best_training_accuracy),\n","      '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/MSRAction3DFPS/MSRAction3D.pt')\n","    else:\n","      # Save the best 3D in Action model to a file and how many epochs it was trained to a file. Also, save the best training accuracy to a file.\n","      torch.save((best_3d_in_action_model.state_dict(), num_trained_epochs, best_training_accuracy),\n","      '/content/drive/MyDrive/Colab Notebooks/COMPSCI 674/Final Project/DFAUST/downloads/scans/50020/DFAUST.pt')\n","\n","  # Plot the losses and accuracies.\n","  draw_losses_and_accuracies()\n","\n","  # Print out the mean average precision.\n","  print('mAP: {}'.format(NumPy.mean(avg_precisions)))\n","\n","  # Increment the number of epochs the best model has been trained.\n","  num_trained_epochs += 1"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["9OV7GIyKP_iE","mF75gkL7Miij"],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}